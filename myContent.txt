reading content from C:\Users\Asus\Desktop\See\EY.txt

PE@!HxG433M4hTyt

reading content from C:\Users\Asus\Desktop\See\FileIndexRowMapper.java

package com.example.searchengine_ver1.backendapi.repository;

import com.example.searchengine_ver1.model.FileIndex;
import org.springframework.jdbc.core.RowMapper;

import java.sql.ResultSet;
import java.sql.SQLException;

public class FileIndexRowMapper implements RowMapper<FileIndex> {
    @Override
    public FileIndex mapRow(ResultSet rs, int rowNum) throws SQLException {
        return new FileIndex(
                rs.getLong("id"),
                rs.getString("file_name"),
                rs.getString("file_path"),
                rs.getString("file_type"),
                rs.getString("file_content"),
                rs.getTimestamp("indexed_at").toLocalDateTime()
        );
    }
}


reading content from C:\Users\Asus\Desktop\See\FileIndexService.java

package com.example.searchengine_ver1.backendapi.service;

import com.example.searchengine_ver1.model.FileIndex;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;

import java.util.List;

@Service
public class FileIndexService {
    private final FileIndexRepository fileIndexRepository;

    @Autowired
    public FileIndexService(FileIndexRepository fileIndexRepository) {
        this.fileIndexRepository = fileIndexRepository;
    }

    public void indexFiles(List<FileIndex> files) {
        fileIndexRepository.saveAll(files);
    }

    public List<FileIndex> searchFiles(String query) {
        return fileIndexRepository.searchFiles(query);
    }
}


reading content from C:\Users\Asus\Desktop\See\Letter of Intent.pdf


Letter of Intent 

For Participation in the MHP Internship 

I, Braica Patricia Maria, am a third-year student at the Faculty of Automation and Computers, within the 

Technical University of Cluj-Napoca, specializing in Computer Science and Information Technology in 

English. I wish to apply for the MHP internship in Cluj-Napoca. 

I would like to bring to your attention the reasons why I believe I am a strong candidate for this project. 

Firstly, I aim to bring innovation and contribute to improving the results of MHP. I feel well-prepared to 

engage in the complex field of Java programming. My qualifications are supported by the excellent 

results I have achieved in relevant subjects throughout my three years of study. 

Secondly, I want to develop my practical skills in the technical field, particularly in software solutions 

implementation. I believe this project will provide me with the opportunity to learn from professionals 

and apply theoretical knowledge in practice. I am highly motivated by the chance to work in an 

interdisciplinary team and contribute to the development of a real-world project. 

It is essential to mention that I have already worked with this type of technology in Web Development 

during the “Software Engineering” course, where I developed a project on restaurant recommendation 

systems using Google Location and Weather APIs, implemented with Java Spring Boot. 

Additionally, I have completed the "Object-Oriented Programming (OOP) in Java and C++" course, where 

I worked on a mandatory project that strengthened my knowledge of OOP-based application 

development. 

The "SQL Programming" course provided me with fundamental skills in database management, which 

are crucial for any project involving data storage and manipulation. 

Throughout my studies, I have taken relevant courses that have equipped me with essential skills in 

computer science and applied technologies. For example, through the "Fundamental Algorithms and 

Data Structures in C" course, I learned efficient programming techniques for developing high-

performance solutions. 

During the "AI Technologies in Python" course, my teammates and I implemented complex AI solutions 

such as theorem proving and the DPLL algorithm. 

My objectives are to expand my experience in advanced technologies, particularly in web development, 

while remaining open to exploring other IT specializations. Through this project, I wish to gain insight 

into different fields where I can contribute and discover what best suits my skills and interests. My goal 

is to acquire valuable knowledge and experiment with various types of projects to eventually become an 

expert in a specific domain or position, based on the skills and passions I develop along the way. 

If you consider that my motivation and expertise make me a suitable candidate for this project, I am 

available for an interview with the selection committee. Thank you for your time and consideration. 

Sincerely, 

Braica Patricia Maria 



reading content from C:\Users\Asus\Desktop\See\Letter of IntentEng.docx

Letter of Intent
For Participation in the MHP Internship
I, Braica Patricia Maria, am a third-year student at the Faculty of Automation and Computers, within the Technical University of Cluj-Napoca, specializing in Computer Science and Information Technology in English. I wish to apply for the MHP internship in Cluj-Napoca.
I would like to bring to your attention the reasons why I believe I am a strong candidate for this project.
Firstly, I aim to bring innovation and contribute to improving the results of MHP. I feel well-prepared to engage in the complex field of Java programming. My qualifications are supported by the excellent results I have achieved in relevant subjects throughout my three years of study.
Secondly, I want to develop my practical skills in the technical field, particularly in software solutions implementation. I believe this project will provide me with the opportunity to learn from professionals and apply theoretical knowledge in practice. I am highly motivated by the chance to work in an interdisciplinary team and contribute to the development of a real-world project.
It is essential to mention that I have already worked with this type of technology in Web Development during the “Software Engineering” course, where I developed a project on restaurant recommendation systems using Google Location and Weather APIs, implemented with Java Spring Boot.
Additionally, I have completed the "Object-Oriented Programming (OOP) in Java and C++" course, where I worked on a mandatory project that strengthened my knowledge of OOP-based application development.
The "SQL Programming" course provided me with fundamental skills in database management, which are crucial for any project involving data storage and manipulation.
Throughout my studies, I have taken relevant courses that have equipped me with essential skills in computer science and applied technologies. For example, through the "Fundamental Algorithms and Data Structures in C" course, I learned efficient programming techniques for developing high-performance solutions.
During the "AI Technologies in Python" course, my teammates and I implemented complex AI solutions such as theorem proving and the DPLL algorithm.
My objectives are to expand my experience in advanced technologies, particularly in web development, while remaining open to exploring other IT specializations. Through this project, I wish to gain insight into different fields where I can contribute and discover what best suits my skills and interests. My goal is to acquire valuable knowledge and experiment with various types of projects to eventually become an expert in a specific domain or position, based on the skills and passions I develop along the way.
If you consider that my motivation and expertise make me a suitable candidate for this project, I am available for an interview with the selection committee. Thank you for your time and consideration.
Sincerely,
Braica Patricia Maria

reading content from C:\Users\Asus\Desktop\See\lisp.l

/* lisp.l - Analizor lexical pentru microinterpretorul Lisp */
%{
#include "y.tab.h"
%}

%%
\s+                 ; /* Ignoră spațiile albe */
\(                  return '(';
\)                  return ')';
CONS                return CONS;
CAR                 return CAR;
CDR                 return CDR;
APPEND              return APPEND;
[0-9]+              { yylval.ival = atoi(yytext); return NUMBER; }
\'\([0-9 ]+\)      { yylval.sval = strdup(yytext); return LIST; }
.                   ;
%%

int yywrap() { return 1; }



reading content from C:\Users\Asus\Desktop\See\lisp.y

/* lisp.y - Analizor sintactic pentru microinterpretorul Lisp */
%{
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

typedef struct list {
    int value;
    struct list *next;
} list;

list *cons(int val, list *lst) {
    list *node = (list *)malloc(sizeof(list));
    node->value = val;
    node->next = lst;
    return node;
}

int car(list *lst) { return lst ? lst->value : 0; }
list *cdr(list *lst) { return lst ? lst->next : NULL; }
list *append(list *l1, list *l2) {
    if (!l1) return l2;
    list *head = l1;
    while (l1->next) l1 = l1->next;
    l1->next = l2;
    return head;
}

void print_list(list *lst) {
    printf("(");
    while (lst) {
        printf("%d ", lst->value);
        lst = lst->next;
    }
    printf(")\n");
}
%}

%union {
    int ival;
    list *lst;
}

%token <ival> NUMBER
%token CONS CAR CDR APPEND
%type <lst> form i_form l_form enum

%%
form: i_form  { $$ = $1; print_list($$); }
    | l_form  { $$ = $1; print_list($$); }
    ;

i_form: '(' i_command ')' { $$ = $2; }
      | NUMBER { $$ = cons($1, NULL); }
      ;

l_form: '(' l_command ')' { $$ = $2; }
      | enum ')' { $$ = $1; }
      ;

i_command: CAR l_form { $$ = cons(car($2), NULL); }
         | '+' form i_form { $$ = cons(car($2) + car($3), NULL); }
         ;

l_command: CDR l_form { $$ = cdr($2); }
         | CONS i_form l_form { $$ = cons(car($2), $3); }
         | APPEND l_form l_form { $$ = append($2, $3); }
         ;

enum: NUMBER enum { $$ = cons($1, $2); }
     | NUMBER { $$ = cons($1, NULL); }
     ;

file: file form '\n' | file '\n' | /* empty */ ;
%%

int main() {
    yyparse();
    return 0;
}

void yyerror(const char *msg) {
    fprintf(stderr, "Error: %s\n", msg);
}


reading content from C:\Users\Asus\Desktop\See\Microsoft Office Word Tabele.pptx

Tabele,randuri, coloane definiție formală
Un tabel este o structură de date organizată în linii (rânduri) și coloane, utilizată pentru a stoca, aranja și prezenta informațiile într-un mod clar și accesibil.

Linie (sau rând) – reprezintă un set de date organizate pe orizontală într-un tabel. Fiecare linie conține informații despre o anumită entitate sau înregistrare.

Coloană – reprezintă un set de date organizate pe verticală într-un tabel. Fiecare coloană conține un anumit tip de informație pentru toate înregistrările (liniile) tabelului.




Microsoft Office Word
Tabele 
Citate de la experți:

“Folosirea tabelelor în Microsoft Word este ca și cum ai încerca să strunești niște pisici – tocmai când crezi că e perfect, ceva se schimbă.” 

“Tabelele din Microsoft Word sunt ca relațiile – complicate, imprevizibile și, uneori, trebuie să o iei de la capăt.”




Ce vom învăța azi?
Inserarea în tabel
Desenarea unui tabel
Lucru în tabel
Operații în tabel



Inserarea unui tabel
Ce metode știți voi?

Insert -> Table -> Insert table
Insert -> Table ->Selectam cu cursorul visual câte rânduri și câte coloane avem
Insert -> Table ->Draw Table (o experiență interesantă)


Prima modalitate



A doua modalitate



A treia modalitate

Despre butoanele de la Draw Table:
Eraser
Shading color
Line style
Line weight
Pen Color


Formatarea datelor din tabel




Sortarea și operațiile matematice




Operații în tabel- adaugarea de randuri si coloane, ștergerea din tabel




Desenarea unui tabel-Utilizarea stilurilor



Merging cells- Unirea celulelor

Cum se face atunci împărțirea celulelor? Dar a tabelelor?



Mențiuni și comenzi interesante


Dimensiunile coloanelor și a rândurilor(1)



Dimensiunile coloanelor și a rândurilor(2)




image1.png

image2.png

image3.png

image4.png

image5.png

image6.png

image7.png

image8.png

image9.png

image10.png

image11.png

image12.png

image13.png

image14.png

image15.png

image16.png



reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (1).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (1).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (2).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (2).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (3).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (3).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\20250320_091525.jpg

reading content from D:\SD\SearchEngine_ver1\Bee\20250320_091525.jpg

reading content from D:\SD\SearchEngine_ver1\Bee\cadenCV-master.zip

reading content from D:\SD\SearchEngine_ver1\Bee\cadenCV-master.zip

reading content from D:\SD\SearchEngine_ver1\Bee\CN lab english (1).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\CN lab english (1).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\CN3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\CN3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\CN4.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN4.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN6.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN6.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN7.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN7.docx

reading content from D:\SD\SearchEngine_ver1\Bee\Comisii burse 2024-2025.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Comisii burse 2024-2025.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\gradientDescent-Univariate.xlsx

reading content from D:\SD\SearchEngine_ver1\Bee\gradientDescent-Univariate.xlsx

reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-28-32.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-28-32.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-34-38.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-34-38.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 5 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 5 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 6 și 7 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 6 și 7 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 8 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 8 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Model_CV_ro 2v 4.doc

reading content from D:\SD\SearchEngine_ver1\Bee\Model_CV_ro 2v 4.doc

reading content from D:\SD\SearchEngine_ver1\Bee\morphological_op_images.zip

reading content from D:\SD\SearchEngine_ver1\Bee\morphological_op_images.zip

reading content from D:\SD\SearchEngine_ver1\Bee\RC3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\RC3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\search.jar

reading content from D:\SD\SearchEngine_ver1\Bee\search.jar

reading content from D:\SD\SearchEngine_ver1\Bee\seminarii_PL.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\seminarii_PL.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\TIC_IX_C12.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\TIC_IX_C12.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Tools and cables.doc

reading content from D:\SD\SearchEngine_ver1\Bee\Tools and cables.doc

reading content from D:\SD\SearchEngine_ver1\See\0_geografie_planificari_calendaristice_liceu_tehnologic_9.docx

reading content from D:\SD\SearchEngine_ver1\See\0_geografie_planificari_calendaristice_liceu_tehnologic_9.docx

reading content from D:\SD\SearchEngine_ver1\See\3_planificare_tic_9.xlsx

reading content from D:\SD\SearchEngine_ver1\See\3_planificare_tic_9.xlsx

reading content from D:\SD\SearchEngine_ver1\See\Adeverință.docx

reading content from D:\SD\SearchEngine_ver1\See\Adeverință.docx

reading content from D:\SD\SearchEngine_ver1\See\airline-safety.csv

reading content from D:\SD\SearchEngine_ver1\See\airline-safety.csv

reading content from D:\SD\SearchEngine_ver1\See\CHANGELOG.md

reading content from D:\SD\SearchEngine_ver1\See\CHANGELOG.md

reading content from D:\SD\SearchEngine_ver1\See\CN3a_2022.pdf

reading content from D:\SD\SearchEngine_ver1\See\CN3a_2022.pdf

reading content from D:\SD\SearchEngine_ver1\See\CN3b_2022.pdf

reading content from D:\SD\SearchEngine_ver1\See\CN3b_2022.pdf

reading content from D:\SD\SearchEngine_ver1\See\CVGenenral.pdf

reading content from D:\SD\SearchEngine_ver1\See\CVGenenral.pdf

reading content from D:\SD\SearchEngine_ver1\See\EY.txt

reading content from D:\SD\SearchEngine_ver1\See\EY.txt

reading content from D:\SD\SearchEngine_ver1\See\FileIndexRowMapper.java

reading content from D:\SD\SearchEngine_ver1\See\FileIndexRowMapper.java

reading content from D:\SD\SearchEngine_ver1\See\FileIndexService.java

reading content from D:\SD\SearchEngine_ver1\See\FileIndexService.java

reading content from D:\SD\SearchEngine_ver1\See\files_border_tracing.zip

reading content from D:\SD\SearchEngine_ver1\See\files_border_tracing.zip

reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele (1).docx

reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele (1).docx

reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele.docx

reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele.docx

reading content from D:\SD\SearchEngine_ver1\See\geometrical_features_images.zip

reading content from D:\SD\SearchEngine_ver1\See\geometrical_features_images.zip

reading content from D:\SD\SearchEngine_ver1\See\lab-05.zip

reading content from D:\SD\SearchEngine_ver1\See\lab-05.zip

reading content from D:\SD\SearchEngine_ver1\See\labeling_images.zip

reading content from D:\SD\SearchEngine_ver1\See\labeling_images.zip

reading content from D:\SD\SearchEngine_ver1\See\Letter of Intent.pdf

reading content from D:\SD\SearchEngine_ver1\See\Letter of Intent.pdf

reading content from D:\SD\SearchEngine_ver1\See\Letter of IntentEng.docx

reading content from D:\SD\SearchEngine_ver1\See\Letter of IntentEng.docx

reading content from D:\SD\SearchEngine_ver1\See\lisp.l

reading content from D:\SD\SearchEngine_ver1\See\lisp.l

reading content from D:\SD\SearchEngine_ver1\See\lisp.y

reading content from D:\SD\SearchEngine_ver1\See\lisp.y

reading content from D:\SD\SearchEngine_ver1\See\MHP Innovation Camp Oferta 2025.odt

reading content from D:\SD\SearchEngine_ver1\See\MHP Innovation Camp Oferta 2025.odt

reading content from D:\SD\SearchEngine_ver1\See\Microsoft Office Word Tabele.pptx

reading content from D:\SD\SearchEngine_ver1\See\Microsoft Office Word Tabele.pptx

reading content from D:\SD\SearchEngine_ver1\See\Orar sem 2 CTI 2024-2025.xlsx

reading content from D:\SD\SearchEngine_ver1\See\Orar sem 2 CTI 2024-2025.xlsx

reading content from D:\SD\SearchEngine_ver1\See\restaurant.csv

reading content from D:\SD\SearchEngine_ver1\See\restaurant.csv

reading content from D:\SD\SearchEngine_ver1\Bee\10005799.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\CN3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\CN4.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN6.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN7.docx

reading content from D:\SD\SearchEngine_ver1\Bee\gradientDescent-Univariate.xlsx

reading content from D:\SD\SearchEngine_ver1\Bee\gradientDescent-Univariate.xlsx

reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-34-38.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 5 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 6 și 7 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 8 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Model_CV_ro 2v 4.doc

reading content from D:\SD\SearchEngine_ver1\Bee\RC3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\search.jar

reading content from D:\SD\SearchEngine_ver1\Bee\search.jar

reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (1).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (1).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (2).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (2).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (3).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (3).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\CN3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\CN3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\CN4.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN4.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN6.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN6.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN7.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN7.docx

reading content from D:\SD\SearchEngine_ver1\Bee\Comisii burse 2024-2025.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Comisii burse 2024-2025.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\gradientDescent-Univariate.xlsx

reading content from D:\SD\SearchEngine_ver1\Bee\gradientDescent-Univariate.xlsx

reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-28-32.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-28-32.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-34-38.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-34-38.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 5 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 5 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 6 și 7 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 6 și 7 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 8 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 8 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Model_CV_ro 2v 4.doc

reading content from D:\SD\SearchEngine_ver1\Bee\Model_CV_ro 2v 4.doc

reading content from D:\SD\SearchEngine_ver1\Bee\morphological_op_images.zip

reading content from D:\SD\SearchEngine_ver1\Bee\morphological_op_images.zip

reading content from D:\SD\SearchEngine_ver1\Bee\RC3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\RC3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\search.jar

reading content from D:\SD\SearchEngine_ver1\Bee\search.jar

reading content from D:\SD\SearchEngine_ver1\Bee\10005799.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\CN3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\CN4.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN6.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN7.docx

reading content from D:\SD\SearchEngine_ver1\Bee\gradientDescent-Univariate.xlsx

reading content from D:\SD\SearchEngine_ver1\Bee\gradientDescent-Univariate.xlsx

reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-34-38.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 5 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 6 și 7 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 8 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Model_CV_ro 2v 4.doc

reading content from D:\SD\SearchEngine_ver1\Bee\RC3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\search.jar

reading content from D:\SD\SearchEngine_ver1\Bee\search.jar

reading content from D:\SD\SearchEngine_ver1\Bee\10005799.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\CN3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\CN4.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN6.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN7.docx

reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-34-38.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 5 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 6 și 7 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 8 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Model_CV_ro 2v 4.doc

reading content from D:\SD\SearchEngine_ver1\Bee\RC3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\10005799.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\CN3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\CN4.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN6.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN7.docx

reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-34-38.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 5 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 6 și 7 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 8 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Model_CV_ro 2v 4.doc

reading content from D:\SD\SearchEngine_ver1\Bee\RC3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\See\0_geografie_planificari_calendaristice_liceu_tehnologic_9.docx

reading content from D:\SD\SearchEngine_ver1\See\0_geografie_planificari_calendaristice_liceu_tehnologic_9.docx

reading content from D:\SD\SearchEngine_ver1\See\3_planificare_tic_9.xlsx

reading content from D:\SD\SearchEngine_ver1\See\3_planificare_tic_9.xlsx

reading content from D:\SD\SearchEngine_ver1\See\Adeverință.docx

reading content from D:\SD\SearchEngine_ver1\See\Adeverință.docx

reading content from D:\SD\SearchEngine_ver1\See\airline-safety.csv

reading content from D:\SD\SearchEngine_ver1\See\airline-safety.csv

reading content from D:\SD\SearchEngine_ver1\See\CHANGELOG.md

reading content from D:\SD\SearchEngine_ver1\See\CHANGELOG.md

reading content from D:\SD\SearchEngine_ver1\See\CN3a_2022.pdf

reading content from D:\SD\SearchEngine_ver1\See\CN3a_2022.pdf

reading content from D:\SD\SearchEngine_ver1\See\CN3b_2022.pdf

reading content from D:\SD\SearchEngine_ver1\See\CN3b_2022.pdf

reading content from D:\SD\SearchEngine_ver1\See\CVGenenral.pdf

reading content from D:\SD\SearchEngine_ver1\See\CVGenenral.pdf

reading content from D:\SD\SearchEngine_ver1\See\EY.txt

reading content from D:\SD\SearchEngine_ver1\See\EY.txt

reading content from D:\SD\SearchEngine_ver1\See\FileIndexRowMapper.java

reading content from D:\SD\SearchEngine_ver1\See\FileIndexRowMapper.java

reading content from D:\SD\SearchEngine_ver1\See\FileIndexService.java

reading content from D:\SD\SearchEngine_ver1\See\FileIndexService.java

reading content from D:\SD\SearchEngine_ver1\See\files_border_tracing.zip

reading content from D:\SD\SearchEngine_ver1\See\files_border_tracing.zip

reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele (1).docx

reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele (1).docx

reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele.docx

reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele.docx

reading content from D:\SD\SearchEngine_ver1\See\geometrical_features_images.zip

reading content from D:\SD\SearchEngine_ver1\See\geometrical_features_images.zip

reading content from D:\SD\SearchEngine_ver1\See\lab-05.zip

reading content from D:\SD\SearchEngine_ver1\See\lab-05.zip

reading content from D:\SD\SearchEngine_ver1\See\labeling_images.zip

reading content from D:\SD\SearchEngine_ver1\See\labeling_images.zip

reading content from D:\SD\SearchEngine_ver1\See\Letter of Intent.pdf

reading content from D:\SD\SearchEngine_ver1\See\Letter of Intent.pdf

reading content from D:\SD\SearchEngine_ver1\See\Letter of IntentEng.docx

reading content from D:\SD\SearchEngine_ver1\See\Letter of IntentEng.docx

reading content from D:\SD\SearchEngine_ver1\See\lisp.l

reading content from D:\SD\SearchEngine_ver1\See\lisp.l

reading content from D:\SD\SearchEngine_ver1\See\lisp.y

reading content from D:\SD\SearchEngine_ver1\See\lisp.y

reading content from D:\SD\SearchEngine_ver1\See\MHP Innovation Camp Oferta 2025.odt

reading content from D:\SD\SearchEngine_ver1\See\MHP Innovation Camp Oferta 2025.odt

reading content from D:\SD\SearchEngine_ver1\See\Microsoft Office Word Tabele.pptx

reading content from D:\SD\SearchEngine_ver1\See\Microsoft Office Word Tabele.pptx

reading content from D:\SD\SearchEngine_ver1\See\Orar sem 2 CTI 2024-2025.xlsx

reading content from D:\SD\SearchEngine_ver1\See\Orar sem 2 CTI 2024-2025.xlsx

reading content from D:\SD\SearchEngine_ver1\See\restaurant.csv

reading content from D:\SD\SearchEngine_ver1\See\restaurant.csv

reading content from D:\SD\SearchEngine_ver1\Bee\10005799.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\CN3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\CN4.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN6.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN7.docx

reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-34-38.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 5 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 6 și 7 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 8 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Model_CV_ro 2v 4.doc

reading content from D:\SD\SearchEngine_ver1\Bee\RC3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\See\0_geografie_planificari_calendaristice_liceu_tehnologic_9.docx

reading content from D:\SD\SearchEngine_ver1\See\Adeverință.docx

reading content from D:\SD\SearchEngine_ver1\See\CN3a_2022.pdf

reading content from D:\SD\SearchEngine_ver1\See\CN3b_2022.pdf

reading content from D:\SD\SearchEngine_ver1\See\CVGenenral.pdf

reading content from D:\SD\SearchEngine_ver1\See\EY.txt

reading content from D:\SD\SearchEngine_ver1\See\files_border_tracing.zip

reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele (1).docx

reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele.docx

reading content from D:\SD\SearchEngine_ver1\See\geometrical_features_images.zip

reading content from D:\SD\SearchEngine_ver1\See\lab-05.zip

reading content from D:\SD\SearchEngine_ver1\See\lab-05.zip

reading content from D:\SD\SearchEngine_ver1\See\Laborator 8 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\See\Laborator 8 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\See\Letter of Intent.pdf

reading content from D:\SD\SearchEngine_ver1\See\Letter of IntentEng.docx

reading content from D:\SD\SearchEngine_ver1\See\0_geografie_planificari_calendaristice_liceu_tehnologic_9.docx

reading content from D:\SD\SearchEngine_ver1\See\0_geografie_planificari_calendaristice_liceu_tehnologic_9.docx

reading content from D:\SD\SearchEngine_ver1\See\Adeverință.docx

reading content from D:\SD\SearchEngine_ver1\See\Adeverință.docx

reading content from D:\SD\SearchEngine_ver1\See\CHANGELOG.md

reading content from D:\SD\SearchEngine_ver1\See\CHANGELOG.md

reading content from D:\SD\SearchEngine_ver1\See\CN3a_2022.pdf

reading content from D:\SD\SearchEngine_ver1\See\CN3a_2022.pdf

reading content from D:\SD\SearchEngine_ver1\See\CN3b_2022.pdf

reading content from D:\SD\SearchEngine_ver1\See\CN3b_2022.pdf

reading content from D:\SD\SearchEngine_ver1\See\CVGenenral.pdf

reading content from D:\SD\SearchEngine_ver1\See\CVGenenral.pdf

reading content from D:\SD\SearchEngine_ver1\See\EY.txt

reading content from D:\SD\SearchEngine_ver1\See\EY.txt

reading content from D:\SD\SearchEngine_ver1\See\FileIndexRowMapper.java

reading content from D:\SD\SearchEngine_ver1\See\FileIndexRowMapper.java

reading content from D:\SD\SearchEngine_ver1\See\FileIndexService.java

reading content from D:\SD\SearchEngine_ver1\See\FileIndexService.java

reading content from D:\SD\SearchEngine_ver1\See\files_border_tracing.zip

reading content from D:\SD\SearchEngine_ver1\See\files_border_tracing.zip

reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele (1).docx

reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele (1).docx

reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele.docx

reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele.docx

reading content from D:\SD\SearchEngine_ver1\See\geometrical_features_images.zip

reading content from D:\SD\SearchEngine_ver1\See\geometrical_features_images.zip

reading content from D:\SD\SearchEngine_ver1\See\lab-05.zip

reading content from D:\SD\SearchEngine_ver1\See\lab-05.zip

reading content from D:\SD\SearchEngine_ver1\See\labeling_images.zip

reading content from D:\SD\SearchEngine_ver1\See\labeling_images.zip

reading content from D:\SD\SearchEngine_ver1\See\Laborator 8 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\See\Laborator 8 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\See\Letter of Intent.pdf

reading content from D:\SD\SearchEngine_ver1\See\Letter of Intent.pdf

reading content from D:\SD\SearchEngine_ver1\See\Letter of IntentEng.docx

reading content from D:\SD\SearchEngine_ver1\See\Letter of IntentEng.docx

reading content from D:\SD\SearchEngine_ver1\See\lisp.l

reading content from D:\SD\SearchEngine_ver1\See\lisp.l

reading content from D:\SD\SearchEngine_ver1\See\lisp.y

reading content from D:\SD\SearchEngine_ver1\See\lisp.y

reading content from D:\SD\SearchEngine_ver1\See\0_geografie_planificari_calendaristice_liceu_tehnologic_9.docx

reading content from D:\SD\SearchEngine_ver1\See\Adeverință.docx

reading content from D:\SD\SearchEngine_ver1\See\CN3a_2022.pdf

reading content from D:\SD\SearchEngine_ver1\See\CN3b_2022.pdf

reading content from D:\SD\SearchEngine_ver1\See\CVGenenral.pdf

reading content from D:\SD\SearchEngine_ver1\See\EY.txt

reading content from D:\SD\SearchEngine_ver1\See\files_border_tracing.zip

reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele (1).docx

reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele.docx

reading content from D:\SD\SearchEngine_ver1\See\geometrical_features_images.zip

reading content from D:\SD\SearchEngine_ver1\See\lab-05.zip

reading content from D:\SD\SearchEngine_ver1\See\lab-05.zip

reading content from D:\SD\SearchEngine_ver1\See\Laborator 8 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\See\Letter of Intent.pdf

reading content from D:\SD\SearchEngine_ver1\See\Letter of IntentEng.docx

reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (1).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (1).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (2).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (2).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (3).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (3).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\10005799.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\CN3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\CN3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\CN4.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN4.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN6.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN6.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN7.docx

reading content from D:\SD\SearchEngine_ver1\Bee\CN7.docx

reading content from D:\SD\SearchEngine_ver1\Bee\Comisii burse 2024-2025.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Comisii burse 2024-2025.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-28-32.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-28-32.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-34-38.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-34-38.pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 5 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 5 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 6 și 7 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 6 și 7 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 8 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 8 FLT (ro).pdf

reading content from D:\SD\SearchEngine_ver1\Bee\Model_CV_ro 2v 4.doc

reading content from D:\SD\SearchEngine_ver1\Bee\Model_CV_ro 2v 4.doc

reading content from D:\SD\SearchEngine_ver1\Bee\morphological_op_images.zip

reading content from D:\SD\SearchEngine_ver1\Bee\morphological_op_images.zip

reading content from D:\SD\SearchEngine_ver1\Bee\RC3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\RC3a_2022.doc

reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (1).pdf


 

 
Abstract—Music has always been an integral part of human’s 

daily lives. But, for the most people, reading musical score and turning 
it into melody is not easy. This study aims to develop an Automatic 
music score recognition system using digital image processing, which 
can be used to read and analyze musical score images automatically. 
The technical approaches included: (1) staff region segmentation; (2) 
image preprocessing; (3) note recognition; and (4) accidental and rest 
recognition. Digital image processing techniques (e.g., horizontal 
/vertical projections, connected component labeling, morphological 
processing, template matching, etc.) were applied according to 
musical notes, accidents, and rests in staff notations. Preliminary 
results showed that our system could achieve detection and 
recognition rates of 96.3% and 91.7%, respectively. In conclusion, we 
presented an effective automated musical score recognition system 
that could be integrated in a system with a media player to play 
music/songs given input images of musical score. Ultimately, this 
system could also be incorporated in applications for mobile devices as 
a learning tool, such that a music player could learn to play 
music/songs. 
 

Keywords—Connected component labeling, image processing, 
morphological processing, optical musical recognition.  

I. INTRODUCTION 

ITH the advance of image processing and computer 
vision techniques in recent years, the techniques have 

been integrated in human’s daily lives. Typical image 
processing and computer vision applications include document 
processing, smartphone applications, video surveillance 
systems, multimedia systems, and/or video games, etc.  

In image processing techniques, the Optical Character 
Recognition (OCR) is an important technique that has been 
widely used in handwriting inputs, license plate recognition, 
and augmented reality applications. The objective of the OCR 
technique is to allow the computer to analyze the text images, 
and then convert to texts (typically the ASCII codes) which 
computer can handle. For example, [1] proposed a method to 
calculate the appropriate threshold for converting gray-level 
images to binary images automatically. Casey and Lecolinet [2] 
proposed a character segmentation system based on connected 
component analysis and feature extraction, which were used to 
segment and recognize each character from document images. 

 
Yuan-Hsiang Chang, Ph.D. is with the Information and Computer 

Engineering Department, Chung-Yuan Christian University, Chung Li, Taiwan, 
R.O.C. (phone: 886-3-265-4713; fax: 886-3-265-4799; e-mail: author@ 
boulder.nist.gov).  

Zhong-Xian Peng, is a graduate student with the. Information and Computer 
Engineering Department, Chung-Yuan Christian University, Chung Li, Tawian, 
R.O.C 

Li-Der Jeng is with the Electronic Engineering Department, Chung-Yuan 
Christian University, Chung Li, Taiwan 

Liu et al. [3] proposed a handwritten character strings 
recognition system for address reading, in which characters 
were segmented using the connected component analysis. Each 
character was then recognized using a beam search algorithm 
and a character classifier. 

In addition to the OCR technique, pattern recognition 
techniques are also drawing attention of many researchers. 
Patterns (or symbols) are commonly seen in documents and/or 
other scenarios in which text information is not used for the 
representation (such as music notes, traffic signs, gestures, etc.). 
However, recognition of such patterns (or symbols) may 
require expertise to achieve effective representation and/or 
communication (e.g., music notes in a music score, etc.). 

Musical score is a form to record music by symbols which 
may include the pitch and tempo information about the music 
and/or songs. With the development of pattern recognition 
techniques, musical score recognition has also become a 
research topic lately. For example, [4] proposed a method to 
detect and remove staff lines using derivation and connected 
component analysis. Chen et al. [5] proposed a conventional 
architecture of Optical Music Recognition (OMR) using the 
staff-lines detection as the key stage. They explored two 
methods, namely the Hough transform and Mathematical 
Morphology, for detecting all staff-lines of an image. Dutta et 
al. [6] proposed a different method to detect and remove staff 
lines from musical documents. The methodology considered a 
staff line segment as a horizontal linkage of vertical black runs 
with uniform height. They also used the neighboring properties 
of a staff line segment to validate it as a true segment. Yoo et al. 
[7] proposed a system to recognize musical scores in low 
resolution images captured by the digital camera of a mobile 
phone. They presented a mask based approach to cope with 
incomplete information in the low resolution images. Toyama 
et al. [8] proposed a score recognition method which could be 
applicable to the complex music scores. Symbol candidates 
were detected by template matching, and then selected by 
considering the relative positions and mutual connections. 
Rossant and Bloch [9] proposed an optical music recognition 
system based on a fuzzy modeling of symbol classes and music 
writing rules. The objective was to disambiguate the 
recognition hypotheses output by the individual symbol 
analysis, followed by the fuzzy modeling to account for 
imprecision in symbol detection. Parker [10] implemented a 
complete optical music recognition system, called Lemon. 
Their system included the techniques, i.e., staff line detection, 
text segmentation, line detection, symbol recognition, note 
head recognition, and semantic interpretation. 

Automatic Music Score Recognition System Using 
Digital Image Processing 
Yuan-Hsiang Chang, Zhong-Xian Peng, Li-Der Jeng. 

W 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1811International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

II.  METHOD 

In this study, we present an “Automatic Music Score 
Recognition System Using Digital Image Processing”, which 
was aimed to automatically recognize musical scores.  

Several system hypotheses can be described as follows: 
 The musical score is a printed document (i.e., black 

musical notes or symbols in white background). 
 The musical score is a scanned document in an upright 

position, therefore no perspective distortions are observed. 
 The image is with sufficient resolution and in good quality. 

Fig. 1 shows the flow chart of our system. The processes 
include: Image Analysis and Segmentation, Image 
Preprocessing, Note recognition, and Accidental and Rest 
Recognition. 

 

Note Recognition

Stem Filtering

Size Filtering

Shape Filtering

Pitch And Beat Analysis

Output

Staff Region Segmentation

Binary Transform

Horizontal Projection

Region Segmentation

Image Preprocessing

Accidental and Rest Recognition

Note Removal

Template ImageTemplate Matching

Source
Image

Staff Line Filtering

Morphological Processing

Connected Component Labeling

 

Fig. 1 System flow chart of the Automatic Music Score Recognition 
System Using Digital Image Processing  

A. Staff Region Segmentation 

A page of musical score consist of number of row stave, with 
a top-down order when playing. A staff consists of five staff 
lines, while notes are recorded on staff lines with respect to the 
height of each line to determine its pitch. Therefore, the first 
step of our system was to segment sub-regions for each staff. 
The processes included: Binary Transform, Horizontal 
Projection, and Region Segmentation. 

Binary Transform was simply used to convert the input 
image to a binary image. In this study, the Otsu’s algorithm was 

used to find the optimal threshold T that minimizes the 
within-class variances. As a result, given an input image I and 
the threshold T, a binary image IB can be acquired using: 
 

   


 


otherwise

TyxIif
yxI B ,0

,,255
,

                    (1) 

 
Horizontal Projection: The image projection is a method for 

projecting source data to selected area to reduce the dimension 
of the source data, such that the data could be easily processed. 
Image projections can be implemented in either the horizontal 
or vertical directions, resulted in horizontal or vertical 
projections. Here, the horizontal projection was applied in our 
system to acquire the horizontally projection histogram as 
shown in Fig. 2. By projecting the musical score in Fig. 2 (a) 
horizontally, total number of pixels for each row could be 
determined in Fig. 2 (b). As shown, the five staff lines were 
associated with five obvious peak values in terms of number of 
pixels. 

 

 

(a) 
 

 

(b) 

Fig. 2 Binary musical score image and the corresponding horizontal 
projects 

 
Region Segmentation: The objective of the region 

segmentation was to identify and segment regions of stave from 
the original image such that each region of the staff could be 
processed independently.  

Based on the result given in Fig. 2, the staff line height HL, 
the staff line space SL, and the distribution of staff lines, could 
be obtained. An example is shown in Fig. 3. 

 

 

Fig. 3 An example of the staff line height HL and the staff line space SL. 
The height of the note head is approximately the same as the staff line 

space 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1812International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

According to the horizontal projections, the histogram 
represented the number of pixels for each row in the binary 
image. Because each staff contained exactly five horizontal 
staff lines, the peaks of the horizontal projections at the location 
of staff line represented the locations of the five staff lines. 
Therefore, the five staff lines could be obtained by 
back-projections of the five peaks in the histogram, such that 
the resulting image contains only the staff lines without any 
note heads (or other symbols). 

B. Image Preprocessing 

In image preprocessing, our objective was to extract or 
isolate the musical symbols to be independent regions from the 
staff by removing the staff lines in the image. However, during 
staff line removal processes, several musical notes (or other 
symbols) may be damaged if they are associated with weak 
structures (shapes). Therefore, our system incorporated the 
image preprocessing processes to retain the musical notes (or 
symbols), while removing the staff lines for further processes. 

Staff Line Filtering: In the musical score, musical symbols 
are recorded on the staff. As a result, musical symbols are 
connected with the staff lines in images. In this step, our 
objective was to retain the music notes (or symbols) in images, 
while removing the staff lines. After acquiring the Staff line 
space and height by horizontal projections, our system removed 
all the black pixels at each rows of staff lines. Because this 
process may damage the structure (shapes) of musical notes (or 
symbols), additional criterion was included. The staff line 
height HL was selected as the threshold and black pixels were 
removed only if the observed height was smaller than the staff 
line height. An example is shown in Fig. 4 (a). 

Morphological Processing: Although the aforementioned 
process was able to remove staff lines effectively, the structure 
(shapes) of the musical notes (or symbols) could be affected. 
The process of Morphological processing was used to retain the 
complete structure (shapes) of each musical note (or symbol). 

 

 

(a) 
 

 

(b) 

Fig. 4 An example of the image preprocessing: (a) result of staff line 
filtering; (b) result of morphological processing 

 
Closing processing is a technology of morphological 

processing that can be used to link the small gaps of structure 
and to improve the connectivity for regions in images. The 
morphological closing is defined by: 

 

EEIEI Θ)(                                 (2) 
 
where I is the input image and is E the structuring element. The 
image is first dilated (  is the dilation operation) and then 

eroded (Θ  is the erosion operation) with the structuring 
element. In our system, the morphological closing was applied, 
an example is shown in Fig. 4 (b). 

Connected Component Labeling: A region of connected 
pixels with an identical label was referred as a connected 
component. The objective of the connected component labeling 
was to assign a unique label to each connected component. An 
example is shown in Fig. 5. 

 

 

Fig. 5 An example of the connected component labeling is shown. 
After labeling, each connected component (region) is assigned a 

unique label 
 

Given a binary images with binary-1s (black pixels) and 
binary-0s (white pixels), we applied the connected component 
labeling to extract each connected component. Therefore, each 
musical notes (or symbols) could be identified and labeled. The 
seed filling algorithm for the connected component labeling is 
given by: 
1) Search each pixel in the image until the value of the current 

pixel P with the binary-1 value and has not been labeled 
yet; 

2) Select P as the seed pixel and assign a label L to P, then 
check each pixel that is adjacent to the seed pixel; 

3) If there is a pixel Q with the binary-1 value that is adjacent 
to the seed pixel, return to step 2 until there is no pixels 
with the binary-1 is found; 

4) Update the label and return to step 1 until all pixels in the 
image have been checked. 

C. Note Recognition 

Once the connected regions for the musical notes (or 
symbols) were identified and labeled, the final step was to 
recognize them. In our system, the processes were divided into 
two major recognition phases: (1) Note recognition; and (2) 
Accidental and rest recognition. 

In staff notations, a musical note can be split into three parts 
according to its structure: head, stem and tail, as shown in Fig. 6. 
The head (e.g., solid or not) is mainly used to determine the 
pitch by its position with respect to the staff lines; the tails is 
mainly used to determine the beat; the stem is used to connect 
both the head and the tail. Our system was designed to detect 
the note heads first, followed by the detection of stems and tails.  

Stem Filtering: A stem is used to connect the head and the 
tail in a musical note. With the different position of a musical 
note, the stem is either extended upward or downward form the 
head. In addition, a whole note has no stems. Because of the 
variety in structures (shapes), recognition of musical note could 
be difficult. To simplify the task, the Stem filtering was 
designed to remove stems for the musical notes, while retaining 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1813International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

the structure of the note heads. 
 

 

Fig. 6 An example of a typical musical note (i.e., eighth note): The 
structure consists of head, stem and tail 

 
In this step, vertical projections were applied and the 

histogram was acquired to determine the approximated location 
of each musical note. During vertical projections, peaks in the 
histogram were related to the location of the stems, despite 
there are different types of musical notes (e.g., 4th or 8th notes, 
etc.). Therefore, stems of each musical notes could be filtered 
(removed). 

Size Filtering: Although there are differences in 
representing musical notes by different publishers, the height of 
the note heads is generally the same as the staff line space. 
Therefore, the staff line space SL was used as the threshold to 
determine if a connected region actually represents the head of 
a musical note. 

Shape Filtering: The head of a musical note is generally an 
oval shape which is symmetrical with respect to its center. Here, 
we detected note heads by calculating the rate of symmetric for 
each connected component. 

In a symmetric connected component L, for any point P∈L, 
there exists a point PS ∈	L	such	that	P - PC = PC - PS, where PC 

is the center of the connected component L, as defined by: 
 

SCCS PPPPPLP  :!,                   (3) 

 
According to the equation, the rate of symmetry R can be 

obtained for each connected component, as given by (4) 
 

A

S

Sum

Sum
R                                       (4) 

 
where Sums is the total number of the symmetric pixels and 
SumA is the total number of all the pixels in the connected 
component. Using the rate of symmetry, we could therefore 
remove all the regions that were not likely to be the heads of 
musical notes. An example is shown in Fig. 7. 

 

 

Fig. 7 An example of the note recognition, in which all the heads of the 
musical notes are marked  

 
Pitch and Beat Analysis: The pitch of the musical note is 

defined by its position with respect to the staff lines. The 
difference of pitches among musical notes is based on the scale 
as a basic unit, and the distance of each scale is with half height 
of the staff line space. Hence, we defined the pitch of each note 
by calculating the distance between musical notes and the 
datum line. The datum line was defined as the position of the 
keynote, i.e., the position of middle C. 

 

Whole/Half  Note ?

Have Stem?

How Many Tails?

Yes

No

Whole Note

Half Note

Quarter Note

Eighth Note

Sixteenth Note

No

Yes

0

1

2

Input

 
Fig. 8 The classifier for the beat of a musical note: Each musical note can thus be classified based on the properties if the stem/tails exist 

 
The beat of a musical note represents the length of the note 

being played, and each note has its own beat. The beat of a 
musical note is represented by three parts: (1) The note is solid 

or not; (2) The note has a stem or not; and (3) How many tails 
do the note have. Based on these properties, our system 
incorporated a classifier for the beat of a musical note, as shown 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1814International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

in Fig. 8. Furthermore, a dot is often used to adjust the beat for 
the musical notes. The dot is meant to increase the beat of the 
musical note by half of its original beat. For example, a note 
with two beats will become three beats. The symbol of a dot in a 
music score is a round black spot, and is generally marked at 
the right side of the note head. The size of dots is smaller than 
the half size of heads and is disconnected with other symbols. 
Based on the dot property as described, our system was 
designed to incorporate additional process for the process of 
recognizing the dot associated with a note head. 

D.  Accidental and Rest Recognition 

Accidentals are the musical symbols used to modify the pitch 
of a musical note. The most common accidentals can be 
described as follow: (1) the sharp is used to raise the pitch of a 
musical note by a semitone; (2) the flat is used to reduce the 
pitch of a musical notes by a semitone; and (3) the natural is 
used to recover the pitch of a musical note to its natural key. 
The accidentals are typically recorded in two ways: (1) marked 
at the start of a staff represent a key signature; and (2) marked at 
the left of a note to adjust the pitch of the musical note.  

Rests are the musical symbols used to represent the pauses in 
music/song. Unlike musical notes, rests have no pitches so that 
the height of rests in a score is fixed. However, shapes of rests 
with different beats are relatively irregular than musical notes. 

To identify the accidentals and/or rests, the technique of 
template matching is used in our system. The technique was 
used to compare an unknown symbol with respect to known 
template images (i.e., template images for possible accidentals 
and/or rests) in the database to recognize the symbol. In our 
system, once a region (sub-image) containing a symbol was 
detected, the region (sub-image) was then normalized to the 
same size with the template image and the logical XOR 
operation was applied: 
 

     


 


otherwise

yxIyxIif
yxI CT

XOR ,255

,,,0
,           (5) 

 
where IT represent the template image, IC represent the 
sub-image containing a symbol, and IXOR represent the result 
image after the exclusive-OR operation. An example is shown 
in Fig. 9. 

 

 

(a) 

 

(b) 

 

(c) 

Fig. 9 An example of the template matching for the rest recognition: 
(a) sub-image of an unknown symbol; (b) template image of the 

crotchet rest; (c) resulting image after the exclusion-OR operation 
 
Fig. 10 shows an example for the recognition of accidentals 

and rests in a musical score. Using the template matching, our 
system was able to identify the accidentals and rests. However, 

our system failed to detect the sharp symbol which is connected 
with the tail of a musical note. 

 

 

(a) 
 

 

(b) 

Fig. 10 An example of the accidental and rest recognition: (a) input 
image; (b) result of the recognition. There is a sharp that is connected 
with the tail of a musical note, resulting in a recognition failure in our 

system  

III. RESULTS 

In this section, we present the research environment and 
recognition results using our system in several musical score 
images. 

A. Research Environment 

The system development was based on a personal computer: 
Pentium(R) Dual-Core E5200 2.5GHz with 2GB memory, and 
Microsoft Windows 7 operating system. The system software 
was developed using the Microsoft Visual Studio C/C++ 2010 
and the Intel Open Source Computer Vision Library (OpenCV) 
Version 2.4.8.  

To evaluate our system performance, a set of digital images 
with musical scores of various complexities were collected 
from the Internet.  

B. Result of Musical Score Recognition 

Table I summarizes the results of musical symbol detection 
and recognition of our system using five images of musical 
scores. The detection rate was evaluated with the probability 
when musical notes or symbols (including accidentals and rests) 
were correctly detected. Then, based on the detected notes or 
symbols, the recognition rate was evaluated with the 
probability when the musical notes or symbols were correctly 
recognized. 

 
TABLE I 

THE RESULTS OF MUSICAL SYMBOL DETECTION AND RECOGNITION 

 Detection Recognition 

 Detected / Total Rate Recognized / Detected Rate 

Image 1 42 / 42 100% 42 / 42 100(%) 

Image 2 62 / 62 100% 62 / 62 100(%) 

Image 3 74(1) / 74 97.3% 64 / 74 86.4(%) 

Image 4 85(4) / 88 87.5% 65 / 85 76.5(%) 

Image 5 89(1) / 92 96.7% 85 / 89 95.5(%) 

Total 382(6) / 388 96.3% 318 / 382 91.7(%) 

 
Recognition results of our system are shown in the following. 

Fig. 11 shows the recognition results for the musical score 
Twinkle, Twinkle, Little Star. All the musical notes, including 
the pitches and beats, were successfully detected and 
recognized. The detected musical notes are marked 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1815International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

accordingly. 
 

 

Fig. 11 Recognition results of the musical score Twinkle, Twinkle, 
Little Star 

 
Fig. 12 shows the recognition results for the musical score 

The Swallow. Although the musical score was more 
complicated, all the musical notes, including the pitches and 
beats, were successfully detected and recognized.  

 

 

Fig. 12 Recognition results of the musical score The Swallow 
 

Fig. 13 shows the recognition results for the musical score I 
Will Sing You. The original image was in JPEG compressed 
format. All the musical notes, accidentals, and rests were 
successfully detected and recognized, despite there was a few 
errors in the recognition of the pitches. 

 

 

Fig. 13 Recognition results of the musical score I Will Sing You 

Fig. 14 shows the recognition results for the musical score At 
This Moment. The quality was relatively poor mainly because 
of compression distortion. The recognition results were 
relatively worse than previous scores. 

 

 

Fig. 14 Recognition results of the musical score At This Moment 
 

Fig. 15 shows the recognition results for the musical score 
My Herd. The quality was also relatively poor mainly because 
of compression distortion. The recognition results were 
relatively worse than previous scores especially in beat 
recognition (most recognition failure occurred at dots).  

 

 

Fig. 15 Recognition results of the musical score My Herd 

IV. CONCLUSION 

In this study, we proposed an Automatic Music Score 
Recognition System Using Digital Image Processing. The 
technical approaches included: staff region segmentation, 
image preprocessing, note recognition and accidental and rest 
recognition. Our system was developed to automatically detect 
and recognize musical notes, accidentals and rests in printed 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1816International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

musical scores.  
The results showed that the detection and the recognition 

rates of our system were 96.3% and 91.7%, respectively. While 
the results were limited and could be affected by image quality, 
our system was shown to achieve effective detection and 
recognition for musical symbols, such as notes, accidentals, and 
rests. Ultimately, our system could be incorporated with a 
media player that could play music/songs with inputs of 
musical scores.  

While our system has been demonstrated with success for 
different types of musical scores, our system was still limited 
with respect to the complexities of some musical scores (e.g., 
chords or other complex symbols). Improvement of our 
systems is still required for such musical scores. 

At present, our system was evaluated using personal 
computers with inputs of digital images. The system could be 
further integrated in applications for smart-phones or other 
mobile devices with built-in digital cameras. In addition, this 
system could be also used as a learning tool for players (e.g., 
piano players, guitar players, etc.) to play the music/songs even 
though they may not be familiar with the music/songs. 

REFERENCES  
[1] N. Otsu, “A Threshold Selection Method form Gray-Level Histograms,” 

IEEE Transactions on Systems, pp. 62-66, 1979. 
[2] R.G. Casey and E. Lecolinet, “A Survey of Methods and Strategies in 

Character Segmentation,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, pp. 690-706, 1996. 

[3] Cheng-Lin Liu, M. Koga and H. Fujisawa, “Lexicon-Driven 
Segmentation and Recognition of Handwritten Character Strings for 
Japanese Address Reading,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, pp. 1425-1437, 2002. 

[4] M. Sotoodeh and F. Tajeripour, “Staff Detection and Removal Using 
Derivation and Connected Component Analysis,” IEEE 16th CSI 
International Symposium on Artificial Intelligence and Signal Processing 
(AISP), pp. 54-57, 2012. 

[5] Chen Genfang, Zhang Liyin, Zhang Wenjun and Wang Qiuqiu, 
“Detecting the Staff-lines of Musical Score with Hough Transform and 
Mathematical Morphology,” IEEE International Conference on 
Multimedia Technology (ICMT) , pp. 1-4, 2010. 

[6] A. Dutta, U. Pal, A. Fornes and J. Llados, “An Efficient Staff Removal 
Approach from Printed Musical Documents,” IEEE International 
Conference on Pattern Recognition (ICPR), pp.1965-1968, 2010. 

[7] JaeMyeong Yoo, GiHong Kim and Gueesang Lee, “Mask Matching for 
Low Resolution Musical Note Recognition,” IEEE International 
Symposium on Signal Processing and Information Technology, pp. 
223-226, 2008. 

[8] F.Toyama, K. Shioji and J. Miyamichi, “Symbol Recognition of Printed 
Piano Scores with Touching Symbols,” Pattern Recognition, ICPR 18th 

International Conference, pp. 480-483, 2006. 
[9] F.Rossant and I. Bloch, “Optical Music Recognition Based on a Fuzzy 

Modeling of Symbol Classes and Music Writing Rules,” Pattern 
Recognition Letters, vol.23, pp. 1129-1141, 2002. 

[10] K.T. Reed and J.R.Parker, “Automatic Computer Recognition of Printed 
Music,” in Proceedings of the ICPR, pp.803-807, 1996. 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1817International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (2).pdf


 

 
Abstract—Music has always been an integral part of human’s 

daily lives. But, for the most people, reading musical score and turning 
it into melody is not easy. This study aims to develop an Automatic 
music score recognition system using digital image processing, which 
can be used to read and analyze musical score images automatically. 
The technical approaches included: (1) staff region segmentation; (2) 
image preprocessing; (3) note recognition; and (4) accidental and rest 
recognition. Digital image processing techniques (e.g., horizontal 
/vertical projections, connected component labeling, morphological 
processing, template matching, etc.) were applied according to 
musical notes, accidents, and rests in staff notations. Preliminary 
results showed that our system could achieve detection and 
recognition rates of 96.3% and 91.7%, respectively. In conclusion, we 
presented an effective automated musical score recognition system 
that could be integrated in a system with a media player to play 
music/songs given input images of musical score. Ultimately, this 
system could also be incorporated in applications for mobile devices as 
a learning tool, such that a music player could learn to play 
music/songs. 
 

Keywords—Connected component labeling, image processing, 
morphological processing, optical musical recognition.  

I. INTRODUCTION 

ITH the advance of image processing and computer 
vision techniques in recent years, the techniques have 

been integrated in human’s daily lives. Typical image 
processing and computer vision applications include document 
processing, smartphone applications, video surveillance 
systems, multimedia systems, and/or video games, etc.  

In image processing techniques, the Optical Character 
Recognition (OCR) is an important technique that has been 
widely used in handwriting inputs, license plate recognition, 
and augmented reality applications. The objective of the OCR 
technique is to allow the computer to analyze the text images, 
and then convert to texts (typically the ASCII codes) which 
computer can handle. For example, [1] proposed a method to 
calculate the appropriate threshold for converting gray-level 
images to binary images automatically. Casey and Lecolinet [2] 
proposed a character segmentation system based on connected 
component analysis and feature extraction, which were used to 
segment and recognize each character from document images. 

 
Yuan-Hsiang Chang, Ph.D. is with the Information and Computer 

Engineering Department, Chung-Yuan Christian University, Chung Li, Taiwan, 
R.O.C. (phone: 886-3-265-4713; fax: 886-3-265-4799; e-mail: author@ 
boulder.nist.gov).  

Zhong-Xian Peng, is a graduate student with the. Information and Computer 
Engineering Department, Chung-Yuan Christian University, Chung Li, Tawian, 
R.O.C 

Li-Der Jeng is with the Electronic Engineering Department, Chung-Yuan 
Christian University, Chung Li, Taiwan 

Liu et al. [3] proposed a handwritten character strings 
recognition system for address reading, in which characters 
were segmented using the connected component analysis. Each 
character was then recognized using a beam search algorithm 
and a character classifier. 

In addition to the OCR technique, pattern recognition 
techniques are also drawing attention of many researchers. 
Patterns (or symbols) are commonly seen in documents and/or 
other scenarios in which text information is not used for the 
representation (such as music notes, traffic signs, gestures, etc.). 
However, recognition of such patterns (or symbols) may 
require expertise to achieve effective representation and/or 
communication (e.g., music notes in a music score, etc.). 

Musical score is a form to record music by symbols which 
may include the pitch and tempo information about the music 
and/or songs. With the development of pattern recognition 
techniques, musical score recognition has also become a 
research topic lately. For example, [4] proposed a method to 
detect and remove staff lines using derivation and connected 
component analysis. Chen et al. [5] proposed a conventional 
architecture of Optical Music Recognition (OMR) using the 
staff-lines detection as the key stage. They explored two 
methods, namely the Hough transform and Mathematical 
Morphology, for detecting all staff-lines of an image. Dutta et 
al. [6] proposed a different method to detect and remove staff 
lines from musical documents. The methodology considered a 
staff line segment as a horizontal linkage of vertical black runs 
with uniform height. They also used the neighboring properties 
of a staff line segment to validate it as a true segment. Yoo et al. 
[7] proposed a system to recognize musical scores in low 
resolution images captured by the digital camera of a mobile 
phone. They presented a mask based approach to cope with 
incomplete information in the low resolution images. Toyama 
et al. [8] proposed a score recognition method which could be 
applicable to the complex music scores. Symbol candidates 
were detected by template matching, and then selected by 
considering the relative positions and mutual connections. 
Rossant and Bloch [9] proposed an optical music recognition 
system based on a fuzzy modeling of symbol classes and music 
writing rules. The objective was to disambiguate the 
recognition hypotheses output by the individual symbol 
analysis, followed by the fuzzy modeling to account for 
imprecision in symbol detection. Parker [10] implemented a 
complete optical music recognition system, called Lemon. 
Their system included the techniques, i.e., staff line detection, 
text segmentation, line detection, symbol recognition, note 
head recognition, and semantic interpretation. 

Automatic Music Score Recognition System Using 
Digital Image Processing 
Yuan-Hsiang Chang, Zhong-Xian Peng, Li-Der Jeng. 

W 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1811International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

II.  METHOD 

In this study, we present an “Automatic Music Score 
Recognition System Using Digital Image Processing”, which 
was aimed to automatically recognize musical scores.  

Several system hypotheses can be described as follows: 
 The musical score is a printed document (i.e., black 

musical notes or symbols in white background). 
 The musical score is a scanned document in an upright 

position, therefore no perspective distortions are observed. 
 The image is with sufficient resolution and in good quality. 

Fig. 1 shows the flow chart of our system. The processes 
include: Image Analysis and Segmentation, Image 
Preprocessing, Note recognition, and Accidental and Rest 
Recognition. 

 

Note Recognition

Stem Filtering

Size Filtering

Shape Filtering

Pitch And Beat Analysis

Output

Staff Region Segmentation

Binary Transform

Horizontal Projection

Region Segmentation

Image Preprocessing

Accidental and Rest Recognition

Note Removal

Template ImageTemplate Matching

Source
Image

Staff Line Filtering

Morphological Processing

Connected Component Labeling

 

Fig. 1 System flow chart of the Automatic Music Score Recognition 
System Using Digital Image Processing  

A. Staff Region Segmentation 

A page of musical score consist of number of row stave, with 
a top-down order when playing. A staff consists of five staff 
lines, while notes are recorded on staff lines with respect to the 
height of each line to determine its pitch. Therefore, the first 
step of our system was to segment sub-regions for each staff. 
The processes included: Binary Transform, Horizontal 
Projection, and Region Segmentation. 

Binary Transform was simply used to convert the input 
image to a binary image. In this study, the Otsu’s algorithm was 

used to find the optimal threshold T that minimizes the 
within-class variances. As a result, given an input image I and 
the threshold T, a binary image IB can be acquired using: 
 

   


 


otherwise

TyxIif
yxI B ,0

,,255
,

                    (1) 

 
Horizontal Projection: The image projection is a method for 

projecting source data to selected area to reduce the dimension 
of the source data, such that the data could be easily processed. 
Image projections can be implemented in either the horizontal 
or vertical directions, resulted in horizontal or vertical 
projections. Here, the horizontal projection was applied in our 
system to acquire the horizontally projection histogram as 
shown in Fig. 2. By projecting the musical score in Fig. 2 (a) 
horizontally, total number of pixels for each row could be 
determined in Fig. 2 (b). As shown, the five staff lines were 
associated with five obvious peak values in terms of number of 
pixels. 

 

 

(a) 
 

 

(b) 

Fig. 2 Binary musical score image and the corresponding horizontal 
projects 

 
Region Segmentation: The objective of the region 

segmentation was to identify and segment regions of stave from 
the original image such that each region of the staff could be 
processed independently.  

Based on the result given in Fig. 2, the staff line height HL, 
the staff line space SL, and the distribution of staff lines, could 
be obtained. An example is shown in Fig. 3. 

 

 

Fig. 3 An example of the staff line height HL and the staff line space SL. 
The height of the note head is approximately the same as the staff line 

space 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1812International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

According to the horizontal projections, the histogram 
represented the number of pixels for each row in the binary 
image. Because each staff contained exactly five horizontal 
staff lines, the peaks of the horizontal projections at the location 
of staff line represented the locations of the five staff lines. 
Therefore, the five staff lines could be obtained by 
back-projections of the five peaks in the histogram, such that 
the resulting image contains only the staff lines without any 
note heads (or other symbols). 

B. Image Preprocessing 

In image preprocessing, our objective was to extract or 
isolate the musical symbols to be independent regions from the 
staff by removing the staff lines in the image. However, during 
staff line removal processes, several musical notes (or other 
symbols) may be damaged if they are associated with weak 
structures (shapes). Therefore, our system incorporated the 
image preprocessing processes to retain the musical notes (or 
symbols), while removing the staff lines for further processes. 

Staff Line Filtering: In the musical score, musical symbols 
are recorded on the staff. As a result, musical symbols are 
connected with the staff lines in images. In this step, our 
objective was to retain the music notes (or symbols) in images, 
while removing the staff lines. After acquiring the Staff line 
space and height by horizontal projections, our system removed 
all the black pixels at each rows of staff lines. Because this 
process may damage the structure (shapes) of musical notes (or 
symbols), additional criterion was included. The staff line 
height HL was selected as the threshold and black pixels were 
removed only if the observed height was smaller than the staff 
line height. An example is shown in Fig. 4 (a). 

Morphological Processing: Although the aforementioned 
process was able to remove staff lines effectively, the structure 
(shapes) of the musical notes (or symbols) could be affected. 
The process of Morphological processing was used to retain the 
complete structure (shapes) of each musical note (or symbol). 

 

 

(a) 
 

 

(b) 

Fig. 4 An example of the image preprocessing: (a) result of staff line 
filtering; (b) result of morphological processing 

 
Closing processing is a technology of morphological 

processing that can be used to link the small gaps of structure 
and to improve the connectivity for regions in images. The 
morphological closing is defined by: 

 

EEIEI Θ)(                                 (2) 
 
where I is the input image and is E the structuring element. The 
image is first dilated (  is the dilation operation) and then 

eroded (Θ  is the erosion operation) with the structuring 
element. In our system, the morphological closing was applied, 
an example is shown in Fig. 4 (b). 

Connected Component Labeling: A region of connected 
pixels with an identical label was referred as a connected 
component. The objective of the connected component labeling 
was to assign a unique label to each connected component. An 
example is shown in Fig. 5. 

 

 

Fig. 5 An example of the connected component labeling is shown. 
After labeling, each connected component (region) is assigned a 

unique label 
 

Given a binary images with binary-1s (black pixels) and 
binary-0s (white pixels), we applied the connected component 
labeling to extract each connected component. Therefore, each 
musical notes (or symbols) could be identified and labeled. The 
seed filling algorithm for the connected component labeling is 
given by: 
1) Search each pixel in the image until the value of the current 

pixel P with the binary-1 value and has not been labeled 
yet; 

2) Select P as the seed pixel and assign a label L to P, then 
check each pixel that is adjacent to the seed pixel; 

3) If there is a pixel Q with the binary-1 value that is adjacent 
to the seed pixel, return to step 2 until there is no pixels 
with the binary-1 is found; 

4) Update the label and return to step 1 until all pixels in the 
image have been checked. 

C. Note Recognition 

Once the connected regions for the musical notes (or 
symbols) were identified and labeled, the final step was to 
recognize them. In our system, the processes were divided into 
two major recognition phases: (1) Note recognition; and (2) 
Accidental and rest recognition. 

In staff notations, a musical note can be split into three parts 
according to its structure: head, stem and tail, as shown in Fig. 6. 
The head (e.g., solid or not) is mainly used to determine the 
pitch by its position with respect to the staff lines; the tails is 
mainly used to determine the beat; the stem is used to connect 
both the head and the tail. Our system was designed to detect 
the note heads first, followed by the detection of stems and tails.  

Stem Filtering: A stem is used to connect the head and the 
tail in a musical note. With the different position of a musical 
note, the stem is either extended upward or downward form the 
head. In addition, a whole note has no stems. Because of the 
variety in structures (shapes), recognition of musical note could 
be difficult. To simplify the task, the Stem filtering was 
designed to remove stems for the musical notes, while retaining 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1813International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

the structure of the note heads. 
 

 

Fig. 6 An example of a typical musical note (i.e., eighth note): The 
structure consists of head, stem and tail 

 
In this step, vertical projections were applied and the 

histogram was acquired to determine the approximated location 
of each musical note. During vertical projections, peaks in the 
histogram were related to the location of the stems, despite 
there are different types of musical notes (e.g., 4th or 8th notes, 
etc.). Therefore, stems of each musical notes could be filtered 
(removed). 

Size Filtering: Although there are differences in 
representing musical notes by different publishers, the height of 
the note heads is generally the same as the staff line space. 
Therefore, the staff line space SL was used as the threshold to 
determine if a connected region actually represents the head of 
a musical note. 

Shape Filtering: The head of a musical note is generally an 
oval shape which is symmetrical with respect to its center. Here, 
we detected note heads by calculating the rate of symmetric for 
each connected component. 

In a symmetric connected component L, for any point P∈L, 
there exists a point PS ∈	L	such	that	P - PC = PC - PS, where PC 

is the center of the connected component L, as defined by: 
 

SCCS PPPPPLP  :!,                   (3) 

 
According to the equation, the rate of symmetry R can be 

obtained for each connected component, as given by (4) 
 

A

S

Sum

Sum
R                                       (4) 

 
where Sums is the total number of the symmetric pixels and 
SumA is the total number of all the pixels in the connected 
component. Using the rate of symmetry, we could therefore 
remove all the regions that were not likely to be the heads of 
musical notes. An example is shown in Fig. 7. 

 

 

Fig. 7 An example of the note recognition, in which all the heads of the 
musical notes are marked  

 
Pitch and Beat Analysis: The pitch of the musical note is 

defined by its position with respect to the staff lines. The 
difference of pitches among musical notes is based on the scale 
as a basic unit, and the distance of each scale is with half height 
of the staff line space. Hence, we defined the pitch of each note 
by calculating the distance between musical notes and the 
datum line. The datum line was defined as the position of the 
keynote, i.e., the position of middle C. 

 

Whole/Half  Note ?

Have Stem?

How Many Tails?

Yes

No

Whole Note

Half Note

Quarter Note

Eighth Note

Sixteenth Note

No

Yes

0

1

2

Input

 
Fig. 8 The classifier for the beat of a musical note: Each musical note can thus be classified based on the properties if the stem/tails exist 

 
The beat of a musical note represents the length of the note 

being played, and each note has its own beat. The beat of a 
musical note is represented by three parts: (1) The note is solid 

or not; (2) The note has a stem or not; and (3) How many tails 
do the note have. Based on these properties, our system 
incorporated a classifier for the beat of a musical note, as shown 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1814International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

in Fig. 8. Furthermore, a dot is often used to adjust the beat for 
the musical notes. The dot is meant to increase the beat of the 
musical note by half of its original beat. For example, a note 
with two beats will become three beats. The symbol of a dot in a 
music score is a round black spot, and is generally marked at 
the right side of the note head. The size of dots is smaller than 
the half size of heads and is disconnected with other symbols. 
Based on the dot property as described, our system was 
designed to incorporate additional process for the process of 
recognizing the dot associated with a note head. 

D.  Accidental and Rest Recognition 

Accidentals are the musical symbols used to modify the pitch 
of a musical note. The most common accidentals can be 
described as follow: (1) the sharp is used to raise the pitch of a 
musical note by a semitone; (2) the flat is used to reduce the 
pitch of a musical notes by a semitone; and (3) the natural is 
used to recover the pitch of a musical note to its natural key. 
The accidentals are typically recorded in two ways: (1) marked 
at the start of a staff represent a key signature; and (2) marked at 
the left of a note to adjust the pitch of the musical note.  

Rests are the musical symbols used to represent the pauses in 
music/song. Unlike musical notes, rests have no pitches so that 
the height of rests in a score is fixed. However, shapes of rests 
with different beats are relatively irregular than musical notes. 

To identify the accidentals and/or rests, the technique of 
template matching is used in our system. The technique was 
used to compare an unknown symbol with respect to known 
template images (i.e., template images for possible accidentals 
and/or rests) in the database to recognize the symbol. In our 
system, once a region (sub-image) containing a symbol was 
detected, the region (sub-image) was then normalized to the 
same size with the template image and the logical XOR 
operation was applied: 
 

     


 


otherwise

yxIyxIif
yxI CT

XOR ,255

,,,0
,           (5) 

 
where IT represent the template image, IC represent the 
sub-image containing a symbol, and IXOR represent the result 
image after the exclusive-OR operation. An example is shown 
in Fig. 9. 

 

 

(a) 

 

(b) 

 

(c) 

Fig. 9 An example of the template matching for the rest recognition: 
(a) sub-image of an unknown symbol; (b) template image of the 

crotchet rest; (c) resulting image after the exclusion-OR operation 
 
Fig. 10 shows an example for the recognition of accidentals 

and rests in a musical score. Using the template matching, our 
system was able to identify the accidentals and rests. However, 

our system failed to detect the sharp symbol which is connected 
with the tail of a musical note. 

 

 

(a) 
 

 

(b) 

Fig. 10 An example of the accidental and rest recognition: (a) input 
image; (b) result of the recognition. There is a sharp that is connected 
with the tail of a musical note, resulting in a recognition failure in our 

system  

III. RESULTS 

In this section, we present the research environment and 
recognition results using our system in several musical score 
images. 

A. Research Environment 

The system development was based on a personal computer: 
Pentium(R) Dual-Core E5200 2.5GHz with 2GB memory, and 
Microsoft Windows 7 operating system. The system software 
was developed using the Microsoft Visual Studio C/C++ 2010 
and the Intel Open Source Computer Vision Library (OpenCV) 
Version 2.4.8.  

To evaluate our system performance, a set of digital images 
with musical scores of various complexities were collected 
from the Internet.  

B. Result of Musical Score Recognition 

Table I summarizes the results of musical symbol detection 
and recognition of our system using five images of musical 
scores. The detection rate was evaluated with the probability 
when musical notes or symbols (including accidentals and rests) 
were correctly detected. Then, based on the detected notes or 
symbols, the recognition rate was evaluated with the 
probability when the musical notes or symbols were correctly 
recognized. 

 
TABLE I 

THE RESULTS OF MUSICAL SYMBOL DETECTION AND RECOGNITION 

 Detection Recognition 

 Detected / Total Rate Recognized / Detected Rate 

Image 1 42 / 42 100% 42 / 42 100(%) 

Image 2 62 / 62 100% 62 / 62 100(%) 

Image 3 74(1) / 74 97.3% 64 / 74 86.4(%) 

Image 4 85(4) / 88 87.5% 65 / 85 76.5(%) 

Image 5 89(1) / 92 96.7% 85 / 89 95.5(%) 

Total 382(6) / 388 96.3% 318 / 382 91.7(%) 

 
Recognition results of our system are shown in the following. 

Fig. 11 shows the recognition results for the musical score 
Twinkle, Twinkle, Little Star. All the musical notes, including 
the pitches and beats, were successfully detected and 
recognized. The detected musical notes are marked 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1815International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

accordingly. 
 

 

Fig. 11 Recognition results of the musical score Twinkle, Twinkle, 
Little Star 

 
Fig. 12 shows the recognition results for the musical score 

The Swallow. Although the musical score was more 
complicated, all the musical notes, including the pitches and 
beats, were successfully detected and recognized.  

 

 

Fig. 12 Recognition results of the musical score The Swallow 
 

Fig. 13 shows the recognition results for the musical score I 
Will Sing You. The original image was in JPEG compressed 
format. All the musical notes, accidentals, and rests were 
successfully detected and recognized, despite there was a few 
errors in the recognition of the pitches. 

 

 

Fig. 13 Recognition results of the musical score I Will Sing You 

Fig. 14 shows the recognition results for the musical score At 
This Moment. The quality was relatively poor mainly because 
of compression distortion. The recognition results were 
relatively worse than previous scores. 

 

 

Fig. 14 Recognition results of the musical score At This Moment 
 

Fig. 15 shows the recognition results for the musical score 
My Herd. The quality was also relatively poor mainly because 
of compression distortion. The recognition results were 
relatively worse than previous scores especially in beat 
recognition (most recognition failure occurred at dots).  

 

 

Fig. 15 Recognition results of the musical score My Herd 

IV. CONCLUSION 

In this study, we proposed an Automatic Music Score 
Recognition System Using Digital Image Processing. The 
technical approaches included: staff region segmentation, 
image preprocessing, note recognition and accidental and rest 
recognition. Our system was developed to automatically detect 
and recognize musical notes, accidentals and rests in printed 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1816International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

musical scores.  
The results showed that the detection and the recognition 

rates of our system were 96.3% and 91.7%, respectively. While 
the results were limited and could be affected by image quality, 
our system was shown to achieve effective detection and 
recognition for musical symbols, such as notes, accidentals, and 
rests. Ultimately, our system could be incorporated with a 
media player that could play music/songs with inputs of 
musical scores.  

While our system has been demonstrated with success for 
different types of musical scores, our system was still limited 
with respect to the complexities of some musical scores (e.g., 
chords or other complex symbols). Improvement of our 
systems is still required for such musical scores. 

At present, our system was evaluated using personal 
computers with inputs of digital images. The system could be 
further integrated in applications for smart-phones or other 
mobile devices with built-in digital cameras. In addition, this 
system could be also used as a learning tool for players (e.g., 
piano players, guitar players, etc.) to play the music/songs even 
though they may not be familiar with the music/songs. 

REFERENCES  
[1] N. Otsu, “A Threshold Selection Method form Gray-Level Histograms,” 

IEEE Transactions on Systems, pp. 62-66, 1979. 
[2] R.G. Casey and E. Lecolinet, “A Survey of Methods and Strategies in 

Character Segmentation,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, pp. 690-706, 1996. 

[3] Cheng-Lin Liu, M. Koga and H. Fujisawa, “Lexicon-Driven 
Segmentation and Recognition of Handwritten Character Strings for 
Japanese Address Reading,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, pp. 1425-1437, 2002. 

[4] M. Sotoodeh and F. Tajeripour, “Staff Detection and Removal Using 
Derivation and Connected Component Analysis,” IEEE 16th CSI 
International Symposium on Artificial Intelligence and Signal Processing 
(AISP), pp. 54-57, 2012. 

[5] Chen Genfang, Zhang Liyin, Zhang Wenjun and Wang Qiuqiu, 
“Detecting the Staff-lines of Musical Score with Hough Transform and 
Mathematical Morphology,” IEEE International Conference on 
Multimedia Technology (ICMT) , pp. 1-4, 2010. 

[6] A. Dutta, U. Pal, A. Fornes and J. Llados, “An Efficient Staff Removal 
Approach from Printed Musical Documents,” IEEE International 
Conference on Pattern Recognition (ICPR), pp.1965-1968, 2010. 

[7] JaeMyeong Yoo, GiHong Kim and Gueesang Lee, “Mask Matching for 
Low Resolution Musical Note Recognition,” IEEE International 
Symposium on Signal Processing and Information Technology, pp. 
223-226, 2008. 

[8] F.Toyama, K. Shioji and J. Miyamichi, “Symbol Recognition of Printed 
Piano Scores with Touching Symbols,” Pattern Recognition, ICPR 18th 

International Conference, pp. 480-483, 2006. 
[9] F.Rossant and I. Bloch, “Optical Music Recognition Based on a Fuzzy 

Modeling of Symbol Classes and Music Writing Rules,” Pattern 
Recognition Letters, vol.23, pp. 1129-1141, 2002. 

[10] K.T. Reed and J.R.Parker, “Automatic Computer Recognition of Printed 
Music,” in Proceedings of the ICPR, pp.803-807, 1996. 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1817International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (3).pdf


 

 
Abstract—Music has always been an integral part of human’s 

daily lives. But, for the most people, reading musical score and turning 
it into melody is not easy. This study aims to develop an Automatic 
music score recognition system using digital image processing, which 
can be used to read and analyze musical score images automatically. 
The technical approaches included: (1) staff region segmentation; (2) 
image preprocessing; (3) note recognition; and (4) accidental and rest 
recognition. Digital image processing techniques (e.g., horizontal 
/vertical projections, connected component labeling, morphological 
processing, template matching, etc.) were applied according to 
musical notes, accidents, and rests in staff notations. Preliminary 
results showed that our system could achieve detection and 
recognition rates of 96.3% and 91.7%, respectively. In conclusion, we 
presented an effective automated musical score recognition system 
that could be integrated in a system with a media player to play 
music/songs given input images of musical score. Ultimately, this 
system could also be incorporated in applications for mobile devices as 
a learning tool, such that a music player could learn to play 
music/songs. 
 

Keywords—Connected component labeling, image processing, 
morphological processing, optical musical recognition.  

I. INTRODUCTION 

ITH the advance of image processing and computer 
vision techniques in recent years, the techniques have 

been integrated in human’s daily lives. Typical image 
processing and computer vision applications include document 
processing, smartphone applications, video surveillance 
systems, multimedia systems, and/or video games, etc.  

In image processing techniques, the Optical Character 
Recognition (OCR) is an important technique that has been 
widely used in handwriting inputs, license plate recognition, 
and augmented reality applications. The objective of the OCR 
technique is to allow the computer to analyze the text images, 
and then convert to texts (typically the ASCII codes) which 
computer can handle. For example, [1] proposed a method to 
calculate the appropriate threshold for converting gray-level 
images to binary images automatically. Casey and Lecolinet [2] 
proposed a character segmentation system based on connected 
component analysis and feature extraction, which were used to 
segment and recognize each character from document images. 

 
Yuan-Hsiang Chang, Ph.D. is with the Information and Computer 

Engineering Department, Chung-Yuan Christian University, Chung Li, Taiwan, 
R.O.C. (phone: 886-3-265-4713; fax: 886-3-265-4799; e-mail: author@ 
boulder.nist.gov).  

Zhong-Xian Peng, is a graduate student with the. Information and Computer 
Engineering Department, Chung-Yuan Christian University, Chung Li, Tawian, 
R.O.C 

Li-Der Jeng is with the Electronic Engineering Department, Chung-Yuan 
Christian University, Chung Li, Taiwan 

Liu et al. [3] proposed a handwritten character strings 
recognition system for address reading, in which characters 
were segmented using the connected component analysis. Each 
character was then recognized using a beam search algorithm 
and a character classifier. 

In addition to the OCR technique, pattern recognition 
techniques are also drawing attention of many researchers. 
Patterns (or symbols) are commonly seen in documents and/or 
other scenarios in which text information is not used for the 
representation (such as music notes, traffic signs, gestures, etc.). 
However, recognition of such patterns (or symbols) may 
require expertise to achieve effective representation and/or 
communication (e.g., music notes in a music score, etc.). 

Musical score is a form to record music by symbols which 
may include the pitch and tempo information about the music 
and/or songs. With the development of pattern recognition 
techniques, musical score recognition has also become a 
research topic lately. For example, [4] proposed a method to 
detect and remove staff lines using derivation and connected 
component analysis. Chen et al. [5] proposed a conventional 
architecture of Optical Music Recognition (OMR) using the 
staff-lines detection as the key stage. They explored two 
methods, namely the Hough transform and Mathematical 
Morphology, for detecting all staff-lines of an image. Dutta et 
al. [6] proposed a different method to detect and remove staff 
lines from musical documents. The methodology considered a 
staff line segment as a horizontal linkage of vertical black runs 
with uniform height. They also used the neighboring properties 
of a staff line segment to validate it as a true segment. Yoo et al. 
[7] proposed a system to recognize musical scores in low 
resolution images captured by the digital camera of a mobile 
phone. They presented a mask based approach to cope with 
incomplete information in the low resolution images. Toyama 
et al. [8] proposed a score recognition method which could be 
applicable to the complex music scores. Symbol candidates 
were detected by template matching, and then selected by 
considering the relative positions and mutual connections. 
Rossant and Bloch [9] proposed an optical music recognition 
system based on a fuzzy modeling of symbol classes and music 
writing rules. The objective was to disambiguate the 
recognition hypotheses output by the individual symbol 
analysis, followed by the fuzzy modeling to account for 
imprecision in symbol detection. Parker [10] implemented a 
complete optical music recognition system, called Lemon. 
Their system included the techniques, i.e., staff line detection, 
text segmentation, line detection, symbol recognition, note 
head recognition, and semantic interpretation. 

Automatic Music Score Recognition System Using 
Digital Image Processing 
Yuan-Hsiang Chang, Zhong-Xian Peng, Li-Der Jeng. 

W 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1811International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

II.  METHOD 

In this study, we present an “Automatic Music Score 
Recognition System Using Digital Image Processing”, which 
was aimed to automatically recognize musical scores.  

Several system hypotheses can be described as follows: 
 The musical score is a printed document (i.e., black 

musical notes or symbols in white background). 
 The musical score is a scanned document in an upright 

position, therefore no perspective distortions are observed. 
 The image is with sufficient resolution and in good quality. 

Fig. 1 shows the flow chart of our system. The processes 
include: Image Analysis and Segmentation, Image 
Preprocessing, Note recognition, and Accidental and Rest 
Recognition. 

 

Note Recognition

Stem Filtering

Size Filtering

Shape Filtering

Pitch And Beat Analysis

Output

Staff Region Segmentation

Binary Transform

Horizontal Projection

Region Segmentation

Image Preprocessing

Accidental and Rest Recognition

Note Removal

Template ImageTemplate Matching

Source
Image

Staff Line Filtering

Morphological Processing

Connected Component Labeling

 

Fig. 1 System flow chart of the Automatic Music Score Recognition 
System Using Digital Image Processing  

A. Staff Region Segmentation 

A page of musical score consist of number of row stave, with 
a top-down order when playing. A staff consists of five staff 
lines, while notes are recorded on staff lines with respect to the 
height of each line to determine its pitch. Therefore, the first 
step of our system was to segment sub-regions for each staff. 
The processes included: Binary Transform, Horizontal 
Projection, and Region Segmentation. 

Binary Transform was simply used to convert the input 
image to a binary image. In this study, the Otsu’s algorithm was 

used to find the optimal threshold T that minimizes the 
within-class variances. As a result, given an input image I and 
the threshold T, a binary image IB can be acquired using: 
 

   


 


otherwise

TyxIif
yxI B ,0

,,255
,

                    (1) 

 
Horizontal Projection: The image projection is a method for 

projecting source data to selected area to reduce the dimension 
of the source data, such that the data could be easily processed. 
Image projections can be implemented in either the horizontal 
or vertical directions, resulted in horizontal or vertical 
projections. Here, the horizontal projection was applied in our 
system to acquire the horizontally projection histogram as 
shown in Fig. 2. By projecting the musical score in Fig. 2 (a) 
horizontally, total number of pixels for each row could be 
determined in Fig. 2 (b). As shown, the five staff lines were 
associated with five obvious peak values in terms of number of 
pixels. 

 

 

(a) 
 

 

(b) 

Fig. 2 Binary musical score image and the corresponding horizontal 
projects 

 
Region Segmentation: The objective of the region 

segmentation was to identify and segment regions of stave from 
the original image such that each region of the staff could be 
processed independently.  

Based on the result given in Fig. 2, the staff line height HL, 
the staff line space SL, and the distribution of staff lines, could 
be obtained. An example is shown in Fig. 3. 

 

 

Fig. 3 An example of the staff line height HL and the staff line space SL. 
The height of the note head is approximately the same as the staff line 

space 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1812International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

According to the horizontal projections, the histogram 
represented the number of pixels for each row in the binary 
image. Because each staff contained exactly five horizontal 
staff lines, the peaks of the horizontal projections at the location 
of staff line represented the locations of the five staff lines. 
Therefore, the five staff lines could be obtained by 
back-projections of the five peaks in the histogram, such that 
the resulting image contains only the staff lines without any 
note heads (or other symbols). 

B. Image Preprocessing 

In image preprocessing, our objective was to extract or 
isolate the musical symbols to be independent regions from the 
staff by removing the staff lines in the image. However, during 
staff line removal processes, several musical notes (or other 
symbols) may be damaged if they are associated with weak 
structures (shapes). Therefore, our system incorporated the 
image preprocessing processes to retain the musical notes (or 
symbols), while removing the staff lines for further processes. 

Staff Line Filtering: In the musical score, musical symbols 
are recorded on the staff. As a result, musical symbols are 
connected with the staff lines in images. In this step, our 
objective was to retain the music notes (or symbols) in images, 
while removing the staff lines. After acquiring the Staff line 
space and height by horizontal projections, our system removed 
all the black pixels at each rows of staff lines. Because this 
process may damage the structure (shapes) of musical notes (or 
symbols), additional criterion was included. The staff line 
height HL was selected as the threshold and black pixels were 
removed only if the observed height was smaller than the staff 
line height. An example is shown in Fig. 4 (a). 

Morphological Processing: Although the aforementioned 
process was able to remove staff lines effectively, the structure 
(shapes) of the musical notes (or symbols) could be affected. 
The process of Morphological processing was used to retain the 
complete structure (shapes) of each musical note (or symbol). 

 

 

(a) 
 

 

(b) 

Fig. 4 An example of the image preprocessing: (a) result of staff line 
filtering; (b) result of morphological processing 

 
Closing processing is a technology of morphological 

processing that can be used to link the small gaps of structure 
and to improve the connectivity for regions in images. The 
morphological closing is defined by: 

 

EEIEI Θ)(                                 (2) 
 
where I is the input image and is E the structuring element. The 
image is first dilated (  is the dilation operation) and then 

eroded (Θ  is the erosion operation) with the structuring 
element. In our system, the morphological closing was applied, 
an example is shown in Fig. 4 (b). 

Connected Component Labeling: A region of connected 
pixels with an identical label was referred as a connected 
component. The objective of the connected component labeling 
was to assign a unique label to each connected component. An 
example is shown in Fig. 5. 

 

 

Fig. 5 An example of the connected component labeling is shown. 
After labeling, each connected component (region) is assigned a 

unique label 
 

Given a binary images with binary-1s (black pixels) and 
binary-0s (white pixels), we applied the connected component 
labeling to extract each connected component. Therefore, each 
musical notes (or symbols) could be identified and labeled. The 
seed filling algorithm for the connected component labeling is 
given by: 
1) Search each pixel in the image until the value of the current 

pixel P with the binary-1 value and has not been labeled 
yet; 

2) Select P as the seed pixel and assign a label L to P, then 
check each pixel that is adjacent to the seed pixel; 

3) If there is a pixel Q with the binary-1 value that is adjacent 
to the seed pixel, return to step 2 until there is no pixels 
with the binary-1 is found; 

4) Update the label and return to step 1 until all pixels in the 
image have been checked. 

C. Note Recognition 

Once the connected regions for the musical notes (or 
symbols) were identified and labeled, the final step was to 
recognize them. In our system, the processes were divided into 
two major recognition phases: (1) Note recognition; and (2) 
Accidental and rest recognition. 

In staff notations, a musical note can be split into three parts 
according to its structure: head, stem and tail, as shown in Fig. 6. 
The head (e.g., solid or not) is mainly used to determine the 
pitch by its position with respect to the staff lines; the tails is 
mainly used to determine the beat; the stem is used to connect 
both the head and the tail. Our system was designed to detect 
the note heads first, followed by the detection of stems and tails.  

Stem Filtering: A stem is used to connect the head and the 
tail in a musical note. With the different position of a musical 
note, the stem is either extended upward or downward form the 
head. In addition, a whole note has no stems. Because of the 
variety in structures (shapes), recognition of musical note could 
be difficult. To simplify the task, the Stem filtering was 
designed to remove stems for the musical notes, while retaining 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1813International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

the structure of the note heads. 
 

 

Fig. 6 An example of a typical musical note (i.e., eighth note): The 
structure consists of head, stem and tail 

 
In this step, vertical projections were applied and the 

histogram was acquired to determine the approximated location 
of each musical note. During vertical projections, peaks in the 
histogram were related to the location of the stems, despite 
there are different types of musical notes (e.g., 4th or 8th notes, 
etc.). Therefore, stems of each musical notes could be filtered 
(removed). 

Size Filtering: Although there are differences in 
representing musical notes by different publishers, the height of 
the note heads is generally the same as the staff line space. 
Therefore, the staff line space SL was used as the threshold to 
determine if a connected region actually represents the head of 
a musical note. 

Shape Filtering: The head of a musical note is generally an 
oval shape which is symmetrical with respect to its center. Here, 
we detected note heads by calculating the rate of symmetric for 
each connected component. 

In a symmetric connected component L, for any point P∈L, 
there exists a point PS ∈	L	such	that	P - PC = PC - PS, where PC 

is the center of the connected component L, as defined by: 
 

SCCS PPPPPLP  :!,                   (3) 

 
According to the equation, the rate of symmetry R can be 

obtained for each connected component, as given by (4) 
 

A

S

Sum

Sum
R                                       (4) 

 
where Sums is the total number of the symmetric pixels and 
SumA is the total number of all the pixels in the connected 
component. Using the rate of symmetry, we could therefore 
remove all the regions that were not likely to be the heads of 
musical notes. An example is shown in Fig. 7. 

 

 

Fig. 7 An example of the note recognition, in which all the heads of the 
musical notes are marked  

 
Pitch and Beat Analysis: The pitch of the musical note is 

defined by its position with respect to the staff lines. The 
difference of pitches among musical notes is based on the scale 
as a basic unit, and the distance of each scale is with half height 
of the staff line space. Hence, we defined the pitch of each note 
by calculating the distance between musical notes and the 
datum line. The datum line was defined as the position of the 
keynote, i.e., the position of middle C. 

 

Whole/Half  Note ?

Have Stem?

How Many Tails?

Yes

No

Whole Note

Half Note

Quarter Note

Eighth Note

Sixteenth Note

No

Yes

0

1

2

Input

 
Fig. 8 The classifier for the beat of a musical note: Each musical note can thus be classified based on the properties if the stem/tails exist 

 
The beat of a musical note represents the length of the note 

being played, and each note has its own beat. The beat of a 
musical note is represented by three parts: (1) The note is solid 

or not; (2) The note has a stem or not; and (3) How many tails 
do the note have. Based on these properties, our system 
incorporated a classifier for the beat of a musical note, as shown 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1814International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

in Fig. 8. Furthermore, a dot is often used to adjust the beat for 
the musical notes. The dot is meant to increase the beat of the 
musical note by half of its original beat. For example, a note 
with two beats will become three beats. The symbol of a dot in a 
music score is a round black spot, and is generally marked at 
the right side of the note head. The size of dots is smaller than 
the half size of heads and is disconnected with other symbols. 
Based on the dot property as described, our system was 
designed to incorporate additional process for the process of 
recognizing the dot associated with a note head. 

D.  Accidental and Rest Recognition 

Accidentals are the musical symbols used to modify the pitch 
of a musical note. The most common accidentals can be 
described as follow: (1) the sharp is used to raise the pitch of a 
musical note by a semitone; (2) the flat is used to reduce the 
pitch of a musical notes by a semitone; and (3) the natural is 
used to recover the pitch of a musical note to its natural key. 
The accidentals are typically recorded in two ways: (1) marked 
at the start of a staff represent a key signature; and (2) marked at 
the left of a note to adjust the pitch of the musical note.  

Rests are the musical symbols used to represent the pauses in 
music/song. Unlike musical notes, rests have no pitches so that 
the height of rests in a score is fixed. However, shapes of rests 
with different beats are relatively irregular than musical notes. 

To identify the accidentals and/or rests, the technique of 
template matching is used in our system. The technique was 
used to compare an unknown symbol with respect to known 
template images (i.e., template images for possible accidentals 
and/or rests) in the database to recognize the symbol. In our 
system, once a region (sub-image) containing a symbol was 
detected, the region (sub-image) was then normalized to the 
same size with the template image and the logical XOR 
operation was applied: 
 

     


 


otherwise

yxIyxIif
yxI CT

XOR ,255

,,,0
,           (5) 

 
where IT represent the template image, IC represent the 
sub-image containing a symbol, and IXOR represent the result 
image after the exclusive-OR operation. An example is shown 
in Fig. 9. 

 

 

(a) 

 

(b) 

 

(c) 

Fig. 9 An example of the template matching for the rest recognition: 
(a) sub-image of an unknown symbol; (b) template image of the 

crotchet rest; (c) resulting image after the exclusion-OR operation 
 
Fig. 10 shows an example for the recognition of accidentals 

and rests in a musical score. Using the template matching, our 
system was able to identify the accidentals and rests. However, 

our system failed to detect the sharp symbol which is connected 
with the tail of a musical note. 

 

 

(a) 
 

 

(b) 

Fig. 10 An example of the accidental and rest recognition: (a) input 
image; (b) result of the recognition. There is a sharp that is connected 
with the tail of a musical note, resulting in a recognition failure in our 

system  

III. RESULTS 

In this section, we present the research environment and 
recognition results using our system in several musical score 
images. 

A. Research Environment 

The system development was based on a personal computer: 
Pentium(R) Dual-Core E5200 2.5GHz with 2GB memory, and 
Microsoft Windows 7 operating system. The system software 
was developed using the Microsoft Visual Studio C/C++ 2010 
and the Intel Open Source Computer Vision Library (OpenCV) 
Version 2.4.8.  

To evaluate our system performance, a set of digital images 
with musical scores of various complexities were collected 
from the Internet.  

B. Result of Musical Score Recognition 

Table I summarizes the results of musical symbol detection 
and recognition of our system using five images of musical 
scores. The detection rate was evaluated with the probability 
when musical notes or symbols (including accidentals and rests) 
were correctly detected. Then, based on the detected notes or 
symbols, the recognition rate was evaluated with the 
probability when the musical notes or symbols were correctly 
recognized. 

 
TABLE I 

THE RESULTS OF MUSICAL SYMBOL DETECTION AND RECOGNITION 

 Detection Recognition 

 Detected / Total Rate Recognized / Detected Rate 

Image 1 42 / 42 100% 42 / 42 100(%) 

Image 2 62 / 62 100% 62 / 62 100(%) 

Image 3 74(1) / 74 97.3% 64 / 74 86.4(%) 

Image 4 85(4) / 88 87.5% 65 / 85 76.5(%) 

Image 5 89(1) / 92 96.7% 85 / 89 95.5(%) 

Total 382(6) / 388 96.3% 318 / 382 91.7(%) 

 
Recognition results of our system are shown in the following. 

Fig. 11 shows the recognition results for the musical score 
Twinkle, Twinkle, Little Star. All the musical notes, including 
the pitches and beats, were successfully detected and 
recognized. The detected musical notes are marked 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1815International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

accordingly. 
 

 

Fig. 11 Recognition results of the musical score Twinkle, Twinkle, 
Little Star 

 
Fig. 12 shows the recognition results for the musical score 

The Swallow. Although the musical score was more 
complicated, all the musical notes, including the pitches and 
beats, were successfully detected and recognized.  

 

 

Fig. 12 Recognition results of the musical score The Swallow 
 

Fig. 13 shows the recognition results for the musical score I 
Will Sing You. The original image was in JPEG compressed 
format. All the musical notes, accidentals, and rests were 
successfully detected and recognized, despite there was a few 
errors in the recognition of the pitches. 

 

 

Fig. 13 Recognition results of the musical score I Will Sing You 

Fig. 14 shows the recognition results for the musical score At 
This Moment. The quality was relatively poor mainly because 
of compression distortion. The recognition results were 
relatively worse than previous scores. 

 

 

Fig. 14 Recognition results of the musical score At This Moment 
 

Fig. 15 shows the recognition results for the musical score 
My Herd. The quality was also relatively poor mainly because 
of compression distortion. The recognition results were 
relatively worse than previous scores especially in beat 
recognition (most recognition failure occurred at dots).  

 

 

Fig. 15 Recognition results of the musical score My Herd 

IV. CONCLUSION 

In this study, we proposed an Automatic Music Score 
Recognition System Using Digital Image Processing. The 
technical approaches included: staff region segmentation, 
image preprocessing, note recognition and accidental and rest 
recognition. Our system was developed to automatically detect 
and recognize musical notes, accidentals and rests in printed 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1816International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

musical scores.  
The results showed that the detection and the recognition 

rates of our system were 96.3% and 91.7%, respectively. While 
the results were limited and could be affected by image quality, 
our system was shown to achieve effective detection and 
recognition for musical symbols, such as notes, accidentals, and 
rests. Ultimately, our system could be incorporated with a 
media player that could play music/songs with inputs of 
musical scores.  

While our system has been demonstrated with success for 
different types of musical scores, our system was still limited 
with respect to the complexities of some musical scores (e.g., 
chords or other complex symbols). Improvement of our 
systems is still required for such musical scores. 

At present, our system was evaluated using personal 
computers with inputs of digital images. The system could be 
further integrated in applications for smart-phones or other 
mobile devices with built-in digital cameras. In addition, this 
system could be also used as a learning tool for players (e.g., 
piano players, guitar players, etc.) to play the music/songs even 
though they may not be familiar with the music/songs. 

REFERENCES  
[1] N. Otsu, “A Threshold Selection Method form Gray-Level Histograms,” 

IEEE Transactions on Systems, pp. 62-66, 1979. 
[2] R.G. Casey and E. Lecolinet, “A Survey of Methods and Strategies in 

Character Segmentation,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, pp. 690-706, 1996. 

[3] Cheng-Lin Liu, M. Koga and H. Fujisawa, “Lexicon-Driven 
Segmentation and Recognition of Handwritten Character Strings for 
Japanese Address Reading,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, pp. 1425-1437, 2002. 

[4] M. Sotoodeh and F. Tajeripour, “Staff Detection and Removal Using 
Derivation and Connected Component Analysis,” IEEE 16th CSI 
International Symposium on Artificial Intelligence and Signal Processing 
(AISP), pp. 54-57, 2012. 

[5] Chen Genfang, Zhang Liyin, Zhang Wenjun and Wang Qiuqiu, 
“Detecting the Staff-lines of Musical Score with Hough Transform and 
Mathematical Morphology,” IEEE International Conference on 
Multimedia Technology (ICMT) , pp. 1-4, 2010. 

[6] A. Dutta, U. Pal, A. Fornes and J. Llados, “An Efficient Staff Removal 
Approach from Printed Musical Documents,” IEEE International 
Conference on Pattern Recognition (ICPR), pp.1965-1968, 2010. 

[7] JaeMyeong Yoo, GiHong Kim and Gueesang Lee, “Mask Matching for 
Low Resolution Musical Note Recognition,” IEEE International 
Symposium on Signal Processing and Information Technology, pp. 
223-226, 2008. 

[8] F.Toyama, K. Shioji and J. Miyamichi, “Symbol Recognition of Printed 
Piano Scores with Touching Symbols,” Pattern Recognition, ICPR 18th 

International Conference, pp. 480-483, 2006. 
[9] F.Rossant and I. Bloch, “Optical Music Recognition Based on a Fuzzy 

Modeling of Symbol Classes and Music Writing Rules,” Pattern 
Recognition Letters, vol.23, pp. 1129-1141, 2002. 

[10] K.T. Reed and J.R.Parker, “Automatic Computer Recognition of Printed 
Music,” in Proceedings of the ICPR, pp.803-807, 1996. 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1817International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


reading content from D:\SD\SearchEngine_ver1\Bee\10005799.pdf


 

 
Abstract—Music has always been an integral part of human’s 

daily lives. But, for the most people, reading musical score and turning 
it into melody is not easy. This study aims to develop an Automatic 
music score recognition system using digital image processing, which 
can be used to read and analyze musical score images automatically. 
The technical approaches included: (1) staff region segmentation; (2) 
image preprocessing; (3) note recognition; and (4) accidental and rest 
recognition. Digital image processing techniques (e.g., horizontal 
/vertical projections, connected component labeling, morphological 
processing, template matching, etc.) were applied according to 
musical notes, accidents, and rests in staff notations. Preliminary 
results showed that our system could achieve detection and 
recognition rates of 96.3% and 91.7%, respectively. In conclusion, we 
presented an effective automated musical score recognition system 
that could be integrated in a system with a media player to play 
music/songs given input images of musical score. Ultimately, this 
system could also be incorporated in applications for mobile devices as 
a learning tool, such that a music player could learn to play 
music/songs. 
 

Keywords—Connected component labeling, image processing, 
morphological processing, optical musical recognition.  

I. INTRODUCTION 

ITH the advance of image processing and computer 
vision techniques in recent years, the techniques have 

been integrated in human’s daily lives. Typical image 
processing and computer vision applications include document 
processing, smartphone applications, video surveillance 
systems, multimedia systems, and/or video games, etc.  

In image processing techniques, the Optical Character 
Recognition (OCR) is an important technique that has been 
widely used in handwriting inputs, license plate recognition, 
and augmented reality applications. The objective of the OCR 
technique is to allow the computer to analyze the text images, 
and then convert to texts (typically the ASCII codes) which 
computer can handle. For example, [1] proposed a method to 
calculate the appropriate threshold for converting gray-level 
images to binary images automatically. Casey and Lecolinet [2] 
proposed a character segmentation system based on connected 
component analysis and feature extraction, which were used to 
segment and recognize each character from document images. 

 
Yuan-Hsiang Chang, Ph.D. is with the Information and Computer 

Engineering Department, Chung-Yuan Christian University, Chung Li, Taiwan, 
R.O.C. (phone: 886-3-265-4713; fax: 886-3-265-4799; e-mail: author@ 
boulder.nist.gov).  

Zhong-Xian Peng, is a graduate student with the. Information and Computer 
Engineering Department, Chung-Yuan Christian University, Chung Li, Tawian, 
R.O.C 

Li-Der Jeng is with the Electronic Engineering Department, Chung-Yuan 
Christian University, Chung Li, Taiwan 

Liu et al. [3] proposed a handwritten character strings 
recognition system for address reading, in which characters 
were segmented using the connected component analysis. Each 
character was then recognized using a beam search algorithm 
and a character classifier. 

In addition to the OCR technique, pattern recognition 
techniques are also drawing attention of many researchers. 
Patterns (or symbols) are commonly seen in documents and/or 
other scenarios in which text information is not used for the 
representation (such as music notes, traffic signs, gestures, etc.). 
However, recognition of such patterns (or symbols) may 
require expertise to achieve effective representation and/or 
communication (e.g., music notes in a music score, etc.). 

Musical score is a form to record music by symbols which 
may include the pitch and tempo information about the music 
and/or songs. With the development of pattern recognition 
techniques, musical score recognition has also become a 
research topic lately. For example, [4] proposed a method to 
detect and remove staff lines using derivation and connected 
component analysis. Chen et al. [5] proposed a conventional 
architecture of Optical Music Recognition (OMR) using the 
staff-lines detection as the key stage. They explored two 
methods, namely the Hough transform and Mathematical 
Morphology, for detecting all staff-lines of an image. Dutta et 
al. [6] proposed a different method to detect and remove staff 
lines from musical documents. The methodology considered a 
staff line segment as a horizontal linkage of vertical black runs 
with uniform height. They also used the neighboring properties 
of a staff line segment to validate it as a true segment. Yoo et al. 
[7] proposed a system to recognize musical scores in low 
resolution images captured by the digital camera of a mobile 
phone. They presented a mask based approach to cope with 
incomplete information in the low resolution images. Toyama 
et al. [8] proposed a score recognition method which could be 
applicable to the complex music scores. Symbol candidates 
were detected by template matching, and then selected by 
considering the relative positions and mutual connections. 
Rossant and Bloch [9] proposed an optical music recognition 
system based on a fuzzy modeling of symbol classes and music 
writing rules. The objective was to disambiguate the 
recognition hypotheses output by the individual symbol 
analysis, followed by the fuzzy modeling to account for 
imprecision in symbol detection. Parker [10] implemented a 
complete optical music recognition system, called Lemon. 
Their system included the techniques, i.e., staff line detection, 
text segmentation, line detection, symbol recognition, note 
head recognition, and semantic interpretation. 

Automatic Music Score Recognition System Using 
Digital Image Processing 
Yuan-Hsiang Chang, Zhong-Xian Peng, Li-Der Jeng. 

W 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1811International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799
Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight



 

II.  METHOD 

In this study, we present an “Automatic Music Score 
Recognition System Using Digital Image Processing”, which 
was aimed to automatically recognize musical scores.  

Several system hypotheses can be described as follows: 
 The musical score is a printed document (i.e., black 

musical notes or symbols in white background). 
 The musical score is a scanned document in an upright 

position, therefore no perspective distortions are observed. 
 The image is with sufficient resolution and in good quality. 

Fig. 1 shows the flow chart of our system. The processes 
include: Image Analysis and Segmentation, Image 
Preprocessing, Note recognition, and Accidental and Rest 
Recognition. 

 

Note Recognition

Stem Filtering

Size Filtering

Shape Filtering

Pitch And Beat Analysis

Output

Staff Region Segmentation

Binary Transform

Horizontal Projection

Region Segmentation

Image Preprocessing

Accidental and Rest Recognition

Note Removal

Template ImageTemplate Matching

Source
Image

Staff Line Filtering

Morphological Processing

Connected Component Labeling

 

Fig. 1 System flow chart of the Automatic Music Score Recognition 
System Using Digital Image Processing  

A. Staff Region Segmentation 

A page of musical score consist of number of row stave, with 
a top-down order when playing. A staff consists of five staff 
lines, while notes are recorded on staff lines with respect to the 
height of each line to determine its pitch. Therefore, the first 
step of our system was to segment sub-regions for each staff. 
The processes included: Binary Transform, Horizontal 
Projection, and Region Segmentation. 

Binary Transform was simply used to convert the input 
image to a binary image. In this study, the Otsu’s algorithm was 

used to find the optimal threshold T that minimizes the 
within-class variances. As a result, given an input image I and 
the threshold T, a binary image IB can be acquired using: 
 

   


 


otherwise

TyxIif
yxI B ,0

,,255
,

                    (1) 

 
Horizontal Projection: The image projection is a method for 

projecting source data to selected area to reduce the dimension 
of the source data, such that the data could be easily processed. 
Image projections can be implemented in either the horizontal 
or vertical directions, resulted in horizontal or vertical 
projections. Here, the horizontal projection was applied in our 
system to acquire the horizontally projection histogram as 
shown in Fig. 2. By projecting the musical score in Fig. 2 (a) 
horizontally, total number of pixels for each row could be 
determined in Fig. 2 (b). As shown, the five staff lines were 
associated with five obvious peak values in terms of number of 
pixels. 

 

 

(a) 
 

 

(b) 

Fig. 2 Binary musical score image and the corresponding horizontal 
projects 

 
Region Segmentation: The objective of the region 

segmentation was to identify and segment regions of stave from 
the original image such that each region of the staff could be 
processed independently.  

Based on the result given in Fig. 2, the staff line height HL, 
the staff line space SL, and the distribution of staff lines, could 
be obtained. An example is shown in Fig. 3. 

 

 

Fig. 3 An example of the staff line height HL and the staff line space SL. 
The height of the note head is approximately the same as the staff line 

space 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1812International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799
Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight



 

According to the horizontal projections, the histogram 
represented the number of pixels for each row in the binary 
image. Because each staff contained exactly five horizontal 
staff lines, the peaks of the horizontal projections at the location 
of staff line represented the locations of the five staff lines. 
Therefore, the five staff lines could be obtained by 
back-projections of the five peaks in the histogram, such that 
the resulting image contains only the staff lines without any 
note heads (or other symbols). 

B. Image Preprocessing 

In image preprocessing, our objective was to extract or 
isolate the musical symbols to be independent regions from the 
staff by removing the staff lines in the image. However, during 
staff line removal processes, several musical notes (or other 
symbols) may be damaged if they are associated with weak 
structures (shapes). Therefore, our system incorporated the 
image preprocessing processes to retain the musical notes (or 
symbols), while removing the staff lines for further processes. 

Staff Line Filtering: In the musical score, musical symbols 
are recorded on the staff. As a result, musical symbols are 
connected with the staff lines in images. In this step, our 
objective was to retain the music notes (or symbols) in images, 
while removing the staff lines. After acquiring the Staff line 
space and height by horizontal projections, our system removed 
all the black pixels at each rows of staff lines. Because this 
process may damage the structure (shapes) of musical notes (or 
symbols), additional criterion was included. The staff line 
height HL was selected as the threshold and black pixels were 
removed only if the observed height was smaller than the staff 
line height. An example is shown in Fig. 4 (a). 

Morphological Processing: Although the aforementioned 
process was able to remove staff lines effectively, the structure 
(shapes) of the musical notes (or symbols) could be affected. 
The process of Morphological processing was used to retain the 
complete structure (shapes) of each musical note (or symbol). 

 

 

(a) 
 

 

(b) 

Fig. 4 An example of the image preprocessing: (a) result of staff line 
filtering; (b) result of morphological processing 

 
Closing processing is a technology of morphological 

processing that can be used to link the small gaps of structure 
and to improve the connectivity for regions in images. The 
morphological closing is defined by: 

 

EEIEI Θ)(                                 (2) 
 
where I is the input image and is E the structuring element. The 
image is first dilated (  is the dilation operation) and then 

eroded (Θ  is the erosion operation) with the structuring 
element. In our system, the morphological closing was applied, 
an example is shown in Fig. 4 (b). 

Connected Component Labeling: A region of connected 
pixels with an identical label was referred as a connected 
component. The objective of the connected component labeling 
was to assign a unique label to each connected component. An 
example is shown in Fig. 5. 

 

 

Fig. 5 An example of the connected component labeling is shown. 
After labeling, each connected component (region) is assigned a 

unique label 
 

Given a binary images with binary-1s (black pixels) and 
binary-0s (white pixels), we applied the connected component 
labeling to extract each connected component. Therefore, each 
musical notes (or symbols) could be identified and labeled. The 
seed filling algorithm for the connected component labeling is 
given by: 
1) Search each pixel in the image until the value of the current 

pixel P with the binary-1 value and has not been labeled 
yet; 

2) Select P as the seed pixel and assign a label L to P, then 
check each pixel that is adjacent to the seed pixel; 

3) If there is a pixel Q with the binary-1 value that is adjacent 
to the seed pixel, return to step 2 until there is no pixels 
with the binary-1 is found; 

4) Update the label and return to step 1 until all pixels in the 
image have been checked. 

C. Note Recognition 

Once the connected regions for the musical notes (or 
symbols) were identified and labeled, the final step was to 
recognize them. In our system, the processes were divided into 
two major recognition phases: (1) Note recognition; and (2) 
Accidental and rest recognition. 

In staff notations, a musical note can be split into three parts 
according to its structure: head, stem and tail, as shown in Fig. 6. 
The head (e.g., solid or not) is mainly used to determine the 
pitch by its position with respect to the staff lines; the tails is 
mainly used to determine the beat; the stem is used to connect 
both the head and the tail. Our system was designed to detect 
the note heads first, followed by the detection of stems and tails.  

Stem Filtering: A stem is used to connect the head and the 
tail in a musical note. With the different position of a musical 
note, the stem is either extended upward or downward form the 
head. In addition, a whole note has no stems. Because of the 
variety in structures (shapes), recognition of musical note could 
be difficult. To simplify the task, the Stem filtering was 
designed to remove stems for the musical notes, while retaining 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1813International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

the structure of the note heads. 
 

 

Fig. 6 An example of a typical musical note (i.e., eighth note): The 
structure consists of head, stem and tail 

 
In this step, vertical projections were applied and the 

histogram was acquired to determine the approximated location 
of each musical note. During vertical projections, peaks in the 
histogram were related to the location of the stems, despite 
there are different types of musical notes (e.g., 4th or 8th notes, 
etc.). Therefore, stems of each musical notes could be filtered 
(removed). 

Size Filtering: Although there are differences in 
representing musical notes by different publishers, the height of 
the note heads is generally the same as the staff line space. 
Therefore, the staff line space SL was used as the threshold to 
determine if a connected region actually represents the head of 
a musical note. 

Shape Filtering: The head of a musical note is generally an 
oval shape which is symmetrical with respect to its center. Here, 
we detected note heads by calculating the rate of symmetric for 
each connected component. 

In a symmetric connected component L, for any point P∈L, 
there exists a point PS ∈	L	such	that	P - PC = PC - PS, where PC 

is the center of the connected component L, as defined by: 
 

SCCS PPPPPLP  :!,                   (3) 

 
According to the equation, the rate of symmetry R can be 

obtained for each connected component, as given by (4) 
 

A

S

Sum

Sum
R                                       (4) 

 
where Sums is the total number of the symmetric pixels and 
SumA is the total number of all the pixels in the connected 
component. Using the rate of symmetry, we could therefore 
remove all the regions that were not likely to be the heads of 
musical notes. An example is shown in Fig. 7. 

 

 

Fig. 7 An example of the note recognition, in which all the heads of the 
musical notes are marked  

 
Pitch and Beat Analysis: The pitch of the musical note is 

defined by its position with respect to the staff lines. The 
difference of pitches among musical notes is based on the scale 
as a basic unit, and the distance of each scale is with half height 
of the staff line space. Hence, we defined the pitch of each note 
by calculating the distance between musical notes and the 
datum line. The datum line was defined as the position of the 
keynote, i.e., the position of middle C. 

 

Whole/Half  Note ?

Have Stem?

How Many Tails?

Yes

No

Whole Note

Half Note

Quarter Note

Eighth Note

Sixteenth Note

No

Yes

0

1

2

Input

 
Fig. 8 The classifier for the beat of a musical note: Each musical note can thus be classified based on the properties if the stem/tails exist 

 
The beat of a musical note represents the length of the note 

being played, and each note has its own beat. The beat of a 
musical note is represented by three parts: (1) The note is solid 

or not; (2) The note has a stem or not; and (3) How many tails 
do the note have. Based on these properties, our system 
incorporated a classifier for the beat of a musical note, as shown 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1814International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

in Fig. 8. Furthermore, a dot is often used to adjust the beat for 
the musical notes. The dot is meant to increase the beat of the 
musical note by half of its original beat. For example, a note 
with two beats will become three beats. The symbol of a dot in a 
music score is a round black spot, and is generally marked at 
the right side of the note head. The size of dots is smaller than 
the half size of heads and is disconnected with other symbols. 
Based on the dot property as described, our system was 
designed to incorporate additional process for the process of 
recognizing the dot associated with a note head. 

D.  Accidental and Rest Recognition 

Accidentals are the musical symbols used to modify the pitch 
of a musical note. The most common accidentals can be 
described as follow: (1) the sharp is used to raise the pitch of a 
musical note by a semitone; (2) the flat is used to reduce the 
pitch of a musical notes by a semitone; and (3) the natural is 
used to recover the pitch of a musical note to its natural key. 
The accidentals are typically recorded in two ways: (1) marked 
at the start of a staff represent a key signature; and (2) marked at 
the left of a note to adjust the pitch of the musical note.  

Rests are the musical symbols used to represent the pauses in 
music/song. Unlike musical notes, rests have no pitches so that 
the height of rests in a score is fixed. However, shapes of rests 
with different beats are relatively irregular than musical notes. 

To identify the accidentals and/or rests, the technique of 
template matching is used in our system. The technique was 
used to compare an unknown symbol with respect to known 
template images (i.e., template images for possible accidentals 
and/or rests) in the database to recognize the symbol. In our 
system, once a region (sub-image) containing a symbol was 
detected, the region (sub-image) was then normalized to the 
same size with the template image and the logical XOR 
operation was applied: 
 

     


 


otherwise

yxIyxIif
yxI CT

XOR ,255

,,,0
,           (5) 

 
where IT represent the template image, IC represent the 
sub-image containing a symbol, and IXOR represent the result 
image after the exclusive-OR operation. An example is shown 
in Fig. 9. 

 

 

(a) 

 

(b) 

 

(c) 

Fig. 9 An example of the template matching for the rest recognition: 
(a) sub-image of an unknown symbol; (b) template image of the 

crotchet rest; (c) resulting image after the exclusion-OR operation 
 
Fig. 10 shows an example for the recognition of accidentals 

and rests in a musical score. Using the template matching, our 
system was able to identify the accidentals and rests. However, 

our system failed to detect the sharp symbol which is connected 
with the tail of a musical note. 

 

 

(a) 
 

 

(b) 

Fig. 10 An example of the accidental and rest recognition: (a) input 
image; (b) result of the recognition. There is a sharp that is connected 
with the tail of a musical note, resulting in a recognition failure in our 

system  

III. RESULTS 

In this section, we present the research environment and 
recognition results using our system in several musical score 
images. 

A. Research Environment 

The system development was based on a personal computer: 
Pentium(R) Dual-Core E5200 2.5GHz with 2GB memory, and 
Microsoft Windows 7 operating system. The system software 
was developed using the Microsoft Visual Studio C/C++ 2010 
and the Intel Open Source Computer Vision Library (OpenCV) 
Version 2.4.8.  

To evaluate our system performance, a set of digital images 
with musical scores of various complexities were collected 
from the Internet.  

B. Result of Musical Score Recognition 

Table I summarizes the results of musical symbol detection 
and recognition of our system using five images of musical 
scores. The detection rate was evaluated with the probability 
when musical notes or symbols (including accidentals and rests) 
were correctly detected. Then, based on the detected notes or 
symbols, the recognition rate was evaluated with the 
probability when the musical notes or symbols were correctly 
recognized. 

 
TABLE I 

THE RESULTS OF MUSICAL SYMBOL DETECTION AND RECOGNITION 

 Detection Recognition 

 Detected / Total Rate Recognized / Detected Rate 

Image 1 42 / 42 100% 42 / 42 100(%) 

Image 2 62 / 62 100% 62 / 62 100(%) 

Image 3 74(1) / 74 97.3% 64 / 74 86.4(%) 

Image 4 85(4) / 88 87.5% 65 / 85 76.5(%) 

Image 5 89(1) / 92 96.7% 85 / 89 95.5(%) 

Total 382(6) / 388 96.3% 318 / 382 91.7(%) 

 
Recognition results of our system are shown in the following. 

Fig. 11 shows the recognition results for the musical score 
Twinkle, Twinkle, Little Star. All the musical notes, including 
the pitches and beats, were successfully detected and 
recognized. The detected musical notes are marked 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1815International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

accordingly. 
 

 

Fig. 11 Recognition results of the musical score Twinkle, Twinkle, 
Little Star 

 
Fig. 12 shows the recognition results for the musical score 

The Swallow. Although the musical score was more 
complicated, all the musical notes, including the pitches and 
beats, were successfully detected and recognized.  

 

 

Fig. 12 Recognition results of the musical score The Swallow 
 

Fig. 13 shows the recognition results for the musical score I 
Will Sing You. The original image was in JPEG compressed 
format. All the musical notes, accidentals, and rests were 
successfully detected and recognized, despite there was a few 
errors in the recognition of the pitches. 

 

 

Fig. 13 Recognition results of the musical score I Will Sing You 

Fig. 14 shows the recognition results for the musical score At 
This Moment. The quality was relatively poor mainly because 
of compression distortion. The recognition results were 
relatively worse than previous scores. 

 

 

Fig. 14 Recognition results of the musical score At This Moment 
 

Fig. 15 shows the recognition results for the musical score 
My Herd. The quality was also relatively poor mainly because 
of compression distortion. The recognition results were 
relatively worse than previous scores especially in beat 
recognition (most recognition failure occurred at dots).  

 

 

Fig. 15 Recognition results of the musical score My Herd 

IV. CONCLUSION 

In this study, we proposed an Automatic Music Score 
Recognition System Using Digital Image Processing. The 
technical approaches included: staff region segmentation, 
image preprocessing, note recognition and accidental and rest 
recognition. Our system was developed to automatically detect 
and recognize musical notes, accidentals and rests in printed 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1816International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

musical scores.  
The results showed that the detection and the recognition 

rates of our system were 96.3% and 91.7%, respectively. While 
the results were limited and could be affected by image quality, 
our system was shown to achieve effective detection and 
recognition for musical symbols, such as notes, accidentals, and 
rests. Ultimately, our system could be incorporated with a 
media player that could play music/songs with inputs of 
musical scores.  

While our system has been demonstrated with success for 
different types of musical scores, our system was still limited 
with respect to the complexities of some musical scores (e.g., 
chords or other complex symbols). Improvement of our 
systems is still required for such musical scores. 

At present, our system was evaluated using personal 
computers with inputs of digital images. The system could be 
further integrated in applications for smart-phones or other 
mobile devices with built-in digital cameras. In addition, this 
system could be also used as a learning tool for players (e.g., 
piano players, guitar players, etc.) to play the music/songs even 
though they may not be familiar with the music/songs. 

REFERENCES  
[1] N. Otsu, “A Threshold Selection Method form Gray-Level Histograms,” 

IEEE Transactions on Systems, pp. 62-66, 1979. 
[2] R.G. Casey and E. Lecolinet, “A Survey of Methods and Strategies in 

Character Segmentation,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, pp. 690-706, 1996. 

[3] Cheng-Lin Liu, M. Koga and H. Fujisawa, “Lexicon-Driven 
Segmentation and Recognition of Handwritten Character Strings for 
Japanese Address Reading,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, pp. 1425-1437, 2002. 

[4] M. Sotoodeh and F. Tajeripour, “Staff Detection and Removal Using 
Derivation and Connected Component Analysis,” IEEE 16th CSI 
International Symposium on Artificial Intelligence and Signal Processing 
(AISP), pp. 54-57, 2012. 

[5] Chen Genfang, Zhang Liyin, Zhang Wenjun and Wang Qiuqiu, 
“Detecting the Staff-lines of Musical Score with Hough Transform and 
Mathematical Morphology,” IEEE International Conference on 
Multimedia Technology (ICMT) , pp. 1-4, 2010. 

[6] A. Dutta, U. Pal, A. Fornes and J. Llados, “An Efficient Staff Removal 
Approach from Printed Musical Documents,” IEEE International 
Conference on Pattern Recognition (ICPR), pp.1965-1968, 2010. 

[7] JaeMyeong Yoo, GiHong Kim and Gueesang Lee, “Mask Matching for 
Low Resolution Musical Note Recognition,” IEEE International 
Symposium on Signal Processing and Information Technology, pp. 
223-226, 2008. 

[8] F.Toyama, K. Shioji and J. Miyamichi, “Symbol Recognition of Printed 
Piano Scores with Touching Symbols,” Pattern Recognition, ICPR 18th 

International Conference, pp. 480-483, 2006. 
[9] F.Rossant and I. Bloch, “Optical Music Recognition Based on a Fuzzy 

Modeling of Symbol Classes and Music Writing Rules,” Pattern 
Recognition Letters, vol.23, pp. 1129-1141, 2002. 

[10] K.T. Reed and J.R.Parker, “Automatic Computer Recognition of Printed 
Music,” in Proceedings of the ICPR, pp.803-807, 1996. 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1817International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


reading content from D:\SD\SearchEngine_ver1\Bee\CN3a_2022.doc

COMPUTER NETWORKS
OPTICAL FIBRES AND COMPONENTS

LABORATORY WORK NO. 3a
OPTICAL FIBERS AND COMPONENTS

1. Objectives
The objective of this work is gaining knowledge on optical fibers and components, link performance analysis and the optical power budget calculus.
2. Theoretical considerations 

2.1 Optical fibers and components
The current laboratory work continues the focus on the Physical layer of the ISO/OSI stack by providing knowledge on optical fibers and components. Furthermore, on part 3b, the main network devices and elements of structured cabling are presented.
Once the drop in the price of optical fibers, and appropriate communications equipment, this has become the environment of choice for new high-speed connections (exterior and interior). 
To transmit data, optical fibers send light signals along glass or plastic cores (of the order tens of microns (μ), which constitutes a wavelength guide for light, obtained from a combination of silicon dioxide and other elements). 

An optical fiber strand is the basic element of an optical fiber cable (a cable contains several strands). A strand has three layers: core, cladding and coating. A fiber optic cable consists of several components: fiber strand(s), buffer, protective materials, outer jacket.

The core is wrapped by material made of silicon dioxide having a refractive index lower than the core called cladding. In order to protect the cladding, this is wrapped in a plastic material. This is called buffer and is wrapped in a material, usually Kevlar, which confers resistance of fiber at the time of installation. Optical fiber buffers are of two categories: tight (a protective covering is applied over the coating of each fiber strand) or  loose-tube (several strands inside a tube filled with a protective gel). For outdoor, long-distance installation, loose-tube fiber is preferred. The last wrapper is the jacket which protects the fiber against abrasive materials, solvents and other factors. The color enclosure in the case of multimode optical fiber is usually orange and in the case of single-mode optical fiber is usually yellow. Each fiber optics cable is composed of two fibers wrapped separately, a fiber being used for transmission and another for the reception, ensuring in this way a full-duplex connection. A cable of optical fiber may contain from two up to hundred separate fiber strands (usually in LANs, up to 24). Figure 2.1 presents the layer of an optical fiber and an optical fiber transversal section.

	 

	Figure 2.1 a. Optical fiber layers               b. Optical fiber transversal section


For the signal to be reflected without loss, the following two conditions need to be met:

· Optical-fiber must have a refractive index higher than the material surrounding it;

· The angle of incidence of light signal must be greater than the critical angle of fiber and of the material surrounding it. The angle of incidence of light signal can be controlled by using the next two factors:

· Numerical aperture of the fiber is the range of angles of the light signal for which the reflection is complete;

· The modes are the ways that the signal light can follow.

Unlike copper-based transmission media, optical fiber is not susceptible to, and it does not generate electromagnetic or crosstalk interference.

Two main optical fibers are commonly used in LANs and WANs: single-mode and multimode. Single-mode optical fiber is used for long distance links and for vertical cabling in buildings (building’s backbone). Multimode optical fiber is commonly used in horizontal and vertical cabling. Multimode fiber has a larger core diameter compared to single-mode. Thus, multimode does not require the same precision as single-mode, resulting in less expensive connectors, transmitters etc.

For the single-mode fiber the core diameter is small enough as to permit only one mode (one way) light signal, being sent in a straight line through the middle of the core. Single-mode optical fiber cables use cores with diameter between 8μ and 10μ. The most used single-mode optical fibers have 9μ diameter and cladding with a diameter of 125μ. They are usually referred as 9/125μ optical fibers. Light source used is the infrared laser. It is recommended caution when using lasers as source of light since it may affect the eyes. Single-mode fibers may transmit data at distances over 100km. The loss on km of single-mode optical fiber is specified by the manufacturer. In the case of single-mode fiber, the refractive index of glass stays constant. This type of glass is called step index glass. 

The core of multimode fiber has a sufficiently large diameter as to permit several modes (several ways) for light signal. Standard multimode optical fiber cables have a core diameter of 62, 5μ or 50μ and cladding with a diameter of 125μ. They are usually referred as optical fibers of 62.5/125μ or 50/125μ. Usually, the light sources used with multimode fibers are Infrared Light Emitting Diode (LED) or Vertical Cavity Surface Emitting Lasers (VCSEL). LED-s are cheaper and require less safety measures than lasers. The disadvantage of LED is that may not transmit light signals at distances as large as lasers. Multimode fibers of 62.5/125 may transmit data at distances of up to 2000m. The loss of multimode optical fiber is specified by the manufacturer. In the case of multimode fiber, the refractive index of glass may be constant (multimode step index glass) or may also decreases from the center to the exterior  (variable or graded-index glass and allows various illuminating modes to reach the receiver at the same time). 
In optical fiber, beside propagation, the light is subjected to two main phenomena: attenuation and dispersion. Attenuation or absorption is essentially due to the presence of hydroxyl ions -OH and of the various metal ions. Light may also be spread by micro crystals, lower than the wavelength, which form at the cooling of the glass. Attenuation limits the length of optical fiber to be used. The dispersion or impulse width widening is mainly due in multimode fibers to the different length of the modes. The chromatic dispersion appears due to the variation of the refraction index function of the light colour or wavelength. The dispersion limits the use of optical fiber in the frequency or in bandwidth. The two limitations multiplied characterize most accurate an optical fiber. 20MHz-km values are obtained for fiber with step index, 1GHz-km for the variable index and 1000GHz-km for the single-mode in which there is no modal dispersion. 

Optical fiber transmitters convert electrical signals in equivalent luminous pulses. There are two types of light source used by transmitters for optical-fiber:
· The LED which produces infra-red light having a wavelength of 850nm or 1310nm. They are used with multimode fibers. Coupling to optical fiber can be improved by using a spherical lens;
· LASER semiconductor diode containing which produces infra-red light having a wavelength of 1310nm or 1550nm. They are used with multimode or single-mode fibers.
There are two types of basic design for LEDs: with surface emission and with edge emission. At surface emission led, the emission of light is perpendicular to the plane of junction through a thin transparent layer. They emit in a geometric radial spectrum. At edge emission led the light is emitted in a plane parallel to the junction at semiconductor edge. The materials used are often compounds III V as GaAs or Al×GA1-XAs for wavelengths of 0.8-0.9 μm and Ga×In1-XPYAs1-y for wavelengths of 1.3-1.6 μm. Emission spectrum of a LED is between 25 to 40 μm for small wavelengths and 50-100 μm for larger wavelengths.
LASER semiconductor diodes, laser diodes (LD), are obtained by introducing a led into an optical resonant cavity. The effect of laser only appears at the existence of a direct current high enough to achieve an inversion of the population of the electrons and holes from the two energy strips of conduction and valence. The current value from which this effect appears is called limit current. Under this current the device acts as an ordinary led. Since the light emitted by a laser is much more coherent than issued by a LED, the efficiency of the optical fiber coupling is higher. Optical power also captured by laser is greater than that emitted by the LED.
An analysis compared between the two types of transmitters is clearly in favour of LD because the possibility to use higher frequencies, narrower spectrum and in favour of the LED due to price and power stability in relation to temperature.
The life expectancy of both devices is equal and is of the order of 10 million hours.
The fiber optics receivers convert luminous pulses into equivalent electrical signals. Semiconductor devices normally used for optical fiber are classified in two types: simple and with internal gain. The first may be called PIN photodiode by type of doping (p intrinsic and n) and the second category is called APD (Avalanche Photo- Diodes). These devices are sensible at 850, 1310 and 1550nm wavelengths, wavelengths used by transmitters for optical fiber. As semiconductor materials are used Si for wavelengths of 800-900 nm and Ge or InGaAsP for 1300 and 1500 nm. Si has optimum sensitivity only within a reduced frequencies range but Ge has an appreciable darkness current and is more sensitive to noise. For this reason last possibility is the best but requires a more sophisticated manufacturing technology and therefore has a higher price. 

In order to connect multiple fibers or for achieving a longer fiber, splices (junctions) may be used. Splices are of two types: mechanical and fusion. Attenuations introduced are lower than 0.5dB (ANSI/TIA-568-C.3 specifies that mechanical or fusions splices shall not exceed a maximum optical insertion loss of 0.3dB). At mechanical splices the two ends of the fiber, carefully cut, cleaned and polished are caught in a rigid mechanical holder that they fix to each other in an fixed ensemble. Fusion splices shall be carried out by heating close to the melting point. At this moment the two fibers are pressed against one another and cooled. These operations shall be preceded by cutting operations and finishing their ends and prior alignment of the two ends which will be connected. Fusion splices also remake draw/bursting resistance of the fiber at approximate 90% of the original value. To protect the splices, splice enclosures are used.
Connectors in the optical fiber allow the connection to ports. The common used connectors are SC (Subscriber Connector) - snap on type, ST (Straight Tip) - twist on type, FC (Ferrule Connector) - screw on type, LC (Lucent Connector) - snap on type and MTP/MPO - push/pull type, for multimode optical fibers and for single-mode optical fibers. Attenuation introduced by an optical connector, even of superior quality is greater than that introduced by a splice, having values of approximately 1 dB. Connectors are high precision mechanical equipment and usually one end of the fiber is in the connector and one is free. In this case attaching a connector shall be reduced to the execution of a splice. Such a solution is usually more advantageous than mounting a connector directly to the end of the fiber because prefabricated connectors ensure the accuracy of mounting much higher. If the optical fiber is ended into an optical fiber terminator for redistribution this end connector is also called pig-tail and is prefabricated type. A special category of connectors is optical cords for distribution or connection. These are special optical fibers with connectors at both ends allowing small fiber curvature radii of approximately 2,5-5 cm. Their color is yellow for single-mode fiber and orange for multimode fiber
Repeaters are optical amplifiers receiving light signals attenuated as a result of the distance traveled through optical fiber, remake the form, power and time parameters of these signals and send them away.

Patch panels for optical fiber are similar with copper cable patch panels, increasing flexibility of the optical networks. For connecting different equipment, an optical fiber patch cord is used (also known as a zip cord - two flexible optical fibers with connectors at each end).
Additionally, several other active or passive devices are used with optical fibers (e.q.: optical couplers - combines or splits optical signals; optical attenuators - reduce the power level of an optical signal; optical isolators; fiber-optic switches; optical multiplexers, etc.).

The ISO/IEC 11801-1 specifies the  requirements for coaxial, twisted-pair copper and optical fiber. The ISO/IEC 11801 (Europe) and ANSI/TIA-568-C (USA and Canada) standards define 7 classes of optical fibers (single-mode and multimode) as shown in table 2.1, together with several important parameters (optical fiber requirements, the cable transmission performance and the physical cable requirements):
Table 2.1 Optical fiber characteristics
	
	Multimode
	Single-mode

	Type
	OM1
62,5/125 μm
	OM2
50/125 μm
	OM3
50/125 μm
	OM4
50/125 μm
	OM5
50/125 μm
	OS1
9/125 μm
	OS2
9/125 μm

	Wavelength
	850, 1300nm
	850, 1300nm
	850, 1300nm
	850, 1300nm
	850, 1300nm
	1300nm, 1550nm
(1383nm)
	1300nm, 1550nm

	Max. attenuation (db/km) 
	2.6 / 
2.4
	3.56 / 2.3
	2.6 / 
1.9
	2.9 / 
1.5
	2.9 / 
1.5
	1
	0.4

	Light source
	LED (Light-Emitting Diode) / 
VCSEL (Vertical Cavity Surface-Emitting Lasers Light Source) 
	LASER (Light Amplification by Stimulated Emission of Radiation)

	Distance/ data rate
	1 Gbps
	275m
	550m
	-
	-
	-
	5-120km

	
	10Gbps
	33m
	82m
	300m
	400m
	400m
	10-80km

	
	40-100 Gbps
	-
	-
	100m
	150m
	150m
	2-80km

	Color
	orange/ slate
	orange
	aqua
	violet/ aqua
	green/ lime
	yellow
	yellow



Incorrect installation of optical fiber has as result the increase in attenuation for the optical signal. The scope or exaggerated than optical fiber may cause cracks in the heart to disperse the signal light. Exaggerated stretching or bending of the optical fiber may cause small cracks of the core which will scatter the light signal. Exaggerated bending of the optical fiber may have as a result the drop in incident angle of the light signal under critical angle of total reflection. For the connector installation the heads must be cut off and finished. After installation, the heads of the optical fibbers, the fiber connectors and ports must be kept clean so that no attenuation will be introduced. Before use of optical fiber cables, their attenuation must be tested. At the design of an optical-fiber links, loss of power signal that can be tolerated must be calculated. This is called the budget of loss of optical link. Loss of power is measured in decibels (dB).
For optical fiber link testing there are several methods: continuity testing, visual fault locator, measurement of optical power output, OTDR and BER test error rate.

Continuity testers are used to test the continuity in an optical fiber. A visual fault locator (VFL) tool allows a technician to identify breaks, macrobends (refers to the minimum bending radius) or poor fusion splices.

The measurement of optical power output determines the loss of power through the optical link by measuring the output power at a known input power. The unit of measurement for optical power is the miliwatt (mW) but for practical reasons shall be used other unit of measure which measure the gain (G) or loss (L) in a system, namely decibel (DB).
The procedure OTDR Optical Time Domain Reflectometer is the procedure by which the attenuation characteristics of an optical fiber and its length may be visualized. This procedure is the only through which can be detected positions such breaks in optical fibre. OTDR displays a graphic having as X axis the fibre length and as Y axis the attenuation. From this graphic, the fiber attenuation and the splices and connectors quality can be deduced. Also can be determined the braking position in the cable if externally the cable is not affected.

The BER test (Bit Error Rate) is the final test for a data link through optical fiber. This test or criterion shows at how many bits transmitted through the fibre an error due fibre will be produced. The BER test must meet the requirements imposed by the producers of the DTE equipment that are coupled to the optical fibre. For computer networks they ask to be less than 1 bit of error at 109/1012 bits transmitted or BER < 10-9/10-12. For the testing is required a generator of random bit sequence and an interface to optical fibre if a loop is tested or two if a single fibre is tested. In order to have significant results, the test must be carried out over a period long enough so as to provide a sufficient number of bits. The test period of one day or two are common if it is working at a large bit rate in the use of optical fibre link and small BER. A counter may automatically count the number of errors detected.

Calculation of optical power budget shall be made according to the following table.
Table 2.2 Optical power budget

	Crt. 
	Optical loss or power
	DB 

	1. 
	The km loss in Optical Fibre db/km X _____km fibre
	_____dB 

	2. 
	The loss in Splices ___dB/splice X _____splices
	_____dB 

	3. 
	The loss in Connectors __dB/connector X ___ connectors
	_____dB 

	4. 
	Losses on other components
	_____dB 

	5. 
	Margin of error
	_____dB 

	6. 
	Total loss on the Link (1+2+3+4+5)
	_____dB 

	7. 
	The power of average emission of the transmitter
	_____dB 

	8. 
	Average power received by the receiver (7-6) 
	_____dB 

	9. 
	The dynamic of the receiver _____dB at _____dB
	 

	10. 
	Receiver sensitivity at a rate of errors given by BER
	_____dB 

	11. 
	Available Remaining Power  (8-10)
	_____dB 


Remarks 

For item 3. the transmitter connection losses to the optical will not be taken into account, these being already included. The amount calculated in item 8. must be within the range of item 9. for the receiver to operate correctly. The amount calculated in item 11 must be positive in order to have a functional optical data link. 
The error margin is due to take into account the average values for all link components. The dispersion of these values around the mean value is known and may take a margin of error large enough to cover deviations from an average with a probability of 99.9% or more. As the number of items is greater and as it is desirable a larger cover probability than a larger error margin will be taken.
Optical emission power of the transmitter is a catalogue data and includes the loss of connection at one end of the optical fiber in the case in which the connection is made in accordance with recommendations. The power is greater at the LASER diodes and smaller at the LED. In the case of LASER usage for relatively short distances an attenuator is necessary so that the receiver will not be destroyed.
Receiver dynamics represents the power range which a receiver can transform in electrical signal without loss of information.
It is also needed a minimum optical power necessary for fulfilling the tolerated error rate condition which for computer networks is situated at the value of 1 bit erroneous at one billion bits transmitted.
Calculus example of the optical power budget 
Optical fiber diameter: Core 62.5μm/Cladding 125μm.
Numerical aperture of the fiber NA: 0.275.
The wavelength of the optical equipment: 1310μm. 

Table 2.3 Calculus example
	Crt. 
	Optical loss or power
	DB 

	1. 
	The km loss in Optical Fiber 1,8db/km X 3,5km fiber
	6,3dB 

	2. 
	The loss in Splices 0,5dB/splice X 2 splices
	1,0dB 

	3. 
	The loss in Connectors 1,0dB/connector X 2 connectors
	2,0dB 

	4. 
	Losses on other components
	0,0dB 

	5. 
	Margin of error
	2,0dB 

	6. 
	Total loss on the Link (1+2+3+4+5)
	11,3dB 

	7. 
	The power of average emission of the transmitter
	-10,0dB 

	8. 
	Average power received by the receiver (7-6) 
	-21,3dB 

	9. 
	The dynamic of the receiver _____dB at _____dB
	

	10. 
	Receiver sensitivity at a rate of errors given by BER
	-26,0dB 

	11. 
	Available Remaining Power  (8-10)
	+4,7dB 


The power at the receiver is in the dynamic of the receiver, which makes possible its function, and the remaining available power is positive, ensuring a viable connection.

There should be taken into account the fact that during the life of the link, aging phenomena may occur, leading to increase the power loss, as well as the fact that optical fiber may be broken accidentally and needs to be spliced. 

A calculation made to the limit endangers the length of service of a link through optical fiber.

3. Lab activity
3.1 The characteristics of various types of optical fibers, components and aspects related to the cabling of computer networks using this transmission environment should be discussed.
3.2 Explore the fiber optic infrastructure deployed in the oceans available at https://www.submarinecablemap.com/
3.3 A 9/125μ single-mode optical fiber having the length of 2,5km and the loss equal to 0,5dB/km, which connects two DTE equipments is considered. The attenuation introduced by splices and connectors is equal to 0,5 and 1dB respectively. The error margin taken into consideration is 3dB. The power of average emission of the transmitter is -15dB, the receiver sensitivity at a rate of errors given by BER 10-9 is -25dB and dynamic of the receiver is in the range -10 ÷ -30dB. Calculate the optical power budget.

Notes

6
7


reading content from D:\SD\SearchEngine_ver1\Bee\CN4.docx

LABORATORY WORK NO. 4
Network Layer – IPv4 Fundamentals

1. Objectives

At the end of the lab, students will be able: to explain the characteristics of the network layer, to describe the operation of the IPv4 protocol, to divide the networks into subnets, to explain the network address translation process, and to implement basic IPv4 network configurations.

2. Theoretical considerations

2.1 Network layer

The OSI Network layer corresponds to the TCP/IP Internet layer. It provides addressing, routing and traffic control services to allow devices to exchange data across networks and contains different types of protocols:
· IP version 4 (IPv4) and IP version 6 (IPv6) routed protocols;
· routing protocols such as Open Shortest Path First (OSPF) or Border Gateway Protocol (BGP);
· messaging protocols such as Internet Control Message Protocol (ICMP).
The network layer performs four basic operations:
· Addressing
· Encapsulation
· Routing
· De-encapsulation





IP protocols have the following characteristics:

· Connectionless
· no connection established between source and destination before data packets transmission;
· no control information (synchronizations, acknowledgments, etc.).

· Best Effort
· unreliable, packet delivery is not guaranteed;
· no mechanism to resend data that is not received, reduced overhead.

· Media Independent
· does not concern itself with the type of frame required at the data link layer or the media type at the physical layer;
· can be sent over any media type: copper, fiber, or wireless.

2.2 IPv4

The packet header is presented below:

	Octet
	0
	1
	2
	3

	Bit
	0
	1
	2
	3
	4
	5
	6
	7
	8
	9
	10
	11
	12
	13
	14
	15
	16
	17
	18
	19
	20
	21
	22
	23
	24
	25
	26
	27
	28
	29
	30
	31

	0
	Version
	IHL
	DSCP
	ECN
	Total Length

	32
	Identification
	Flags
	Fragment Offset

	64
	Time To Live
	Protocol
	Header Checksum

	96
	Source IP Address

	128
	Destination IP Address

	160
	Options



· Version - version field, equal to 4;
· Internet Header Length (IHL) - the size of the IPv4 header;
· Differentiated Services Code Point (DSCP) - originally defined as the type of service (ToS), specifies differentiated services (DiffServ);
· Explicit Congestion Notification (ECN) - allows end-to-end notification of network congestion without dropping packets, optional feature;
· Total Length - defines the entire packet size in bytes, including header and data;
· Identification- identification field, primarily used for uniquely identifying the group of fragments of a single IP datagram;
· Flags - used to control or identify fragments;
· bit 0 – Reserved, must be zero;
· bit 1 – Don't Fragment (DF)
· bit 2 – More Fragments (MF)
· Fragment offset –specifies the offset of a fragment relative to the beginning of the original unfragmented IP datagram;
· Time to live (TTL) – limits a datagram's lifetime;
· in practice, is used as a hop count;
· when the datagram arrives at a router, the router decrements the TTL field by one;
· when the TTL field hits zero, the router discards the packet and sends an ICMP time exceeded message to the sender.
· Protocol –defines the protocol used in the data portion of the IP datagram;
· Header checksum – used for error-checking of the header;
· Source address – the IPv4 address of the sender of the packet;
· Destination address – the IPv4 address of the receiver of the packet;
· Options – rarely used, if IHL is greater than 5, the options field is present.

The addresses can be assigned statically or dynamically.
The address is hierarchical, being composed of two parts: the network part and host part.

	Network ID
	Host ID



The number of bits assigned to the network and host depends on the class to which the address belongs:

	Class
	1st Octet Decimal Range
	1st Octet High Order Bits
	Network/Host ID (N=Network, H=Host)
	Default Subnet Mask

	A
	1 – 126*
	0
	N.H.H.H
	255.0.0.0

	B
	128 – 191
	10
	N.N.H.H
	255.255.0.0

	C
	192 – 223
	110
	N.N.N.H
	255.255.255.0

	D
	224 – 239
	1110
	Reserved for Multicasting

	E
	240 – 255**
	1111
	Experimental; used for research


Note:	* Class A addresses 127.0.0.0 to 127.255.255.255 cannot be used and is reserved for loopback and diagnostic functions.
** 255.255.255.255 is reserved as the IPv4 Broadcast address.
The IPv4 subnet mask is used to differentiate the network portion from the host portion of an IPv4 address. It is, like the IPv4 address, a 32 bits structure. The bits corresponding to the network portion are set to 1 and the bits corresponding to the host portion are set to 0.

	Network ID
	Host ID

	11………..1
	00…………………………………………………..0



The network masks corresponding to the classes are presented below:

Class A: 255.0.0.0 or /8 (11111111.00000000.00000000.00000000)
Class B: 255.255.0.0 or /16 (11111111.11111111.00000000.00000000)
Class C: 255.255.255.0 or /24 (11111111.11111111.11111111.00000000)

Public IPv4 addresses are uniquely assigned addresses and are are globally routed between internet service provider (ISP) routers. There are also blocks of addresses, called private addresses, that are used by most organizations to assign IPv4 addresses to internal hosts. These addresses are not uniquely assigned addresses and are are not globally routed between ISP routers. These blocks of private addresses are presented below.
Class A: 10.0.0.0 - 10.255.255.255		/8
Class B: 172.16.0.0 - 172.31.255.255		/12
Class C: 192.168.0.0 - 192.168.255.255	/16

To allow a device with a private IPv4 address to access devices and resources outside of the local network, the private address must be translated to a public address. This process is called network address translation (NAT) and provides the translation of private addresses to public addresses. A NAT router typically operates at the border of a network. When a device inside the network wants to communicate with a device outside of its network, the packet is forwarded to the border router which performs the NAT process, translating the internal private address of the device to a public, outside, routable address.






The network address has all the host bits set to 0 and the broadcast address has all the bits set to 1. These addresses cannot be assigned to a host. All the other addresses are valid host addresses.

Exercise
Consider the following address: 192.168.1.10/24. Calculate the network and broadcast address, the valid host range, the total number of host bits and the total number of hosts.
IP:	11000000.10101000.00000001.00001010
NM:	11111111.11111111.11111111.00000000
IP logic AND with the NM:
11000000.10101000.00000001.00001010
11111111.11111111.11111111.00000000
--------------------------------------------------
11000000.10101000.00000001.00000000 – Network address (all host bits are set to 0)
192.168.1.0 – Network address
11000000.10101000.00000001.11111111 – Broadcast address (all host bits are set to 1)
192.168.1.255 – Broadcast address
11000000.10101000.00000001.00000001 – First valid host address
192.168.1.1 – First valid host address
11000000.10101000.00000001.11111110 – Last valid host address
192.168.1.254 – Last valid host address
192.168.1.1-192.168.1.254 – Valid host range
Total number of host bits is 8.
Total number of hosts is 28-2=254.

2.3 Subnetting

To create subnets, bits are borrowed from the host ID. A new network mask is created to show the new structure. In the network mask, the bits corresponding to the subnetwork portion are set to 1.


	Network ID
	Host ID

	11………..1
	00…………………………………………………..0

	Network ID
	Subnetwork ID
	Host ID

	11………..1
	11……………………..1
	00……………………0



Exercise
Consider the following address: 192.168.1.0/24. Divide this address in 4 subnets and further divide the fourth subnet into a maximum number of subnets. Specify for the subnets: netmask, network address, broadcast address, the number of host bits, the number of hosts and their address range.

We will borrow 2 bits to obtain 4 subnets. In order to further divide the fourth subnet into a maximum number of subnets, we will reserve for the host portion 2 bits, the minimum possible number.





First /26 subnet:
	Network Subnetwork Host
	

	11000000.10101000.00000001.00000000
	192.168.1.0/26 - Network Address

	11000000.10101000.00000001.00000001
	192.168.1.1/26 - First Host Address

	…
	…

	11000000.10101000.00000001.00111110
	192.168.1.62/26 - Last Host Address

	11000000.10101000.00000001.00111111
	192.168.1.63/26 - Broadcast Address


Netmask: /26 (255.255.255.192)
Network address: 192.168.1.0/26
Broadcast address: 192.168.1.63/26
Number of host bits: 6
Number of hosts: 26-2=62
Hosts address range: 192.168.1.1/26-192.168.1.62/26

First /30 subnet:
	Network Subnetwork Host
	

	11000000.10101000.00000001.11000000
	192.168.1.192/30 - Network Address

	11000000.10101000.00000001.11000001
	192.168.1.193/30 - First Host Address

	11000000.10101000.00000001.11000010
	192.168.1.194/30 - Last Host Address

	11000000.10101000.00000001.11000011
	192.168.1.195/30 - Broadcast Address


Netmask: /30 (255.255.255.252)
Network address: 192.168.1.192/30
Broadcast address: 192.168.1.195/30
Number of host bits: 2
Number of hosts: 22-2=2
Hosts address range: 192.168.1.193/30-192.168.1.194/30

3. Lab activity

3.1 Discuss the theoretical aspects.
3.2 Solve the following problems:
A. Determine the network and broadcast addresses and number of host bits and hosts for the given IPv4 addresses and prefixes:
	IPv4 
Address/Prefix
	Network Address
	Broadcast Address 
	Total Number 
of Host Bits 
	Total Number 
of Hosts

	172.16.104.99/27
	
	
	
	

	198.133.219.250/24
	
	
	
	

	10.1.113.75/19
	
	
	
	



B. Having the following information, compute subnets with the following constrains:
· A number of 62 subnets
· Host IP Address: 172.16.0.0
· Original Subnet Mask 255.255.0.0

C. Having the following information, compute subnets with the following constrains:
· A maximum number of 29 hosts/subnet
· Host IP Address: 192.168.200.0 
· Original Subnet Mask 255.255.255.0

D. Having the following information, compute subnets with the following constrains:
· A number of 250 subnets
· Host IP Address: 10.0.0.0
· Original Subnet Mask 255.0.0.0

3.3 Test the following commands (using Command Prompt on Windows OS or Terminal in Linux OS):

· Command: ipconfig /all (on Windows OS) and ifconfig (on Linux OS)
· Role: displays all network configuration values for your network interface cards

· Command: ipconfig /release and ipconfig /renew (on Windows OS) and dhclient (on Linux OS)
· Role: refreshes DHCP and DNS values

· Command: ping
· Role: troubleshoots network connectivity; verifies IP connections, using ICMP packets

· Command: tracert (traceroute on Linux)
· Role: troubleshoots network connectivity; resolves the path to an IP destination, using ICMP packets

· Command: nslookup
· Role: performs DNS queries

· Command: route print 
· Role: displays the routing table of the host device

· Command: netstat
· Role: network statistics tool

· Command: arp -a 
· Role: displays the ARP cache (mapping of IP address to a physical addresses)

Hint: you can use online operating systems to test various commands (e.g. https://bellard.org/jslinux/ for Alpine Linux or Windows 2000)

3.4 Using Wireshark, capture different types of IP packets and analyze their headers. For example:
· capture ping traffic by filtering the ICMP protocol filter 
· capture nsloookup traffic by filtering the DNS protocol filter
· etc.

3.5 Configure and test the following network using Packet Tracer:






Considering IP address 172.16.0.0 /16, compute 2 subnets and assign the correct IP address to the routers’ interfaces and to the host computers (PC0 and PC1).

Step 0: In order  to show the interface name and numbers, go to Options -> Preferences and check “Always Show Port Labels in Logical Workspace”



Step 1: Create the two subnets

Step 2: Before configuring the network devices, assign a unique IP address and he corresponding subnet mask to each network port:

	Device
	Interface
	IP Address
	Subnet mask

	PC0
	 Fa0
	172 . ___ . ___ . ___
	___ . ___ . ___ . ___

	Router0
	Gig0/0
	___ . ___ . ___ . ___
	___ . ___ . ___ . ___

	Router0
	Gig0/1
	___ . ___ . ___ . ___
	___ . ___ . ___ . ___

	PC1
	Fa0
	___ . ___ . ___ . ___
	___ . ___ . ___ . ___



Step 3: Configure the router using the commands provided in steps 3.x below. The commands provide sample interface names and IP addresses. You must use the interface names and the IP addresses filled in the previous table:

Example on configuring the depicted topology

COMPUTER NETWORKS
Network Layer – IPv4 Fundamentals






Step 3.1: Enter configuration mode on the router
Router>enable
Router#configure terminal 
Router(config)# 

Step 3.2: Assign static IPv4 address to the router interfaces

Router(config)#interface fastethernet 0/0
Router(config-if)#ip address 192.168.0.1 255.255.255.0 
Router(config-if)#no shutdown
Router(config-if)#exit

Configure the other router interface with the corresponding IP address the same for the other router interface
Router(config)# interface ___
Router(config-if)#ip address ___________ ___________
Router(config-if)#no shutdown 

Step 3.3: Display information about the router configuration

Router#show ip interface brief
Description: Display IP information about router’s interfaces

Router#show ip route
Description: Display IP routing table

Step 4: Configure IP addresses on the PCs using the following screenshots






Test the connectivity.
a. check IP addresses oh hosts computers: PC -> Desktop -> IP Configuration
b. Check connectivity between computers using the ping <target IP> command: PC -> Desktop -> Command prompt



Notes



image5.png

image7.png

image8.png

image4.png

image9.png

image3.png

image11.png

image10.png

image6.png

image2.png

image1.png


reading content from D:\SD\SearchEngine_ver1\Bee\CN6.docx


COMPUTER NETWORKS
Network Layer – IPv6
LABORATORY WORK NO. 7
Network Layer – IPv6

1. Objectives

At the end of the lab, students will be able: to explain the characteristics of the IPv6 protocol, to describe the dynamic IPv6 configuration, to explain the routing process, and to implement basic IPv6 network configurations.

2. Theoretical considerations

2.1 IPv6

IPv6 was developed by the Internet Engineering Task Force (IETF) to overcome the limitations of IPv4.
The main limitation of IPv4 is the exhaustion of addresses because the address request is larger than the address space provided by the 32 bits of the address. The solution for the IPv4 address depletion is private addressing and NAT. This solution in turn creates several drawbacks such as lack of end-to-end connectivity and increased network complexity.
IPv6 provides the following improvements:
· Increased address space based on 128 bit address;
· Improved packet handling due to the simplified header with fewer fields;
· Eliminates the need for NAT by eliminating the need for private addresses.

The packet header is presented below:



· Version - version field, equal to 6;
· Traffic class - equivalent to DiffServ – DS field;
· Payload length – indicates the length of the payload of the IPv6 packet;
· Next header – defines the next level protocol;
· Hop limit – replaces the Time to live field in IPv4;
· Source address – the IPv4 address of the sender of the packet;
· Destination address – the IPv4 address of the receiver of the packet;

IPv6 packet may contain extension headers, placed between IPv6 header and the payload, providing optional network layer information. Routers do not fragment IPv6 packets.

IPv6 addresses are 128 bits in length. The preferred format for writing an IPv6 address is x:x:x:x:x:x:x:x, with each “x” consisting of four hexadecimal values, 4 bits being represented by a hexadecimal digit. Hextet is an unofficial term, it refers to a segment of 16 bits (4 values in hexadecimal). Example of an IPv6 addresses in the preferred format:

	Type
	Format

	Preferred
	2001:0b20:0000:00d7:0000:0000:0000:0012



There are two rules to reduce or compress IPv6 representation. The first rule is to omit the zeros that are at the beginning of each hextet - leading 0s (zeros).

	Type
	Format

	Preferred
	2001:0b20:0000:00d7:0000:0000:0000:0012

	No leading 0s
	2001:b20:0:d7:0:0:0:12



The second rule is to omit the segments (hextets) that contain all the bits 0 and replace them with "double colon" (::). This replacement can be done only once

	Type
	Format

	Preferred
	2001:0b20:0000:00d7:0000:0000:0000:0012

	No leading 0s
	2001:b20:0:d7:0:0:0:12

	Compressed
	2001:b20:0:d7::12

	or
	

	Compressed
	2001:b20::d7:0:0:0:12



Types of IPv6 addresses:
· Unicast
· Uniquely identifies an interface
· The source address must be unicast
· Multicast
· It is used to send a single IPv6 packet to multiple destinations
· IPv6 does not have a broadcast address, but there is a multicast address that provides the same result
· Well-Known Multicast Addresses
· ff02 :: 1: All IPv6 devices
· ff02 :: 2: All IPv6 routers
· ff02 :: 5: All OSPFv3 routers
· ff02 :: a: All EIGRP (IPv6) routers
· Anycast
· Any unicast address that can be assigned to multiple devices
· A packet sent to anycast address is routed to the nearest device with that address

IPv6 prefix length indicates the network portion of an IPv6 address. It is represented in slash notation and can range from 0 to 128. The recommended IPv6 prefix length for LANs is /64. Example of an IPv6 address and prefix length: 2001:b20:0:d7::12/64

	Prefix (64 bits)
	Interface ID (64 bits)

	2001:0b20:0000:00d7
	0000:0000:0000:0012



Types of unicast addresses:
· Global Unicast Address (GUA)
· Globally unique
· Routable on the Internet
· Similar to a public IPv4 address
· Link-local Address (LLA)
· Required for every IPv6-enabled device
· Created even if the device has not been assigned a global unicast address
· For communication with other devices from the same local link
· Allow devices to communicate only on the same link
· Unique only in the local link
· Not routable on the Internet
· They are in the range FE80::/10
· The router's link-local address is usually used as the default gateway
· Unique Local Address (ULA)
· Local addressing within a site or between a limited number of sites



Structure of the Global Unicast Addresses (GUA)
· Global routing prefix
· Network
· Portion of the address assigned by the provider
· Typical /48
· Subnet ID
· For subnetting in an organization
· Usually, 16 bits
· Interface ID
· The equivalent of the host portion of an IPv4 address
· Usually, 64 bits
Example of an IPv6 global unicast address: 2001:b20:0:d7::12/64

	Global Routing Prefix
	Subnet ID
	Interface ID

	2001:0b20:0000
	00d7
	0000:0000:0000:0012



2.2 Host configuration

Methods:
· Static
· Manual configuration of the IPv6 address
· Dynamic
· Stateless Address Autoconfiguration (SLAAC)
· Stateful DHCPv6

A device obtains the IPv6 addressing information dynamically, through Internet Control Message Protocol version 6 (ICMPv6) messages. IPv6 routers periodically send out ICMPv6 Router Advertisement (RA) messages to all IPv6-enabled devices on the network. An RA message will also be sent in response to a host sending an ICMPv6 Router Solicitation (RS) message, which is a request for an RA message.
The ICMPv6 RA message is a suggestion to devices on how to obtain IPv6 addressing information. The ICMPv6 RA message includes the following:
· Network prefix and prefix length
· Default gateway address
· DNS addresses and domain name

There are three methods for RA messages:
· Method 1: SLAAC - prefix, prefix length, and default gateway address
· Method 2: SLAAC with a stateless DHCPv6 server – partial information, the rest of the information, such as DNS addresses, needs to be obtained from a stateless DHCPv6 server
· Method 3: Stateful DHCPv6 (no SLAAC) - default gateway address, the rest of the information, needs to be obtained from a stateful DHCPv6 server

The decision of how a client will obtain IPv6 addressing information depends on the settings within the RA message. An ICMPv6 RA message includes three flags to identify the dynamic options available to a host, as follows:
· A flag - Address Autoconfiguration flag. Use Stateless Address Autoconfiguration (SLAAC) to create an IPv6 GUA.
· O flag - Other Configuration flag. Other information is available from a stateless DHCPv6 server.
· M flag - Managed Address Configuration flag. Use a stateful DHCPv6 server to obtain an IPv6 GUA.

· Method 1 - SLAAC



· Method 2 - SLAAC with a stateless DHCPv6 server



· Method 3 - Stateful DHCPv6 (no SLAAC)



3. Lab activity

3.1 Discuss the theoretical aspects.

3.2 Consider the network topology below:



Step 1: Before configuring the network devices, discuss the IPv6 address assignment in the table below:

	Device
	Interface
	IPv6 Address

	Laptop 1
	Fa0
	DHCPv6

	Laptop 2
	Fa0
	DHCPv6

	R1
	Gig0/0
	2001:1:1:1::1/64
fe80::1 link-local 

	R1
	Gig0/1
	2001:1:1:2::1/64

	R2
	Gig0/1
	2001:1:1:2::2/64
fe80::2 link-local 

	R2
	Gig0/0
	2001:1:1:3::1/64


Note*: pay attention to the interface names of the router you are using, some routers may only have FastEthernet interfaces.

Step 2: Assign hostnames, enable IPv6 routing and assign static IPv6 addresses to router interfaces.

Example:
R1>enable 
R1#configure terminal 
Enter configuration commands, one per line.  End with CNTL/Z.
Router(config)#hostname R1
R1(config)#ipv6 unicast-routing 
R1(config)# interface gigabitEthernet 0/0
R1(config-if)#ipv6 address fe80::1 link-local 
R1(config-if)#ipv6 address 2001:1:1:1::1/64
R1(config-if)#no shutdown

Use the following command to display the IPv6 addresses configured on the router:
R1#show ipv6 interface brief

Step 3: Configure a static route on each router pointed to the IPv6 address of Gig0/1 on the other router. For R1 router specify the LLA address for the next hop and for the R2 router specify the GUA address the next hop. Discuss the differences!

R1(config)#ipv6 route 2001:1:1:3::/64 GigabitEthernet0/1 FE80::2

R2(config)# ipv6 route 2001:1:1:1::/64 2001:1:1:2::1

Use the following command to display the IPv6 routing table:
Router#show ipv6 route

Step 4: Verify SLAAC Address Assignment.





Step 5: Test the connectivity between end devices from opposite networks.
a. ping <target IP>
b. tracert <target IP>



Step 6: Replace the configured static routes with default routes and test the connectivity between end devices from opposite networks. In IPv6, the default route is ::/0.

R1(config)#no ipv6 route 2001:1:1:3::/64 GigabitEthernet0/1 FE80::2
R2(config)#no ipv6 route 2001:1:1:1::/64 2001:1:1:2::1

R1(config)#ipv6 route ::/0 ______________________________________
R2(config)#ipv6 route ::/0 ______________________________________

Step 7: Configure R1 to provide stateless DHCPv6 for Laptop 1.

R1(config)#ipv6 dhcp pool R1_NET1
R1(config-dhcpv6)#dns-server 2001:1:1:1::F
R1(config-dhcpv6)#domain-name NET1.com
R1(config-dhcpv6)#exit
R1(config)#interface gigabitEthernet 0/0
R1(config-if)#ipv6 nd other-config-flag 
R1(config-if)#ipv6 dhcp server R1_NET1

Step 8: Verify stateless DHCPv6 Address Assignment.







Step 9: Configure R2 to provide stateful DHCPv6 for Laptop 2.

R2(config)#ipv6 dhcp pool R2_NET3
R2(config-dhcpv6)# address prefix 2001:1:1:3::/64
R2(config-dhcpv6)#dns-server 2001:1:1:3::A
R2(config-dhcpv6)#domain-name NET3.com
R2(config-dhcpv6)#exit
R2(config)#interface gigabitEthernet 0/0
R2(config-if)#ipv6 nd managed-config-flag
R2(config-if)#ipv6 dhcp server R2_NET3

Step 10: Verify stateful DHCPv6 Address Assignment





Step 11: Test the connectivity between end devices from opposite networks.
a. ping <target IP>
b. tracert <target IP>




Notes



12

11

image3.png

image4.png

image5.png

image6.png

image7.png

image8.png

image9.png

image10.png

image11.png

image12.png

image13.png

image14.png

image1.png

image2.png


reading content from D:\SD\SearchEngine_ver1\Bee\CN7.docx

LABORATORY WORK 
Application Layer: Network programming with sockets


1. Objectives
Prerequisite: Use a working software environment for your preferred programming language (Java, C#, Python, C/C++, etc.) 
At the end of the activity, students will be able to write software for socket applications and debug network applications using Wireshark.

2. Theoretical considerations
The current practical work focuses on the Transport and Application layers of the ISO/OSI stack (Figure 8.1).

Figure 8.1 Network stack models and PDU naming in each level. The arrows indicate the addressed layers in the current activity
This practical activity addresses the programming side of software engineering and communication offered through the use of network sockets in a desktop environment. Socket programming is available in any high level programming language and sockets are transmitting information at the Application Layer. Sockets are used in different types of applications, such as: Client-Server, peer-2-peer systems, inter-process communication (on the same machine).
Network sockets can be constructed to use both IPv4 and IPv6 addresses. A socket is the combination of an IP address and a port number for use in a network application. A network application provides connectivity between different network devices. It is not possible to bind a socket to a port that is already in use by any other application, however the same port may be used concurrently by TCP and UDP transport layer protocols. The IP addresses identify the network device, but the port number uniquely identifies each running application on the current network device.
The operations that an application can perform on a socket are the following:
· Create - Creation of a socket object 
· Bind - Configure the socket object to use a local pair of IP address and port number to accept connections
· Listen - Program the socket to wait for incoming connections
· Accept - Accept the incoming connection
· Connect - This operation is used by a client that wants to connect to a server
· Send - Used to send data over the socket to the remote destination
· Receive - Used to receive data which is sent from a remote location
· Close - close the connection between the two sockets
2.1. Working with sockets on the local machine
· In order to simulate a network on the local machine, the entire available loopback range: 127.0.0.0 - 127.255.255.255 can be used. The loopback network interface is available only on the local host and is mainly used for diagnostics and standalone network applications. Therefore, a simulated local network can use these IP addresses for communication. In order to test and confirm that this range can be used, a ping command can be run from the local terminal to verify connectivity to said IP addresses (Figure 8.2):

Figure 8.2 Loopback addresses testing
· It is also possible to assign multiple valid IP addresses on the local interface, but this has to be done manually by statically allocating IP addresses to the interface. In this case, running the ipconfig command would show all the IP addresses assigned to the same interface. See an example below (Figure 8.3):

Figure 8.3 IP configuration view - CLI
· After having assigned the IP addresses, sockets can now be created to use these IP addresses.

2.2. TCP Sockets
· TCP (Transmission Control Protocol) sockets are connection oriented and represent a reliable data transmission mechanism that allows data to be received and processed in the same order it was transmitted.
· The Figure 8.4 shows a Wireshark traffic capture on the “Adaptor for loopback traffic capture”. The screenshot shows a client-server communication via sockets using the loopback addresses. The applied filter is tcp.port == 1234. The server is bound to the 127.0.0.1 address and awaits connections on port number 1234 while the client binds on the 127.0.0.2 address sending a payload of 14 bytes to the server.

Figure 8.4 Wireshark capture of TCP socket communication
· The screenshot highlights the TCP mechanism represented by acknowledgement (ACK) packets. The first three packet exchanges (Figure 8.4) represent the 3-way handshake which is needed to establish the connection for any TCP connection (Figure 8.5) and following that the packet sending the payload is visible. This handshake assures that both hosts want to communicate and acknowledge the other host’s intention to communicate.

Figure 8.5 TCP 3-way handshake
· The Wireshark image shows a socket communication which remains open.
· Answer the following question while working on the practical activity: If the socket connection is closed, what are the TCP flags that are set in order to close the connection?
2.3. UDP Sockets
· In contrast with the TCP sockets, UDP (User Datagram Protocol) sockets are not connection oriented and they do not provide reliable communication. This means they do not guarantee that network packets are delivered to the destination. The Figure 8.6 represents a Wireshark capture (again on the “Adaptor for loopback traffic capture”) of a UDP communication between two hosts. The applied filter is udp.port == 1234. As can be seen, there is no handshake performed and there aren’t any ACK packets being transmitted.

Figure 8.6 Wireshark capture of UDP socket communication
TCP and UDP socket communications are presented in Figure 8.7 a and b.
	
	


	1. TCP socket communication
	1. UDP socket communication


Figure 8.7 Socket communications

1. Implementation template
· A network device can function in 3 modes:
· Server: Receiving device
· Client: Sending device
· Relay: Acting as an intermediary node in a communication and acts as both sending and receiving device. This type of network node can be encountered in Wireless Sensor Networks (WSN) where not all sensor nodes are in the wireless range of the collector device, therefore some nodes need to forward the information to the sink node (the collector node).
· This chapter provides a template for implementing the relay communication node using OOP concepts (the template is written in pseudocode, not in a particular programming language). This is not the only possibility to organize the code, students can choose any software design methodology they are comfortable with.
	Relay node implementation template

	class RelayNode {
public:
    RelayNode(IPAddress, serverPortNr) {
        m_server.listen(IPAddress, serverPortNr);
        m_client.bind(IPAddress);

        m_server.onReceive() => {
            ByteArray receivedData = m_server.readData();
            m_client.connectToHost(m_nextHopIpAddress, m_nextHopPortNr);
            m_client.sendData(receivedData);
            m_client.close();
        }
    }
    void setNextHopInformation(nextHopIPAddress, nextHopServerPortNr) {
        m_nextHopIpAddress = nextHopIPAddress;
        m_nextHopPortNr= nextHopServerPortNr;
    }

private:
    Server m_server; // server instance accepting connections
    Client m_client; // client instance sending data to the next hop
    IPAddress m_nextHopIpAddress; // next hop address used by the client instance
    int m_nextHopPortNr; // next hop port nr used by the client instance
}

void main() {
    RelayNode relay(127.0.0.1, 1234);
    relay.setNextHopInformation(127.0.0.2, 2345)
    …
    // run application event loop
}


3. Practical activity
· Each student will be assigned one of the topologies below and the simulation scenario has to be implemented in software.
· Besides the constraints imposed by each simulation scenario, the common tasks for each implementation are the following:
· Use a programming language of choice to implement the network simulation
· Use the loopback address range for addressing: 127.0.0.0 – 127.255.255.255
· Test the implementation using Wireshark
· Deliver the implementation (source code or link to online code versioning repository)
· Provide a Wireshark capture to prove the communication between different IP addresses
· Inspect the ratio between total delivered payload against the relevant application layer traffic / the ratio between the total packet length (headers and data) compared to the length of data sent (use Wireshark statistics or manual packet inspection)
· Depending on the implemented simulation, research the headers for TCP and/or UDP protocols. Using Wireshark, identify the header elements in the captured traffic

3.1 Ring communication
· Three computers are communicating in a single direction creating a loop (Figure 8.8)
· One of the computers initiates the communication sending the value ‘1’
· Upon receipt, each network device increments the received value and sends it to the next device
· The communication ends when the delivered payload reaches the value ‘100’
· Implementation hints:
· Implement a single class which is instantiated 3 times with different communication parameters (reuse the code and do not duplicate it for each instance)
· All communication uses TCP sockets (optional)

Figure 8.8 Ring communication network topology

3.2 Node selector
· There are three nodes in the topology: N1, N2, N3 (Figure 8.9)
· N1 increments a value 100 times and after every increment it sends the value to either N2 or N3 which are selected randomly for transmission
· When N2 receives an integer value which is a multiple of 3 it will send an ACK packet back to N1
· When N3 receives an integer value which is a multiple of 5 it will send an ACK packet back to N1
· Implementation hints:
· Implement a single class for N2 and N3 which is instantiated with different communication parameters (reuse the code and do not duplicate it for each instance)
· All communication uses UDP sockets (optional)

Figure 8.9 Node selector network topology

3.3 Relay nodes
· There are four nodes in the topology (Figure 8.10), Sender and three possible destinations (D1, D2, and D3)
· The Sender node is transmitting 100 packets containing an integer number randomly to one of the 3 possible destinations (D1, D2 or D3)
· After each packet transmission the integer number is incremented
· Every node can only send data to the next hop to which it is connected to, therefore a packet from the Sender to D3 must pass through D1 and D2


Figure 8.10 Relay nodes network topology
· Implementation hints:
· The data payload that is transmitted via the socket has to contain the target IP address, so the payload has the following format (Figure 8.11):
	Target IP address
	Value


Figure 8.11 Payload format
· Every time a node receives a packet it verifies whether the received payload’s target IP address is the same as the current node IP address. If it is identical, the communication stops here, otherwise the data is forwarded to the next hop.
· Implement a single class for D1, D2 and D3 which is instantiated with different communication parameters (reuse the code and do not duplicate it for each instance)

image6.png

image7.png

image8.png

image9.png

image10.png

image11.png

image1.png

image2.png

image3.png

image4.png

image5.png


reading content from D:\SD\SearchEngine_ver1\Bee\Comisii burse 2024-2025.pdf


     
                                            

                  FACULTATEA DE AUTOMATICĂ ȘI CALCULATOARE 
                          Str. G. Barițiu nr 26-28, Cluj Napoca, 400027, ROMÂNIA 
                                                   Telefon +40 264 401218 
                                                           https://ac.utcluj.ro/ 
 

 

 

 

 

DECIZIA nr. 11 din 19.09.2024 

- extras - 

 

În Consiliul Facultății din data de 19.09.2024, s-au aprobat componențele următoarelor 

comisii  pentru anul universitar 2024-2025: 

1. Comisiei de analiză, evaluare a dosarelor și atribuire a burselor  
Prodecan: prof.dr.ing. Mihaela DÎNȘOREANU 
Secretar șef: Luciana ABRUDANU 
Student: Cristian Mihai FILIP  - an IV Ca ro 
Student: Aurelia Georgiana DUȚULESCU - an III Au ro 
 

2. Comisia de specialiști pentru burse de performanță științifică: 
Prof.dr.ing. Gheorghe SEBESTYEN 
Conf.dr.ing. Mihai HULEA 
 

3. Comisia de contestații burse: 
Prodecan: conf.dr.mat. Daniela INOAN 
Dr. ec. Simona SABO-MARȚIȘ 
Student Natalia Georgiana BONCEA - an IV Ca ro 
Student Antonia Maria FILIMON - an IV Au ro 
 
 
 
 
 

DECAN, 

Prof. dr. ing. Vlad MUREȘAN 

 
 



reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-28-32.pdf


Image Processing - Laboratory 4: Geometrical features of binary objects 

 

 

27 

4. Geometrical features of binary objects 
 

4.1. Introduction 

 
This lab work presents some important geometric properties of binary images and the 

algorithms used for computing them. The properties described are the area, the center of mass, the 

elongation axis, the perimeter, the thinness ratio, the aspect ratio and the projections of the binary 

image.  

 

4.2. Theoretical considerations 
  

After applying segmentation and labeling algorithms, we obtain a new image where each object 

can be referred separately: 

 

𝐼𝑖(𝑟, 𝑐) = {
1,      if 𝐼(𝑟, 𝑐) ∈ object labeled 'i'
0,      otherwise 

 

 

where 𝑟 ∈ [0. . . 𝐻𝑒𝑖𝑔ℎ𝑡 − 1] and 𝑐 ∈ [0. . . 𝑊𝑖𝑑𝑡ℎ − 1]  
 

An object ‘i’ in the image is described by the function:  

The geometric properties of the objects can be classified into two categories:  

• position and orientation properties: the center of mass, the area, the perimeter, the 

elongation axis; 

• shape properties: aspect ratio, thinness ratio, Euler’s number, the projections, the Feret 

diameters of the objects. 

 

4.2.1. Area 

𝐴𝑖 = ∑ ∑ 𝐼𝑖(𝑟, 𝑐)

𝑊−1

𝑐=0

𝐻−1

𝑟=0

 

 

The area Ai is measured in pixels and it indicates the relative size of the object. 

 

4.2.2. The center of mass 
 

�̄�𝑖 =
1

𝐴𝑖
∑ ∑ 𝑟𝐼𝑖(𝑟, 𝑐)

𝑊−1

𝑐=0

𝐻−1

𝑟=0

 

�̄�𝑖 =
1

𝐴𝑖
∑ ∑ 𝑐𝐼𝑖(𝑟, 𝑐)

𝑊−1

𝑐=0

𝐻−1

𝑟=0

 

 

The equations above correspond to the row and column where the center of mass is located. 

This attribute helps us locate the object in a bi-dimensional image. 

 

4.2.3. The axis of elongation (the axis of least second order moment) 

 

𝑡𝑎𝑛( 2𝜑𝑖) =
2 ∑ ∑ (𝑟 − �̄�𝑖)(𝑐 − �̄�𝑖)𝐼𝑖(𝑟, 𝑐)𝑊−1

𝑐=0
𝐻−1
𝑟=0

∑ ∑ (𝑐 − �̄�𝑖)2𝐼𝑖(𝑟, 𝑐) − ∑ ∑ (𝑟 − �̄�𝑖)2𝑊−1
𝑐=0 𝐼𝑖(𝑟, 𝑐)𝐻−1

𝑟=0
𝑊−1
𝑐=0

𝐻−1
𝑟=0

 



Technical University of Cluj-Napoca, Computer Science Department 

 

 

28 

If both the nominator and the denominator of the above equation are equal to zero, then the 

object has a circular symmetry, and any line that passes through the center of mass is a symmetry 

axis. 

For finding the direction of the line (the angle) one must apply the arctangent function. The 

arctangent is defined on the interval (-∞, +∞) and it takes values in the interval  

(-π/2, π/2). The evaluation of the arctangent becomes unstable when the denominator of the fraction 

tends to zero.  

The signs of the numerator and of the denominator are important for determining the right 

quadrant in which the result lays. The arctangent function does not make the difference between 

directions that are opposed. For this reason, the usage of the function “atan2” is suggested. The 

“atan2” function has as arguments the numerator and the denominator of such fraction, and it returns 

a result in the interval (-π, π). 

The axis of elongation gives information about how the object is positioned in the field of 

view, more exactly, its orientation. The axis corresponds to the direction in which the object (seen as 

a plane surface of constant width) can rotate most easily (has a minimum kinetic moment).  

 After the i  angle is found, the correctness of the resulted value can be validated by drawing 

the axis of elongation. The axis of elongation will correspond to the line that passes through the center 

of mass and determines the i  angle with Ox axis.  

   

4.2.4. The perimeter  

 

 The perimeter of the object helps us determine the position of the object in space and it also 

gives information about the shape of the object. The perimeter can be computed by counting the 

number of pixels on the contour (pixels of value 1 and having at least one neighbor pixel of value 0). 

 A first approach to contour detection is the scanning of the image, line by line and counting 

the number of pixels in the object that satisfy the condition mentioned above. A main disadvantage 

of this method is that we cannot distinguish the exterior contour from the interior contours (if they 

exist, they are generated by the holes in the object). As the pixels of digital images represent 

distributions on a rectangular raster, the length of curves and oblique lines in the image cannot be 

correctly estimated by counting the pixels. A first correction is given by the multiplication by π/4 of 

the perimeter that resulted in the previous algorithm. There are other methods for length correction. 

These methods take into account the type of neighborhood used (4 neighbors, 8 neighbors etc.). 

 Another method for detecting the contour of an object involves the usage of an existing 

algorithm for edge detection, the thinning of the edges until they become 1 pixel thick and in the end 

the counting of the resulted edge pixels. 

 Methods of type “chain-codes” represent complex methods for contour detection and offer a 

high accuracy. 

 

4.2.5. The thinness ratio (circularity) 

 

 

 The function above has the maximum value equal to 1, and for this value we obtain a circle. 

The thinness ratio is used for determining how “round” an object is. If the value of T is close to 1, the 

object tends to be round. 









=

2
4

P

A
T 



Image Processing - Laboratory 4: Geometrical features of binary objects 

 

 

29 

 The value of the thinness ratio also offers information on how regular an object is. The objects 

that have a regular contour have a greater value of T than the objects of irregular contours. The value 

1/T is called irregularity factor of the object (or compactness factor). 

 

 

4.2.6. The aspect ratio 

 

 This property is found by scanning the image and keeping the minimum and maximum 

values of the lines and columns that form the rectangle circumscribed to the object. 

 

 

 

4.2.7. The projections of the binary object 

 

 The projections give information about the shape of the object. The horizontal projection 

equals the sum of pixels computed on each line of the image, and the vertical projection is given by 

the sum of the pixels on the columns.  

 

 

ℎ𝑖(𝑟) = ∑ 𝐼𝑖(𝑟, 𝑐)𝑊−1
𝑐=0       𝑣𝑖(𝑐) = ∑ 𝐼𝑖(𝑟, 𝑐)𝐻−1

𝑟=0  

 

 

 The projections are used in applications of text recognition in which the interest object can be 

normalized.  

 

4.3. Implementation details 
 

In order to distinguish between the various objects present in an image, we will suppose that 

each one of them is painted using a different color. These colors may be the result of a previous 

labeling step or may be generated manually (see Fig. 4.1). 

 

 
Fig. 4.1 Example of a labeled image on which the described algorithms could be tested 

1

1

minmax

minmax

+−

+−
=

rr

cc
R



Technical University of Cluj-Napoca, Computer Science Department 

 

 

30 

There are various approaches for implementing the geometrical properties extractors:  

 

4.3.1. Compute the geometrical features for all objects in an image at once 

 

For each object, the compound pixels are selected based on the object unique label (color) and 

the corresponding geometrical features are computed. This procedure is applied to each object from 

the input labeled image. 

 

4.3.2. Compute the geometrical features for a specific object selected with the mouse 

 

The user should position the mouse pointer over a pixel belonging to the desired object and 

click on it. In response to this action, the geometrical features of the desired object should be 

computed and displayed in the standard output. 

 

In order to add an event handler, we will use the setMouseCallback function from OpenCV, 

which has the role to set a handler for the mouse in a specific window.  

 
void setMouseCallback(const string& winname, MouseCallback onMouse, void* userdata=0) 

winname – window title, 

onMouse – callback function name that is called when a mouse event occurs on the winname 

window, 

userdata – optional parameter that may be passed to the callback function. 

 
The computation of the desired features will be implemented in onMouse function. 

 
void onMouse (int event, int x, int y, int flags, void* param) 

event – is the mouse event and can take the following values: 

- EVENT_MOUSEMOVE 

- EVENT_LBUTTONDOWN 

- EVENT_RBUTTONDOWN 

- EVENT_MBUTTONDOWN 

- EVENT_LBUTTONUP 

- EVENT_RBUTTONUP 

- EVENT_MBUTTONUP 

- EVENT_LBUTTONDBLCLK 

- EVENT_RBUTTONDBLCLK 

- EVENT_MBUTTONDBLCLK 

x, y – are the x and y coordinates where the event occurred, 

flags – specific condition whenever a mouse event occurs, 

param – corresponds to the userdata pointer passed through setMouseCallback function. 
 

In OpenCVApplication framework, an example of event handler is presented in the 

testMouseClick() function.  
 

In order to draw the elongation axis, use the line function from OpenCV to draw the line: 
  

void line( Mat img,  Point pStart, Point pEnd, Scalar color, int thickness ) 

 img – image where the line segment is drawn 

 pStart, pEnd – the two points that define the line segment 

 color – line color 

 thickness – line thickness 



Image Processing - Laboratory 4: Geometrical features of binary objects 

 

 

31 

4.4. Practical work 
 

1. For a specific object in a labeled image selected by a mouse click, compute the object’s area, 

center of mass, axis of elongation, perimeter, thinness ratio and aspect ratio.  

a. Display the results in the standard output 

b. In a separate image (source image clone): 

o Draw the contour points of the selected object 

o Display the center of mass of the selected object 

o Display the axis of elongation of the selected object by using the line function from 

OpenCV. 

c. Compute and display the projections of the selected object in a separate image (source 

image clone). 

2. Create a new processing function which takes as input a labeled image and keeps in the output 

image only the objects that: 

a. have their area < TH_area 

b. have a specific orientation phi, where phi_LOW < phi < phi_HIGH  

where TH_area, phi_LOW, phi_HIGH are given by the user.  

3. Save your work. Use the same application in the next laboratories. At the end of the image 

processing laboratory, you should present your own application with the implemented 

algorithms!!! 

 

4.5. Bibliography 
 

[1] Umbaugh Scot E., Computer Vision and Image Processing, Prentice Hall, NJ, 1998, ISBN 0-13-

264599-8.  


	Image processing
	4. Geometrical features of binary objects
	4.1. Introduction
	4.2. Theoretical considerations
	4.2.1. Area
	4.2.2. The center of mass
	4.2.3. The axis of elongation (the axis of least second order moment)
	4.2.4. The perimeter
	4.2.5. The thinness ratio (circularity)
	4.2.6. The aspect ratio
	4.2.7. The projections of the binary object

	4.3. Implementation details
	4.3.1. Compute the geometrical features for all objects in an image at once
	4.3.2. Compute the geometrical features for a specific object selected with the mouse

	4.4. Practical work
	4.5. Bibliography




reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-34-38.pdf


Image Processing - Laboratory 5: Connected-component labeling 

 

 

33 

5. Connected-component labeling 
 

5.1. Introduction 
 

 This laboratory work presents algorithms for labeling distinct objects from a black and white 

image. As a result, every object will be assigned a unique number. This number, or label, can be used 

to process the objects separately. 

 

5.2. Theoretical foundations 
 

 We will present several algorithms for labeling. The input for the algorithms is a binary image. 

The output is a label matrix which has the same dimensions as the input image. It should be capable 

of storing sufficiently large label values.  

 In the input binary image, the objects are represented as connected components of color black 

(0), the background is assigned the color white (255). To define what a connected component is, we 

need to introduce different neighborhood types. 

 The 4-neighborhood of a position (i,j) is defined to be the set of positions:  

N4(i,j)={(i-1,j), (i,j-1), (i+1,j), (i,j+1)}, 

i.e., the upper, left, lower and right neighbors.  

 The 8-neighborhood consists of all neighboring positions differing by at most 1: 
N8(i,j) = {(k,l) | |k-i|≤1, |l-j|≤1, (k,l)≠(i,j) }, 

so, it includes the 4-neighborhood and the neighbors situated diagonally. 

 When traversing the image in a particular direction we can define the previous neighbors with 

regard to this traversal. The previous neighbors for normal top-down, left-right traversal for a position 

(i,j) is:  

Np(i,j)={(i,j-1), (i-1,j-1), (i-1,j), (i-1,j+1)}. 

 

The presented definitions are illustrated below.  

 

           

 x    x    x  

           
             a) 4-neighborhood          b) 8-neighborhood     c) previous neighbors 

 

We will define a graph generated by a binary image. The set of vertices is formed by all object 

pixel positions. The neighboring object pixels determine the edges of the graph. Two positions are 

neighboring if one is part of the other's neighborhood. We will use N4 and N8, so the generated graph 

is undirected. In this setting a connected component is a set of vertices in which for each pair there is 

path from vertex 1 to vertex 2.  

 

5.2.1. Algorithm 1 - Breadth first traversal 

 

We start the description with a straightforward method for labeling, which relies on breadth 

first traversal of the graph defined on the image. The first step is to initialize the label matrix to zeroes 

which indicates that everything is unlabeled. Then algorithm searches for an unlabeled object pixel. 

If it finds one, it gives it a new label and propagates the label to its neighbors. We repeat this until all 

object pixels are given a label. In the following we present the steps of the algorithm:  



Technical University of Cluj-Napoca, Computer Science Department 

 

 

34 

label = 0    

labels = zeros(height, width) // height x width matrix with 0  

for i = 0:height-1 

 for j = 0:width-1 

  if img(i,j)==0 and labels(i,j)==0 

   label++ 

   Q = queue()  

   labels(i,j) = label 

   Q.push( (i,j) ) 

   while Q not empty 

    q = Q.pop()     

    for each neighbor in N8(q) 

     if img(neighbor)==0 and labels(neighbor)==0 

      labels(neighbor) = label 

      Q.push( neighbor ) 

Algorithm 1. Breadth first traversal for connected-component labeling 

 

The queue data structure maintains the list of points that need to be labeled. Since the queue 

uses a FIFO policy we obtain a breadth first traversal. We mark visited nodes by setting the label for 

their position. Changing the data structure to a stack would result in a depth first traversal of the image 

graph. 

 

5.2.2. Algorithm 2 - Two-pass with equivalence classes 

 

Labeling can be achieved by performing two linear passes over the image and some additional 

processing on a smaller graph. This approach uses less memory. In the previous algorithm we needed 

the store a list of points. If there is a large connected component, the size of the list is roughly the 

same as the size of the image.  

The current algorithm performs the first pass and labels all object pixels with initial labels. 

For each pixel we need to consider the previously visited and labeled pixels, so we use the Np 

neighborhood defined above. After inspecting the labels of the previous positions, we can have the 

following cases: 

• If no previous neighbor was labeled, we create a new label. 

• Otherwise, we take the smallest label, called x, from the neighbors. Afterwards, we mark each 

neighboring label y as equivalent to x. 

We assign the label found in the previous step to the current position and continue. After the 

first pas we have assigned initial labels to each position. However, several labels are equivalent, so 

we need to assign new ones to each equivalence class.  

The equivalence relations define an undirected graph on the labels. This graph is usually much 

smaller than the original graph defined on the whole image. It consists of nodes labeled from 1 to the 

maximum label value. The edges of the graph indicate the equivalence relations. We can apply 

Algorithm 1 on this smaller graph to obtain a new list of labels. All labels equivalent to label 1 get 

relabeled to 1. The next connected component not equivalent to 1 gets relabeled to 2, and so on. A 

new pass over the labels’ matrix is necessary to update the labels. 

  



Image Processing - Laboratory 5: Connected-component labeling 

 

 

35 

label = 0 

labels = zeros(height, width) 

vector<vector<int>> edges(1000) 

for i = 0:height-1 

 for j = 0:width-1 

  if img(i,j)==0 and labels(i,j)==0 

   L = vector() 

   for each neighbor in Np(i,j) 

    if labels(neighbor)>0 

     L.push_back(labels(neighbor)) 

   if L.size() == 0  // assign new label 

    label++ 

    labels(i,j) = label 

   else     // assign smallest neighbor 

    x = min(L) 

    labels(i,j) = x 

    for each y from L 

                    if (y <> x)  

     edges[x].push_back(y) 

     edges[y].push_back(x) 

 

newlabel = 0     

newlabels = zeros(label+1)   // an array of zeroes of length label+1 

for i = 1:label 

 if newlabels[i]==0 

  newlabel++ 

  Q = queue() 

  newlabels[i] = newlabel 

  Q.push( i ) 

  while Q not empty 

   x = Q.pop() 

   for each y in edges[x] 

    if newlabels[y] == 0 

     newlabels[y] = newlabel 

     Q.push( y ) 

           

for i = 0:height-1 

 for j = 0:width-1 

  labels(i,j) = newlabels[labels(i,j)]    

Algorithm 2. Two-pass connected-component labeling 

 

 

 

 

 
Fig. 5.1 Example of a case when the previous neighbors have different labels.  

Labels 1 and 2 are marked as equivalent at this step 

 



Technical University of Cluj-Napoca, Computer Science Department 

 

 

36 

5.3. Implementation details 
 

The following code illustrates how to visit the 4-neighborhood of a pixel. It can be easily 

modified to 8-neighborhood, or to only consider the upper and left neighbors of the pixel. 

 
int di[4] = {-1,0,1,0}; 

int dj[4] = {0,-1,0,1}; 

uchar neighbors[4]; 

for(int k=0; k<4; k++) 

neighbors[k] = img.at<uchar>(i+di[k], j+dj[k]); 

 

Pay attention to stay within the bounds of the image!  

 

Store the labels in a matrix capable of holding the maximum number of labels: 

 

28
 = 256 - uchar (CV_8UC1)  

216 = 65536 - short (CV_16SC1)  

232 ~ 2.1e9 - int (CV_32SC1)  

 

You can use the std∷stack and std∷queue container for storing points for Algorithm 1 

to obtain DFS and BFS traversal, respectively. The points can be instances of structure 

pair<int,int>. Sample code for initializing and performing operations on a queue: 

 
#include <queue> 

queue<pair<int,int>> Q; 

Q.push( pair<int,int>(i,j) ); // add as tail of the queue (newest) 

pair<int,int> p = Q.front();  // access the front element (oldest) 

Q.pop(); // remove the front element 

// access position of p 

i = p.first; j = p.second; 

 

The equivalence relations that define the edges of the smaller graph can be stored using 

adjacency lists in a vector<vector<uchar>>.  Sample code to initialize and insert edges: 

 
// ensure that edges has the proper size 

vector<vector<int>> edges(1000); 

// if u is equivalent to v 

edges[u].push_back(v); 

edges[v].push_back(u); 

 

To display the label matrix as a color image you need to generate a random color for each 

label. You should use the default random generator from the standard library. It is better than a call 

to rand()%256. 

 
#include <random> 

default_random_engine gen; 

uniform_int_distribution<int> d(0,255); 

uchar x = d(gen); 

  



Image Processing - Laboratory 5: Connected-component labeling 

 

 

37 

5.4. Labeling examples 
 

 
 

 
Fig. 5.2 Labeling examples 

 

5.5. Practical Work 
 

1. Implement the breadth first traversal component labeling algorithm (Algorithm 1). You should be 

able to easily switch between the neighborhood types of 4 and 8. 

2. Implement a function which generates a color image from a label matrix by assigning a random 

color to each label. Display the results. 

3. Implement the two-pass component labeling algorithm. Display the intermediate results you get 

after the first pass over the image. Compare this to the final results and to the previous algorithm. 

4. Optionally, visualize the process of labeling by showing intermediate results and pausing after 

each step to illustrate the order of traversal a selected algorithm. 

5. Optionally, change the queue to a stack to perform DFS traversal. 

6. Save your work. Use the same application in the next laboratories. At the end of the image 

processing laboratory, you should present your own application with the implemented 

algorithms!!! 

 

5.6. Bibliography 
 

[1] Umbaugh Scot E., Computer Vision and Image Processing, Prentice Hall, NJ, 1998, ISBN 0-13-

264599-8 

[2] Robert M. Haralick, Linda G. Shapiro, Computer and Robot Vision, Addison-Wesley Publishing 

Company, 1993. 

  


	Image processing
	5. Connected-component labeling
	5.1. Introduction
	5.2. Theoretical foundations
	5.2.1. Algorithm 1 - Breadth first traversal
	5.2.2. Algorithm 2 - Two-pass with equivalence classes

	5.3. Implementation details
	5.4. Labeling examples
	5.5. Practical Work
	5.6. Bibliography




reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 5 FLT (ro).pdf


Laborator 5 

Arbori dezechilibrați și interpretor de expresii postfix 

 
În laboratorul al treilea am aflat cum se stochează simbolurile pe stivă și cum se 

procesează și se propagă valorile semantice (cu ajutorul pseudo-variabilelor dolari) bottom-up în 

arborele sintactic (parse tree). În cazul expresiilor aritmetice, pe stiva de valori erau stocate doar 

valori de tip întreg, care în urma unei reduceri se substituiau tot cu o valoare întreagă. La o 

reducere, partea dreaptă a unei producții se înlocuia cu (se reducea la) partea stângă. 

În laboratorul al patrulea am lucrat și cu liste, fapt pentru care a fost nevoie să definim un 

%union cu un câmp pentru numere întregi și un câmp pentru liste. Pe stiva de valori ajung să 

coexiste și numere și liste, de aceea trebuie să facem stiva omogenă, cu elemente de același tip, 

și anume union. Acest union, în cazul de față, este un fel de wrapper, care conferă o formă 

comună numerelor și listelor. Deși la citirea unui token din input se pune pe stiva de valori doar 

câte un întreg, în urma unei reduceri (când se recunoaște în input o structură sintactică agregată), 

ajunge să se pună pe stiva de valori o valoare de tip agregat. În cazul de față, structura de date 

agregată este lista. 

Așadar, ne putem imagina cum arată arborele sintactic la citirea și crearea unei liste. La 

fiecare pas, pe stiva de valori se pune câte un element de tip întreg dintr-o listă. Când în stiva de 

valori există un întreg SAU un întreg și o listă, acestea vor fi reduse la o singură listă. În regula 

enum din setul de producții (din laboratorul 4) este descrisă compunerea unei liste intern, ca 

structură de date. Regula poate fi recursivă dreapta sau recursivă stânga. În primul caz, se 

introduce un element la începutul listei, iar arborele este dezechilibrat pe dreapta. În al doilea 

caz, se introduce un element la finalul listei, iar arborele este dezechilibrat pe stânga. 

Introducerea unui element la finalul unei liste este o metodă ineficientă, deoarece trebuie 

parcursă toată lista.  

Recursivitate dreapta:       Recursivitate stânga: 

       

 

enum -> NUMBER enum 

      | NUMBER  

 

enum -> enum NUMBER 

      | NUMBER  

 



În primul caz, pe stiva de valori se stochează la fiecare pas toate elementele citite până 

acum din listă. După stocarea ultimului element, începe extragerea de pe stivă și adăugarea 

efectivă în listă a elementelor, începând cu ultimul (cel mai din dreapta) și terminând cu primul 

(cel mai din stânga). Adică se adaugă elementele în lista finală în ordine, de la dreapta la stânga, 

printr-o simplă adăugare pas cu pas în capul unei liste parțiale. În al doilea caz, se păstrează în 

stiva de valori doar elementul care se introduce în listă la pasul curent.  

Să luăm ca exemplu compunerea listei ‘(1 2 3 4). În tabelul următor putem vedea cum 

evoluează stiva de valori la compunerea unei liste recursiv dreapta, respectiv recursiv stânga.  

Recursivitate dreapta Recursivitate stânga 

Stiva de valori: 
  1 
  1 2 
  1 2 3 
  1 2 3 4 
  1 2 3 
  1 2 
  1 

Stiva de valori: 
  1 
  2 
  3 
  4 

Compunerea listei: 
           4 
       3  4 
     2 3 4 
  1 2 3 4 

Compunerea listei: 
  1 
  1 2 
  1 2 3 
  1 2 3 4 

 Următoarea provocare este să creăm un analizor lexico-sintactic pentru a transforma 

expresii aritmetice din formă infix în formă postfix.  

 Exemple:  

 1 + 2 =>    1 2 + 

 (a – 5 + c) * 2 =>   a 5 – c + 2 * 

  a / 2 + – (a – 5 + c) * 2 ^ b =>     a 2 / a 5 – c + – 2 b ^ * + 

 Observăm că inputul poate să conțină variabile, pe lângă numere și operatori. Având în 

vedere că nu putem calcula expresiile, ci trebuie doar să le modificăm forma, le putem stoca sub 

formă de string-uri. În acest caz, canalul de comunicare semantică între analizorul lexical și 

parserul sintactic, yylval, trebuie să accepte string-uri, deci poate fi reprezentat ca un %union cu 

un câmp de string-uri.  

 În acest exercițiu sunt foarte importante prioritățile operațiilor, pentru a asigura o 

transpunere corectă a expresiilor. Ne amintim din laboratorul al treilea că prioritățile operațiilor 

sunt specificate în partea de declarații a fișierului .y, cu %left, %right sau %nonassoc. Ordinea în 

care sunt declarate indică importanța lor: prima are cea mai mică prioritate, iar ultima are cea 

mai mare prioritate. Dacă asociativitatea este pe stânga (%left), atunci o serie de operații cu 



aceleași priorități va fi tratată de la stânga spre dreapta. Dacă asociativitatea este pe dreapta 

(%right), atunci seria va fi tratată din dreapta spre stânga. Există situații în care este nevoie să 

definim priorități particulare. De exemplu, dacă tratăm numere negative, minusul lor (minus 

unar) nu are aceeași prioritate ca minusul de la scădere (minus binar) și nici nu este tratat la fel. 

Așa că vom defini o prioritate specială pentru minusul unar al numerelor negative.  

 

 În setul de producții trebuie să specificăm că minusul numerelor negative are prioritatea 

specială, definită de noi. Prin “%prec MINUSUNAR” se suprascrie precedența care ar fi fost dată 

implicit de ‘-‘. Știm deja că precedența unei reguli este importantă în conflictele shift-reduce, 

când se compară precedența regulii care s-ar reduce cu precedența simbolului care s-ar shifta. 

 

  

Exerciții propuse: 

1. Creați un analizor lexico-sintactic care să preia din input expresii aritmetice scrise în 

formă postfix și să le transforme în formă prefix. Exemplu:     1 2 +    =>    + 1 2 

2. Creați un analizor lexico-sintactic care să citească din input expresii aritmetice în 

formă postfix, fără variabile, doar cu numere, și să afișeze rezultatul calculului. 

Exemplu:   1  2  +    =>   3 

10  5  –  3  +  2  *   =>  16 

%left '+' '-' 

%left '*' '/' 

%left MINUSUNAR 

%right '^' 

expr : expr '+' expr  

     | expr '-' expr  

     | expr '*' expr  

     | expr '/' expr  

     | expr '^' expr  

     | '-' expr %prec MINUSUNAR 

     | '(' expr ')' 

     | NUMBER 

     | VAR 

     ; 



reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 6 și 7 FLT (ro).pdf


Laborator 6 și 7 

Prelucrarea matricilor 

 

Pe parcursul laboratoarelor 6 și 7 vom realiza un analizor lexico-sintactic pentru a prelucra 

matrici și operații pe matrici. Așadar, vom crea o nouă pereche de fișiere lex și yacc. 

Inputul poate fi o atribuire de matrice unei variabile sau o operație aritmetică între 

variabile de tip matrice. Exemple: 

A = 1 0 2 

       0 3 1 ; 

B = 6 11 16 

       0  1  2 ; 

C = 0 1 0 

       2 4 2 ; 

A + B + C ; 

> 7 12 18 

   2  8   5  

A + B – C ; 

> 7 10 18 

   -2  0  1 

 Scopul este să reținem matricile citite în variabile, pentru a putea aplica operații pe ele. 

Dacă variabilele sunt scrise în input cu majuscule, putem crea un vector de 26 de poziții în care 

să stocăm matricile atribuite variabilelor. Tradițional, în domeniul compilatoarelor, acest vector 

se numește tabelă de simboluri. Totuși, dintre simboluri (mai exact, dintre simbolurile 

terminale/tokeni), tabela de simboluri stochează doar identificatorii (variabile și nume de funcții) 

împreună cu informații legate de acestea: valoarea curentă păstrată într-o variabilă, respectiv un 

pointer spre începutul codului unei funcții. 

 

 Pentru a stoca o matrice, putem crea două structuri: una pentru a stoca o înșiruire de 

numere întregi compunând un rând dintr-o matrice, iar alta pentru a stoca o înșiruire de rânduri 

care formează o matrice. Fiecare dintre cele două structuri trebuie să conțină și numărul total de 

elemente dintr-un rând (care practic definește numărul total de coloane din matrice), respectiv 

numărul total de rânduri dintr-o matrice.  

 

matr *mem[26]; 

typedef struct _line{ 

 int elems[MAX]; 

 int no_columns_used; 

} line; 

 

typedef struct _matr { 

 line *rows[MAX]; 

 int no_rows_used; 

} matr; 

 



Având în vedere că pe stiva de valori pot să coexiste atât numere, cât și înșiruiri de numere 

sau înșiruiri de rânduri, înseamnă că yylval trebuie să fie declarat drept un %union cu trei câmpuri. 

 

Setul de producții este format dintr-un set de reguli care descriu inputul (stmt), un set de 

reguli care descriu operațiile aritmetice aplicate pe matrici (expr) și reguli pentru construcția 

rândurilor (row) și a matricilor (matrix).  

 

Tokenul (literalul) ‘;’ indică finalul unei instrucțiuni (statement – stmt), după care ar urma 

un ‘\n’. Tokenul ‘\n’ apare și ca un separator între rândurile dintr-o matrice. După ultimul rând 

dintr-o matrice nu urmează direct ‘\n’, ci urmează tokenul ‘;’ și abia apoi ‘\n’ după finalul 

instrucțiunii.  

Putem observa o comparație între gramatica matricilor și gramatica G1 de la curs: 

 

În gramatica G1, o expresie aritmetică E este definită recursiv ca o enumerare de termeni 

aritmetici T, separați prin tokenul ‘+’. Asemănător, în cazul matricilor, o matrice (matrix) este 

definită recursiv ca o enumerare de rânduri (row), separate între ele prin tokenul ‘\n’. Ca și aspect 

vizual, în G1 o expresie E este o sumă de termeni T (separați prin ‘+’) de la stânga la dreapta, iar 

o matrice (matrix) este o succesiune de rânduri (row) de sus în jos, efectul vertical fiind dat de 

‘\n’-urile dintre rânduri. 

În final, în secțiunea de user subroutines a fișierului .y vom defini funcțiile necesare pentru 

lucrul pe matrici.  

%union { 

  struct _matr *mat; 

  struct _line *lin; 

  int ival; 

} 

 

stmt : VAR '=' matrix ';' 

     | expr ';'  

     ; 

expr : expr '+' expr  

     | expr '-' expr  

     | VAR  

     ; 

matrix : matrix '\n' row  

       | row 

       ; 

row : row NUMBER  

    | NUMBER 

    ; 

E -> E + T 

   | T 

 



Exerciții propuse: 

1. Adăugați o funcție pentru calculul determinantului unei matrice. 

2. Adăugați o funcție pentru realizarea înmulțirii a două matrici. 



reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 8 FLT (ro).pdf


Laborator 8 

Interpretarea arborilor binari în Haskell/ML 

 

Laboratorul 8 constă în crearea unui analizor lexico-sintactic pentru procesarea arborilor 

binari de căutare în sintaxă Haskell și, comparativ, în sintaxă ML. Partea de ML va apărea pe 

fundal color (albastru), iar pentru implementare vom merge pe una dintre cele două sintaxe. Vom 

avea în vedere citirea arborilor și executarea unor operații pe arbori: insert (inserarea unui nod 

într-un arbore) și count (contorizarea nodurilor, diferite de frunzele vide Lf, dintr-un arbore). 

Exemple de input în Haskell: 

 

Exemple de input în ML: 

 

După cum se poate observa în exemple, sintaxa Haskell a unui arbore binar este 

următoarea:  

Iar sintaxa ML a unui arbore binar este: 

  

Node Lf 2 Lf 
> Node Lf 2 Lf 

Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf) 
> Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf) 

count (insert 16 (Node (Node Lf 2 Lf) 15 Lf)) 
> 3 

insert (count (Node Lf 17 (Node Lf 24 Lf))) (insert 12 (Node Lf 10 Lf)) 
> Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf) 

Node(2, Lf, Lf) 
> Node(2, Lf, Lf) 

Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf)) 
> Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf)) 

count(insert(16, Node(15, Node(2, Lf, Lf), Lf))) 
> 3 

insert(count(Node(17, Lf, Node(24, Lf, Lf))), insert(12, Node(10, Lf, Lf))) 
> Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf)) 

Node (Tree Int) Int (Tree Int) 

Node (int, int Tree, int Tree) 

 



Să luăm ca exemplu arborele binar din imaginea următoare: 

 

Reprezentarea arborelui în sintaxă Haskell este următoarea: 

 

Iar reprezentarea în sintaxă ML este: 

 

Pentru a reprezenta în memorie arborii binari de căutare, vom crea o structură cu trei 

câmpuri: unul pentru cheia nodului (de tip int) și două pentru fiii nodului (pointeri la subarborele 

stâng și la subarborele drept).  

 

Pe stiva de valori vor coexista două tipuri: int, pentru numerele citite din input și pentru 

cheile nodurilor, și o structură de tip arbore, pentru a reduce numerele din input la arbori în 

forma potrivită (reducând partea dreaptă a producțiilor la partea stângă). Astfel, yylval va fi un 

union cu două câmpuri: 

 

În ceea ce privește setul de producții, vom avea un set de reguli (expr) care descriu 
inputul. Putem separa instrucțiunile din input în două categorii, în funcție de tipul rezultatului. 
Citirile arborilor și comanda insert vor returna arbori, în vreme ce comanda count returnează un 

Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf) 

Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf)) 

typedef struct _node { 

int key; 

 struct _node *left, *right;  

} node; 

%union { 

 int ival; 

 struct _node *btree; 

} 



număr întreg. Astfel, reies alte două seturi de reguli, unul pentru situațiile din care rezultă un 
arbore (t_expr) și unul pentru cele din care rezultă numere întregi (i_expr). Cel mai important set 
de reguli este cel care descrie construirea unui arbore binar (tree), cu ajutorul celor doi 
constructori de date Haskell/ML pentru arbori binari: constructorul Node cu trei argumente și 
constructorul Lf cu zero argumente. 

 Setul de producții pentru sintaxă Haskell:

 

Setul de producții pentru sintaxă ML: 

 

  

expr : i_expr 

     | t_expr 

     ; 

i_expr : COUNT t_expr 

  |'(' i_expr ')' 

  | NUMBER 

  ; 

t_expr : INSERT i_expr t_expr 

       | '(' t_expr ')' 

       | tree 

       ; 

tree : NODE tree NUMBER tree 

     | '(' tree ')'    

     | LF    

     ; 

expr : i_expr 

     | t_expr 

     ; 

i_expr : COUNT '(' t_expr ')' 

  | NUMBER 

  ; 

t_expr : INSERT '(' i_expr ',' t_expr ')' 

       | tree 

       ; 

tree : NODE '(' NUMBER ',' tree ',' tree ')' 

     | LF    

     ; 



Exerciții propuse: 

1. Implementați o funcție pentru căutarea unui nod într-un arbore.  

Exemple în Haskell: 

find 12 (Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf)) 
> true 
find 17 (Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf)) 
> false 

Exemple în ML: 

 

2. Implementați o funcție pentru ștergerea unui nod dintr-un arbore. Verificați întâi dacă 

nodul căutat există în arbore.  

Exemplu în Haskell: 

delete 12 (Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf)) 
> Node (Node Lf 2 Lf) 10 Lf 

Exemplu în ML: 

 
 

3. Creați o funcție pentru a verifica dacă un arbore binar este echilibrat.  

Exemple în Haskell: 

balanced (Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf)) 
> true 
balanced (Node (Node Lf 2 Lf) 10 Lf) 
> false 

Exemple în ML: 

 

find(12, Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf))) 
> true 
find(17, Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf))) 
> false 

 

delete(12, Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf))) 
> Node(10, Node(2, Lf, Lf), Lf) 

balanced(Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf))) 
> true 
balanced(Node(10, Node(2, Lf, Lf), Lf)) 
> false 



reading content from D:\SD\SearchEngine_ver1\Bee\Model_CV_ro 2v 4.doc

 
Curriculum Vitae 


	INFORMAŢII PERSONALE
	Braica Patricia Maria 

	

	 
	 Satu Mare, Strada Zenit, Z4, cod postal 440174 

	
	 0770644019      

	
	 braica.patricia@yahoo.com 

	
	

	
	Whatsapp, yahoo 

	
	Sexul F | Data naşterii 22/11/2003 | Naţionalitatea Română 


	LOCUL DE MUNCA PENTRU CARE SE CANDIDEAZĂ

POZIŢIA

LOCUL DE MUNCĂ DORIT

STUDIILE PENTRU CARE SE CANDIDEAZĂ

profilul personal
	Participant grup țintă în proiectul „ Studenți motivați în realizarea de stagii de practică corelate cu cerințele pieței muncii - SMART-PRACTICE„


	EXPERIENŢA PROFESIONALĂ
	 


	Scrieţi datele (de la - până la) 
	

	

	

	


	EDUCAŢIE ŞI FORMARE
	 


	Scrieţi datele (de la - până la) 
	Studentă, anul III, Forma de zi
UTCN, specializarea Calculatoare și Tehnologia Informației


	Scrieţi nivelul EQF, dacă îl cunoaşteţi 

	
	Secția: limba engleză 

	
	· OOP on Java and C++
I successfully completed an Object-Oriented Programming (OOP) course using Java, which included a mandatory project.
· SQL programming
Through the completion of an SQL course, I acquired the essential skills required for effective database management.
· Fundamental Algorithms in C
Completing the Fundamental Algorithms and Data Structures in C course set me on the path to efficiency in programming.
· Logic Design of Circuits, Assembly, VHDL
Successfully completing the Logic Design of Circuits course has been instrumental in building a strong foundation for my understanding of hardware systems.
· AI Technologies in Python
Implemented PDDL-like theorem proving to detect deception in Among Us. Designed AI solutions for Sliding Tile Puzzle and All Lights Out using automated planning. Integrated AI into the Pac-Man framework for decision-making and pathfinding, leveraging adversarial search.


	COMPETENΤE PERSONALE
	 


	Limba(i) maternă(e)
	Limba română

	
	

	Alte limbi străine cunoscute
	ΙNΤELEGERE 
	VORBIRE 
	SCRIERE 

	
	Ascultare 
	Citire 
	Participare la conversaţie 
	Discurs oral 
	

	Limba engleză
	Utilizator experimentat 
	Utilizator experimentat
	Utilizator experimentat
	Utilizator experimentat
	Utilizator experimentat

	
	Admiterea la sectia Engleză a UTCN a fost echivalată cu Nivelul C1


	Limba germană
	Utilizator independent
	Utilizator independent
	Utilizator independent
	Utilizator independent
	Utilizator independent

	
	Certificat DSD Nivelul B1 


	
	Niveluri: A1/A2: Utilizator elementar  -  B1/B2: Utilizator independent  -  C1/C2: Utilizator experimentat 

Cadrul european comun de referinţă pentru limbi străine 


	Competenţe digitale
	AUTOEVALUARE

	
	Procesarea informaţiei
	Comunicare
	Creare de conţinut
	Securitate
	Rezolvarea de probleme

	
	Utilizator experimentat 
	Utilizator experimentat
	Utilizator experimentat
	Utilizator experimentat
	Utilizator experimentat

	
	Niveluri: Utilizator elementar  -  Utilizator independent  -  Utilizator experimentat 

Competențele digitale - Grilă de auto-evaluare

	
	Certificat ECDL


	
	În primul rând, mă simt foarte pregătită pentru a aborda  domeniul complex al Web Development. Pregătirea mea se confirmă prin rezultatele foarte bune obținute la materiile vizate în timpul celor 3 ani de studiu.

În al doilea rând, aș vrea să îmi dezvolt abilitățile practice în domeniul tehnic, în special, în ceea ce privește implementarea soluțiilor software. Consider că acest proiect îmi va oferi o oportunitate de a învăța de la profesioniști și de a aplica teoria în practică. Mă motivează oportunitatea de a lucra într-o echipă interdisciplinară și de a contribui la dezvoltarea unui proiect real. 


Consider că este prioritar să amintesc că am lucrat cu acest tip de tehnologie Web Development în cadrul cursului “Inginerie Software”, și am realizat un proiect despre sisteme de recomandare ale resturantelor din apropiere folosind API-urile de la Google Location si de vreme. 

De asemenea, am urmat cursuri de "Object-Oriented Programming (OOP) on Java and C++", unde am realizat un proiect obligatoriu ce mi-a consolidat cunoștințele în dezvoltarea aplicațiilor bazate pe OOP.

 
"SQL Programming" mi-a oferit abilități fundamentale pentru gestionarea bazelor de date, esențiale în orice proiect care implică stocarea și manipularea datelor. 

În cadrul studiilor mele, am urmat cursuri relevante care mi-au oferit abilități esențiale în domeniul informaticii și al tehnologiilor aplicate. De exemplu, prin completarea cursului de "Fundamental Algorithms and Data Structures in C", am învățat tehnici de programare eficiente, pentru dezvoltarea de soluții performante. 

În cadrul cursului "AI Technologies in Python", am implementat soluții AI complexe, cum ar fi theorem proving și PDDL împreună cu colegii mei de echipă. 




	Permis de conducere 
	Dețin permis Categoria B


	INFORMAΤII SUPLIMENTARE
	 


	ANEXE
	 


	
	





 © Uniunea Europeană, 2002-2015 | europass.cedefop.europa.eu 
Pagina 2 / 6 

 © Uniunea Europeană, 2002-2018 | europass.cedefop.europa.eu 
Pagina 1 / 6 


reading content from D:\SD\SearchEngine_ver1\Bee\morphological_op_images.zip


Morphological_Op_Images/1_Dilate/mon1thr1_bw.bmp


Morphological_Op_Images/1_Dilate/reg1neg1_bw.bmp


Morphological_Op_Images/1_Dilate/wdg2ded1_bw.bmp


Morphological_Op_Images/1_Dilate/wdg2thr3_bw.bmp


Morphological_Op_Images/2_Erode/mon1thr1_bw.bmp


Morphological_Op_Images/2_Erode/mon1_gray.bmp


Morphological_Op_Images/3_Open/art3_bw.bmp


Morphological_Op_Images/3_Open/cel4thr3_bw.bmp


Morphological_Op_Images/3_Open/cel4_gray.bmp


Morphological_Op_Images/3_Open/mon1thr1_bw.bmp


Morphological_Op_Images/4_Close/art4_bw.bmp


Morphological_Op_Images/4_Close/mon1thr1_bw.bmp


Morphological_Op_Images/4_Close/phn1thr1_bw.bmp


Morphological_Op_Images/4_Close/phn1_gray.bmp


Morphological_Op_Images/5_BoundaryExtraction/reg1neg1_bw.bmp


Morphological_Op_Images/5_BoundaryExtraction/wdg2thr3_bw.bmp


Morphological_Op_Images/5_BoundaryExtraction/wdg2_gray.bmp


Morphological_Op_Images/6_RegionFilling/reg1neg1_bw.bmp


Morphological_Op_Images/6_RegionFilling/wdg2ded1_bw.bmp


Morphological_Op_Images/2_Erode/reg1neg1_bw.bmp


reading content from D:\SD\SearchEngine_ver1\Bee\RC3a_2022.doc

REŢELE DE CALCULATOARE
FIBRE OPTICE ŞI COMPONENTE OPTICE

LUCRAREA NR. 3a
FIBRE OPTICE ŞI COMPONENTE OPTICE
1. Scopul lucrării

Obiectivul acestei lucrări este cunoașterea și înțelegerea fibrelor optice, a componentelor optice, principalele metodelor de testare, precum şi calculul bugetului optic.
2. Consideraţii teoretice

2.1 Fibre şi componente optice
Lucrarea de laborator continuă să se concentreze asupra nivelului fizic al stivei ISO/OSI, oferind cunoștințe despre fibrele optice și componente optice. În plus, în partea 3b sunt prezentate principalele dispozitive de rețea și elementele cablării structurate.

Odată cu scăderea accentuată a preţului fibrei optice, şi a echipamentelor de comunicaţie corespunzătoare, aceasta a devenit mediul preferat pentru noile conexiuni de mare viteza (în mediul exterior, cât şi în interiorul clădirilor).

Pentru transmiterea datelor, fibrele optice trimit semnale luminoase de-a lungul miezurilor de sticlă sau plastic (de ordinul zecilor de microni (μ), care constituie un ghid de undă pentru lumină, obținut dintr-o combinație de dioxid de siliciu și alte elemente).

Un fir de fibră optică (eng. fiber strand) este elementul de bază al unui cablu de fibră optică (un cablu conține mai multe fire). Un fir optic este format din trei straturi: miez, îmbrăcăminte și învelitoare de protecție. Un cablu de fibră optică este format din mai multe componente: fire de fibră, zona tampon/buffer, materiale de protecție și mantaua exterioară.

Miezul este învelit de un material realizat din dioxid de siliciu având un indice de refracţie mai mic decât al miezului numit imbrăcăminte. Pentru a proteja îmbrăcămintea, aceasta este învelită într-un material plastic. Acest inveliş se numeşte protecţie şi este învelit la rândul său de un material întăritor, de obicei Kevlar, care conferă rezistenţă fibrei în momentul instalării. Zonele tampoan ale fibrelor optice sunt de două categorii: strânse (se aplică o acoperire de protecție peste învelișul fiecărui fir de fibră) sau cu tub liber (mai multe fire în interiorul unui tub umplut cu un gel protector). Ultimul inveliş este mantaua care protejează fibra împotriva materialelor abrazive, a solventilor şi a altor factori. Culoarea mantalei în cazul fibrei optice multimod este de obicei portocaliu şi în cazul fibrei optice monomod este de obicei galben. Fiecare cablu de fibră optică este compus din doua fibre invelite separat, o fibră fiind folosită pentru transmisie şi alta pentru recepţie, asigurându-se în acest mod o legatură full-duplex. Un cablu de fibră optică poate contine de la 2 până la sute de fibre separate, învelite într-un strat protector. 
Figura 2.1 prezintă o straturile unei fibre și o secţiune transversală prin fibra optică.

	

	Figure 2.1 a. Straturile unei fibre optice             b. Secţiune transversală prin fibra optică


Pentru ca semnalul luminos să fie reflectat fără pierderi trebuiesc îndeplinite următoarele două condiţii:

· fibra optică trebuie să aibă un indice de refracţie mai mare decât materialul care o înconjoară;
· unghiul de incidenţă al semnalului luminos trebuie să fie mai mare decât unghiul critic al fibrei şi al materialului care o inconjoară. Unghiul de incidenta al semnalului luminos poate fi controlat cu ajutorul următorilor doi factori:

· apertura numerică a fibrei este gama unghiurilor semnalului luminos pentru care reflexia este totală;
· modurile reprezintă căile pe care semnalul luminos le poate urma.

Spre deosebire de mediile de transmisie bazate de cupru, fibra optică nu este susceptibilă la și nu generează interferențe electromagnetice sau probleme de diafonie.
Două tipuri principale de fibre optice sunt utilizate în mod obișnuit în rețele LAN și WAN: monomod (eng. single-mode) și multimod (eng. multimode). Fibra optică monomod este utilizată pentru conexiuni pe distanțe lungi și pentru cablarea verticală în clădiri (coloana vertebrală a clădirii). Fibra optică multimod este utilizată în cablarea orizontală și verticală. Fibra multimod are un diametru miezului mai mare în comparație cu cel al fibrei monomod. Astfel, fibra multimod nu necesită aceeași precizie ca în cazul fibrei monomod, rezultând astfel elemente optice (conectori, transmițători etc) mai puțin costisitoare.

Miezul fibrei monomod are diametrul suficient de mic încât să permită doar un singur mod (o singură cale) semnalului luminos, acesta fiind transmis în linie dreaptă prin mijlocul miezului. Cablurile de fibră optică monomod folosesc miezul cu diametrul între 8μ şi 10μ. Cele mai folosite fibre optice monomod au diametrul de 9μ şi îmbrăcămintea cu diametrul de 125μ. Acestea sunt de obicei referite ca şi fibre optice de 9/125μ. Sursa de lumină folosită la fibra monomod este laserul infraroşu. Se recomandă precauţie atunci când se foloseşte laserul ca şi sursă de lumină deoarece acesta poate afecta ochii. Fibra monomod poate transmite date la distanţe de peste 100km. Pierderea pe km de fibră optică monomod este specificată de către producator. În cazul fibrei monomod indicele de refracţie al sticlei este constant. Acest tip de sticlă se numeşte sticlă cu index pas.

Miezul fibrei multimod are diametrul suficient de mare încât să permită mai multe moduri (mai multe căi) semnalului luminos. Cablurile de fibră optică multimod standard folosesc miezul cu diametrul de 62,5μ sau 50μ şi îmbrăcămintea cu diametrul de 125μ. Acestea sunt de obicei referite ca şi fibre optice de 62.5/125μ sau 50/125μ. De obicei, sursele de lumina folosite cu fibra multimod sunt Infrared Light Emitting Diode (LED) sau Vertical Cavity Surface Emitting Lasers (VCSEL). LED-urile sunt mai ieftine şi necesită mai puţine măsuri de siguranţă decât laserele. Dezavantajul LED-urilor este că nu pot transmite semnalele luminoase la distante la fel de mari ca şi laserele. Fibra multimod de 62.5/125 poate transmite date la distante de până la 2000m. În cazul fibrei multimod indicele de refracţie al sticlei poate fi constant (sticlă monomod cu index pas) sau poate scădea de la centru spre exterior (sticlă monomod cu index variabil sau gradat şi permite diferitelor moduri luminoase să ajunga la receptor în acelaşi moment).
În fibra optică lumina suferă, pe lângă propagare, două fenomene principale: atenuare şi dispersie. Atenuarea sau absorbţia se datorează în principal prezenţei ionilor hidroxil -OH şi a diferiţilor ioni de metale. Lumina poate fi de asemenea împrăştiată de microcristale, mai mici decât lungimea de undă, care se formează la răcirea sticlei. Atenuarea limitează utilizarea fibrei optice în lungime. Dispersia sau lărgirea lăţimii impulsurilor se datorează în fibra multimod lungimii diferite pe care o au diferitele moduri. O altă dispersie cea cromatică este datorată variaţiei indicelui de refracţie în funcţie de culoarea sau lungimea de undă a luminii. Dispersia limitează utilizarea fibrei optice în frecvenţă sau lărgime de bandă. Cele două limitări înmulţite caracterizează cel mai corect o fibră optică. Valori de 20MHz-km se obţin pentru fibra cu index pas, de 1GHz-km pentru cea cu index variabil şi de 1000GHz-km pentru cea monomod la care nu există dispersie modală.

Transmiţătoarele pentru fibra optică convertesc semnalele electrice în pulsuri luminoase echivalente. Există două tipuri de surse de lumină folosite de transmiţătoarele pentru fibra optică:

· LED-ul care produce lumina în infraroşu având lungimea de undă de 850nm sau 1310nm. Acestea sunt folosite cu fibre multimod. Cuplarea la fibra optică poate fi îmbunătăţită prin utilizarea unei lentile sferice;
· dioda semiconductoare LASER care produce lumina în infrarosu având lungimea de undă de 1310nm sau 1550nm. Acestea sunt folosite cu fibre multimod sau monomod.
Există două tipuri constructive de bază pentru LED-uri: cu emisie pe suprafaţă şi cu emisie pe muchie. La LED cu emisie pe suprafaţă, emisia luminii are loc perpendicular pe planul joncţiunii printr-un strat subţire transparent. Acestea emit într-un spectru geometric radial. La LED cu emisie pe muchie lumina este emisă într-un plan paralel cu joncţiunea la muchia semiconductorului. Materialele cel mai des utilizate sunt compuşi III-V ca GaAs sau AlxGa1-xAs pentru lungimi de undă de 0,8-0,9 μm şi GaxIn1-xPyAs1-y pentru lungimi de undă de 1,3-1,6 μm. Spectrul de emisie a unui LED este cuprins între 25-40 μm pentru lungimi de undă mici şi 50-100 μm pentru lungimi de undă mai mari.

Diodele semiconductoare LASER, diode laser (LD), se obţin prin introducerea unui LED într-o cavitate rezonantă optic. Efectul de LASER apare numai la existenţa unui curent direct suficient de mare pentru a se realiza o inversare de populaţii a electronilor şi a golurilor din cele două benzi energetice de conducţie şi de valenţă. Valoarea de curent de la care apare acest efect se numeşte curent limită. Sub acest curent dispozitivul se comportă ca un LED obişnuit. Deoarece lumina emisă de un laser este mult mai coerentă decât cea emisă de un LED, eficienţa de cuplare la fibra optică este superioară. De asemenea puterea optică captată de la un laser este mai mare decât cea emisă de LED.
O analiză comparată între cele două tipuri de emiţătoare este clar în favoarea LD prin posibilitatea de utilizare la frecvenţe mai mari, spectru mai restrâns şi în favoarea LED ca preţ şi stabilitate mai mare a puterii în raport cu temperatura.

Timpul de viaţă al ambelor dispozitive este egal şi este de ordinul a 10 milioane ore.

Receptoarele pentru fibra optică convertesc pulsurile luminoase în semnale electrice echivalente. Dispozitivele semiconductoare folosite de obicei de receptoarele pentru fibra optică se clasifică în două tipuri: simple şi cu câştig intern. Primele se mai numesc şi fotodiode PIN după tipul de dopare (p intrinsec şi n) iar cea de a doua categorie se numeşte APD (Avalanche Photo-Diodes). Aceste dispozitive sunt sensibile la lungimile de undă ale luminii de 850, 1310 şi 1550nm, lungimi de undă folosite de transmiţătoarele pentru fibra optică. Ca materiale semiconductoare sunt folosite Si pentru lungimi de undă de 800-900 nm şi Ge sau InGaAsP pentru 1300 şi 1500 nm. Si are sensibilitate optimă doar într-o zonă de frecvenţe redusă pe când Ge are un curent de întuneric apreciabil şi este mai sensibil la zgomot. Din acest motiv ultima variantă este cea mai bună dar necesită o tehnologie de fabricaţie mai sofisticată şi în consecinţă are şi un preţ mai mare.

Pentru a conecta fibrele sau pentru a realizare unei fibre mai lungi se folosesc joncţiuni (eng. splices). Joncţiunile sunt de două tipuri: mecanice şi de fuziune. Atenuările introduse sunt  mai mici de 0.5dB (ANSI/TIA-568-C.3 specifică că joncțiunile mecanice sau de fuziune nu trebuie să depășească o pierdere maximă de inserție optică de 0,3 dB). La joncţiunile mecanice cele două capete de fibră, atent tăiate, curăţate şi şlefuite sunt prinse într-o montură mecanică rigidă care le fixează una faţă de cealaltă într-un ansamblu imobil. Joncţiunile de fuziune se execută prin încălzirea aproape până la punctul de topire. În acest moment cele două fibre sunt lipite una de alta şi răcite. Aceste operaţii sunt precedate de operaţii de tăiere şi finisare a capetelor şi de aliniere prealabilă a celor două capete de jonctat. Joncţiunile de fuziune refac şi rezistenţa la tragere/rupere a fibrei la aproximativ 90% din cea iniţială. Pentru a proteja joncțiunile, se folosesc incinte speciale.
Conectorii pentru fibra optică permit conectarea fibrelor la porturi. Cei mai folosiţi conectori sunt SC (Subscriber Connector) - snap on type, ST (Straight Tip) - twist on type, FC (Ferrule Connector) - screw on type, LC (Lucent Connector) - snap on type and MTP/MPO - push/pull type, pentru fibre optice multimod si fibre optice monomod. Atenuarea introdusă de un conector optic, chiar de calitate superioară este mai mare decât cea introdusă de o joncţiune, având valori de aproximativ 1dB. Conectorii sunt echipamente mecanice de mare precizie şi de obicei un capăt al fibrei se află în conector iar unul este liber. În acest caz ataşarea unui conector se reduce la execuţia unei joncţiuni. O astfel de soluţie este de obicei mai avantajoasă decât montarea unui conector direct pe capătul fibrei deoarece conectorii prefabricaţi asigură o precizie de montare mult mai mare. Dacă fibra optică este terminată într­un terminator de fibră optică pentru redistribuire acest conector de capăt se mai numeşte şi pig­tail şi este de tipul prefabricat. O categorie specială de conectori o constituie cordoanele optice de distribuire sau legătură. Acestea sunt fibre optice speciale cu conectori la ambele capete care permit raze de curbură a fibrei mici de ordinul 2,5­5 cm. Culoarea acestora este galben pentru fibra monomod şi portocaliu pentru fibra multimod.

Repetoarele sunt amplificatoare optice care receptionează semnalele luminoase atenuate ca urmare a distanţei parcurse prin fibra optică, refac forma, puterea şi parametri de timp a acestor semnale şi le transmit mai departe.

Patch panel-urile pentru fibră sunt similare patch panel-urilor pentru cablul de cupru mărind flexibilitatea reţelelor optice. Pentru conectarea diferitelor echipamente, se folosește un patch cord de fibră optică (cunoscut și sub denumirea de zip cord - două fibre optice flexibile cu conectori la fiecare capăt).
În plus, alte câteva dispozitive active sau pasive sunt folosite împreună cu fibrele optice (exemple: cuploare optice - combină sau împart semnale optice; atenuatoare optice - reduc nivelul de putere al unui semnal optic; izolatori optici; comutatoare de fibră optică; multiplexoare optice etc.).

ISO/IEC 11801-1 specifică cerințele pentru fibre coaxiale, cu perechi răsucite și fibre optice. Standardele ISO/IEC 11801 (Europa) și ANSI/TIA-568-C (SUA și Canada) definesc 7 clase de fibre optice (monomod și multimod) așa cum se arată în tabelul 2.1, împreună cu câțiva parametri importanți (specificațiile pentru fibre optice, performanța transmisiei prin cablu și specificațiile fizice ale cablurilor):
Tabel 2.1 Caracteristicile fibrelor optice
	
	Multimod
	Monomod

	Tip
	OM1
62,5/125 μm
	OM2
50/125 μm
	OM3
50/125 μm
	OM4
50/125 μm
	OM5
50/125 μm
	OS1
9/125 μm
	OS2
9/125 μm

	Lungime de undă
	850, 1300nm
	850, 1300nm
	850, 1300nm
	850, 1300nm
	850, 1300nm
	1300nm, 1550nm
(1383nm)
	1300nm, 1550nm

	Atenuare max. (db/km) 
	2.6 / 
2.4
	3.56 / 2.3
	2.6 / 
1.9
	2.9 / 
1.5
	2.9 / 
1.5
	1
	0.4

	Sursă luminoasă
	LED (Light-Emitting Diode) / 

VCSEL (Vertical Cavity Surface-Emitting Lasers Light Source) 
	LASER (Light Amplification by Stimulated Emission of Radiation)

	Distanță/

rată

de date
	1 Gbps
	275m
	550m
	-
	-
	-
	5-120km

	
	10Gbps
	33m
	82m
	300m
	400m
	400m
	10-80km

	
	40-100 Gbps
	-
	-
	100m
	150m
	150m
	2-80km

	Culoare
	orange/ slate
	orange
	albastru deschis (aqua)
	violet/ albastru deschis (aqua)
	verde/ lime
	galben
	galben


Instalarea incorecta a fibrelor optice are ca şi rezultat creşterea atenuării semnalului optic. Intinderea sau curbarea exagerată a fibrei optice poate cauza mici fisuri ale miezului care vor dispersa semnalul luminos. Curbarea exagerată a fibrei optice poate avea ca urmare scăderea unghiului incident al semnalului luminos sub unghiul critic de reflexie totală. Pentru instalarea conectorilor capetele fibrei trebuiesc taiate si finisate. Dupa instalare, capetele fibrelor optice, conectorii şi porturile de fibră trebuiesc păstrate curate pentru a nu introduce atenuări. Înaintea folosirii cablurilor de fibră optică, trebuie testată atenuarea introdusă de acestea. La proiectarea unei legaturi pe fibră optică, trebuie calculată pierderea puterii semnalului care poate fi tolerată. Aceasta se numeste bugetul de pierdere a legaturii optice. Pierderea puterii se masoara in decibeli (dB).

Pentru testarea unei legături prin fibră optică există mai multe procedee: testare de continuitate, localizare vizuală a erorilor, procedeul de măsurare a puterii optice la ieşire, procedeul OTDR şi testul BER de rată a erorilor.
Testerele de continuitate sunt folosite pentru a testa continuitatea unei fibre optice. Un instrument de localizare vizuală a defecțiunilor (VFL) permite unui tehnician să identifice rupturi, macro-îndoituri (se referă la raza minimă de îndoire) sau joncțiuni de fuziune slabe.
Procedeul de măsurare a puterii optice la ieşire determină pierderile de putere prin legătura optică măsurând puterea la ieşire la o putere de intrare cunoscută. Unitatea de măsură pentru puteri optice este miliwattul (mW) insă din considerente practice se utilizează o altă unitate de măsură care măsoră câştigul (G) sau pierderea (L) într-un sistem şi anume deciBell-ul (dB).

Procedeul OTDR Optical Time Domain Reflectometer este procedeul prin care se pot vizualiza caracteristicile de atenuare ale unei fibre optice precum şi lungimea acesteia. Acest procedeu este singurul prin care se pot detecta poziţiile întreruperilor în fibra optică. OTDR afişează un grafic care are ca axă x lungimea fibrei şi ca axă y atenuarea. Din graficul astfel afişat se pot deduce atenuarea fibrei, calitatea joncţiunilor şi a conectoarelor. Deasemenea se poate determina poziţia rupturilor în cablu dacă extern cablul nu este afectat.

Testul BER (Bit Error Rate) este testul final la care se supune o legătură de date prin fibră optică. Acest test sau criteriu arată la câţi biţi transmişi prin fibră se produce o eroare datorată fibrei. Testul BER trebuie să îndeplinească cerinţele impuse de producătorii de echipamente DTE ce se cuplează la fibra optică. Pentru reţele de calculatoare acestea cer să fie mai mici decât 1 bit de eroare la 109/1012 biţi transmişi sau BER < 10-9/10-12. Pentru testare este nevoie de un generator de secvenţe de bit aleatoare şi de o interfaţă la fibra optică dacă se testează o buclă sau de două dacă se testează o singură fibră. Pentru a avea rezultate semnificative testul trebuie să se desfăşoare pe o perioadă suficient de lungă astfel încât să se transmită un număr suficient de mare de biţi. Perioade de testare de o zi sau două sunt obişnuite dacă se lucrează la rată de bit mare în utilizarea legăturii prin fibră optică şi BER mic. Un numărător poate contoriza automat numărul de erori detectate.

2.2 Calculul bugetului de putere optică 
Tabelul  2.2 Calcul buget de putere optica
	Crt. 
	Pierdere sau Putere Optică
	dB

	1.
	Pierderea pe km în Fibra Optică___dB/km X __km fibră 
	___dB

	2.
	Pierderea în Joncţiuni ___dB/joncţiune X __ joncţiuni
	___dB

	3.
	Pierderea în Conectoare ___dB/conector X ___ conectoare
	___dB

	4.
	Pierderi pe alte Componente
	___dB

	5.
	Margine de Eroare
	___dB

	6.
	Pierderea Totală pe Legătură (1+2+3+4+5)
	___dB

	7.
	Puterea de Emisie Medie a Emiţătorului
	___dB

	8.
	Puterea Medie Recepţionată de Receptor (7-6)
	___dB

	9.
	Dinamica Receptorului _____dB la _____dB
	

	10.
	Sensibilitatea Receptorului la o Rată de Erori dată BER ____
	___dB

	11.
	Putere Rămasă Disponibilă (8-10)
	___dB


Observaţii:
La punctul 3. nu se iau în considerare pierderile de conectare a emiţătorului la fibra optică, acestea fiind deja incluse. Valoarea calculată la punctul 8. trebuie să fie în intervalul de la punctul 9. pentru ca receptorul să funcţioneze corect. Valoarea calculată la punctul 11. trebuie să fie pozitivă pentru a avea o legătură de date optică funcţională.

Marginea de eroare se datorează luării în calcul a unor valori medii pentru toate componentele legăturii. Dispersia acestor valori în jurul valorii medii este cunoscută şi se poate lua o margine de eroare suficient de mare ca aceasta să acopere deviaţiile de la medie cu o probabilitate de 99,9% sau mai mare. Cu cât numărul de elemente este mai mare şi cu cât se doreşte o probabilitate de acoperire mai mare cu atât se va lua o margine de eroare mai mare.

Puterea de emisie optică a emiţătorului este o dată de catalog şi conţine în ea inclusă şi pierderea de conectare la un capăt de fibră optică în cazul în care conectarea se face conform recomandărilor. Puterea este mai mare la diode LASER şi mai mică la LED. În cazul utilizării de LASER este nevoie pentru distanţe relativ scurte chiar de un atenuator pentru a nu distruge receptorul.

Dinamica receptorului reprezintă plaja de puteri pe care un receptor le poate transforma în semnal electric fără pierderi de informaţie.

De asemenea este nevoie de o putere optică minimă necesară pentru îndeplinirea condiţiei de rată de erori tolerată care pentru reţele de calculatoare se situează la valoarea de 1 bit eronat la un miliard de biţi transmişi.

Exemplu de calcul al bugetului de putere optică

Diametrul fibrei optice: Miez 62.5μm/Înveliş 125μm. Apertura numerică a fibrei NA:0,275. Lungimea de undă a echipamentului optic: 1310μm.

Tabelul 2.3 Exemplu de calcul 
	Crt. 
	Pierdere sau Putere Optică
	dB

	1.
	Pierderea pe km în Fibra Optică 1,8dB/km X 3,5km fibră
	6,3dB

	2.
	Pierderea în Joncţiuni 0,5dB/joncţiune X 2 joncţiuni
	1,0dB

	3.
	Pierderea în Conectoare 1,0dB/conector X 2 conectoare
	2,0dB

	4.
	Pierderi pe alte Componente
	0,0dB

	5.
	Margine de Eroare
	2.0dB

	6.
	Pierderea totală pe Legătură (1+2+3+4+5)
	11,3dB

	7.
	Puterea de Emisie Medie a Emiţătorului
	-10,0dB

	8.
	Puterea Medie Recepţionată de Receptor (7-6)
	-21,3dB

	9.
	Dinamica Receptorului -10,0dB la -30,0dB
	

	10.
	Sensibilitatea Receptorului la o Rată de Erori dată BER 10-9
	-26,0dB

	11.
	Putere Rămasă Disponibilă (8-10)
	+4,7dB


Puterea ajunsă la receptor se încadrează în dinamica receptorului, ceea ce face posibilă funcţionarea sa, iar puterea rămasă disponibilă este pozitivă ceea ce ne asigură de o legătură viabilă.

Trebuie ţinut cont şi de faptul că în cursul vieţii legăturii pot apare fenomene de îmbătrânire a materialelor, care duc la creşterea pierderilor de putere, precum şi de faptul că fibra optică poate fi ruptă accidental şi trebuie joncţionată.
Un calcul făcut la limită periclitează durata de exploatare a unei legături prin fibră optică.

3. Desfăşurarea lucrării

3.1 Se vor discuta caracteristicile diferitelor tipuri de fibre şi componente optice şi aspectele legate de cablarea reţelelor de calculatoare folosindu-se acest mediu de transmisie.
3.2 Explorați infrastructura de fibra optică din oceane: https://www.submarinecablemap.com/ 

3.3 Se consideră o fibră optică monomod de 9/125μ având lungimea de 2,5km şi pierderea egală cu 0,5dB/km, care conectează două echipamente DTE. Atenuarea introdusă de joncţiuni şi conectori este egală cu 0,5 şi respectiv 1dB. Marginea de eroare luată în considerare este de 3dB. Puterea de emisie medie a emiţătorului este de -15dB, sensibilitatea receptorului la o rată de erori dată BER 10-9 este de -25dB şi dinamica receptorului este în intervalul -10 ÷ -30dB. Să se calculeze bugetul de putere optică.
(Manta)

(Întăritor)

(Protecție)

(Îmbracaminte)

(Miez)





2
3


reading content from D:\SD\SearchEngine_ver1\See\0_geografie_planificari_calendaristice_liceu_tehnologic_9.docx

PLANIFICARE CALENDARISTICĂ ANUALĂ 
PENTRU ANUL ȘCOLAR  - 2025, LA DISCIPLINA GEOGRAFIE 
 ÎNVĂȚĂMÂNT LICEAL, FILIERA TEHNOLOGICĂ
CLASA a IX-a

În baza prevederilor OME nr. 3.694/01.02  privind structura anului școlar  2024- 2025 și ale OME nr. 3965/2024 privind măsuri de aplicare şi corelare a planurilor de învăţământ pentru învăţământul profesional, liceal - filiera tehnologică şi postliceal cu structura anului şcolar 2024 - 2025, în organizarea procesului de învățământ se vor avea în vedere următoarele reglementări:
• Pentru clasele a IX-a – a XI-a zi și a IX-a – a XII-a seral din învățământul liceal și profesional, filiera tehnologică, anul școlar are o durată de 37 de săptămâni de cursuri și se încheie la data de 23 iunie 2025.
• Pentru clasele a XII-a zi și a XIII-a seral din învățământul liceal și profesional, filiera tehnologică, anul școlar are o durată de 34 de săptămâni de cursuri și se încheie la data de 2 iunie 2025. 
• Pentru clasele din învățământul liceal și profesional, filiera tehnologică, ale căror planuri-cadru de învățământ în vigoare prevăd un număr mai mare de 37 de săptămâni, în organizarea procesului de învățământ se va avea în vedere menținerea structurii, a numărului total de ore/săptămână și a numărului de săptămâni alocate stagiilor de pregătire practică prevăzute în planurile-cadru de învățământ în vigoare, dar cu reducerea numărului de săptămâni de cursuri pentru disciplinele și modulele din ariile curriculare, astfel:
1. Învățământ de zi:
 Pentru clasa a IX-a liceu: 
· 34 de săptămâni de pregătire teoretică și pregătire practică; 
· 3 săptămâni de stagii de pregătire practică; 
 Pentru clasa a IX-a învățământ profesional: 
· 32 de săptămâni de pregătire teoretică și pregătire practică săptămânală; 
· 5 săptămâni de stagii de pregătire practică;
 Pentru clasa a X-a liceu: 
· 34 de săptămâni de pregătire teoretică și pregătire practică; 
· 3 săptămâni de stagii de pregătire practică; 
 Pentru clasa a XI-a liceu, profil Tehnic și Resurse naturale și protecția mediului: 
· 32 de săptămâni de pregătire teoretică și pregătire practică; 
· 5 săptămâni de stagii de pregătire practică; 
 Pentru clasa a XI-a liceu, profil Servicii: 
· 33 de săptămâni de pregătire teoretică și pregătire practică;
· 4 săptămâni de stagii de pregătire practică; 
 Pentru clasa a XII-a liceu: 
· 29 de săptămâni de pregătire teoretică și pregătire practică; 
· 5 săptămâni de stagii de pregătire practică. 

2. Învățământ seral:
 Pentru clasele din învățământul liceal, cu excepția claselor a XIII-a, se respectă numărul de săptămâni de cursuri stabilit prin planurile-cadru de învățământ în vigoare.
 Pentru clasa a XIII-a învățământ seral: 
· 29 de săptămâni de pregătire teoretică și pregătire practică; 
· 5 săptămâni de stagii de pregătire practică.




CLASA A IX-A
(pentru toate profilurile și specializările)

• Număr de ore alocate: - 1 oră pe săptămână (TC), respectiv 34 de ore pe an 
• Structura avută în vedere la realizarea planificării calendaristice:
Modul 1: 09.09.2024 - 25.10.2024
Modul 2: 04.11.2024 - 20.12.2024
Modul 3: 08.01.2025 - 21.02.2025*
Modul 4: 03.03.2025 – 17.04.2025  
Modul 5: 28.04.2025 - 27.06.2025 
– cu două săptămâni de instruire practică în perioada celor 2 programe ”Școala Altfel” și ” Săptămâna Verde”**
– cu o săptămână de instruire practică** 

  *  Se va modifica în funcție de decizia ISJ/ISMB
**  Se va modifica/ajusta în funcție de intervalele (săptămânile) de desfășurare a stagiilor de instruire practică stabilite la nivelul fiecărei unități de învățământ.

PLANIFICARE CALENDARISTICĂ ANUALĂ 
GEOGRAFIE FIZICĂ (,,PĂMÂNTUL PLANETA OAMENILOR”)
	Unitatea de învățare
	Competențe specifice
	Conținuturi
	Nr. de ore alocate
	Săptămâna
	Observații/
Evaluare

	MODUL DE ÎNVĂȚARE 1

	1. Pământul - o entitate a Universului
	1.1.
1.2.
1.3.
2.1.
3.2.
	· Elemente de geografie generală. (evaluare inițială)
· Universul şi Sistemul solar
· Evoluţia Universului şi a Terrei
· Caracteristicile Pământului şi consecinţele geografice 
	4
	1 – 4
	Observarea sistematică
Autoevaluare/
Interevaluare
Evaluare orală

	2. Măsurarea 
şi reprezentarea spaţiului terestru

	1.1.
2.2.
4.1.
4.2.
4.3.
4.4.
4.5.
	· Coordonatele geografice
· Reprezentări cartografice
· Măsurarea şi calculul distanţelor şi al suprafeţelor pe hărţi geografice şi în orizontul local
· Reprezentările cartografice şi societatea omenească
· *GIS, teledetecție, imagini satelitare
Recapitulare și evaluare
	3
	5 – 7
	
Observarea sistematică

Autoevaluare/
Interevaluare

Evaluare scrisă (T1)

	Vacanță (28.10.2024 – 31.10.2024)

	MODUL DE ÎNVĂȚARE 2

	3. Relieful terestru

	1.1.
1.2.
3.2.
4.2.
4.5.
5.3.
5.4.

	· Scoarţa terestră ca suport al reliefului: structură şi alcătuire petrografică
· Unităţile majore ale reliefului terestru
· Agenţi, procese şi forme de relief
· Tipuri şi unităţi de relief
· Analiza şi interpretarea  reliefului
· Relieful şi societatea omenească
· Relieful orizontului local
· Aplicaţii practice în orizontul local
· *Modificări naturale actuale ale reliefului. Modificări accentuate antropic
Recapitulare și evaluare
	






7
	






8 – 14
	
Observarea sistematică


Autoevaluare/
Interevaluare







Evaluare scrisă (T2)

	Vacanță (21.12.2024 – 7.01.2025)

	MODUL DE ÎNVĂȚARE 3

	4. Atmosfera terestră 
	1.1.
1.2.
3.2.
4.1.
4.5.
4.6.
5.4.

	· Alcătuirea şi structura atmosferei
·  Factorii genetici ai climei
·  Climatele Terrei 
· Evoluţia şi tendinţele de evoluţie a climei
· Hărţile climatice şi harta sinoptică. Analiza şi interpretarea datelor
· Clima şi societatea omenească
· Clima orizontului local
*Modificări climatice actuale și impactul acestora asupra societății umane
Recapitulare și evaluare
	7
	15 – 21
	


Observarea sistematică

Autoevaluare/
Interevaluare




Evaluare scrisă (T3)

	Vacanță de ski(22.02.2025 – 02.03.2025)

	MODUL DE ÎNVĂȚARE 4*

	5. Apele Terrei
	1.1.
1.2.
3.2.
4.1.
4.5.
4.6.
5.4.
5.5.
	· Componentele hidrosferei
· Apele oceanice (oceanosfera) și apele continentale
· Analiza şi interpretarea unor date hidrologice
· Hidrosfera şi societatea omenească
· Hidrografia orizontului local
· Aplicaţii practice în orizontul local
*Modificări ale componentelor hidrosferei (naturale și antropice)
Recapitulare și evaluare
	7
	22 – 28
(orientativ)
	

Observarea sistematică

Autoevaluare/
Interevaluare


Evaluare scrisă (T4)

	Vacanță (18.04.2025 – 27.04.2025)

	MODUL DE ÎNVĂȚARE 5*

	6. Viaţa şi solurile pe Terra
	1.1.
1.2.
3.2.
4.5.
4.6.
5.4.
5.5.
	· Biosfera şi organizarea ei.
   Evoluţia vieţii pe Terra
· Pedosfera
· Zonele biopedoclimatice
· Biosfera, solurile şi activitatea omenească
· Aplicaţii în orizontul local
*Transformări recente în învelișul biotic cu implicații asupra societății umane
Recapitulare și evaluare
	2
	29 – 30
(orientativ)
	


Observarea sistematică

Autoevaluare/
Interevaluare


Evaluare scrisă (T5)

	7. Mediul, peisajul şi societatea omenească 
	1.1. 
1.4.
2.3.
2.4. 
2.5. 
5.5.


	· Interacţiunile dintre elementele
   naturale ale mediului
· Interacţiunile dintre om şi
   mediul terestru
· Peisajele naturale
· Factorii geoecologici naturali
· Tipurile de mediu natural
· Rolul mediului geografic în evoluţia şi dezvoltarea  societăţii omeneşti 
· Mediul orizontului local
Recapitulare și evaluare
	2
	31 – 32 
(orientativ)
	


Observarea sistematică

Autoevaluare/
Interevaluare




Evaluare orală

	8. *Modificări 
globale ale mediului 
natural
	1.1.
1.2.
1.3.
1.4.
2.4.
2.5.
4.1.
4.6.
5.4.
5.5.
	· *Mediul natural ca sistem global. Interacțiuni, sisteme, structuri
· *Modificări naturale
· *Modificări influențate antropic
· *Intercondiționarea transformărilor mediului natural
Recapitulare și evaluare finală
	


4






	


33 – 37
(orientativ)





	Observarea sistematică

Autoevaluare/
Interevaluare

Evaluare finală

	*include o  săptămână de instruire practică 
(la decizia unității de învățământ, între S29 și S37)



 Planificarea calendaristică este întocmită în conformitate cu programa școlară pentru disciplina Geografie, clasa a IX-a, aprobată prin OMECT nr. 3458/09.03.2004, structura anului școlar 2024-2025 aprobată prin OME nr. 3.694/01.02 2024, măsurile de aplicare și corelare a planurilor de învățământ pentru învățământul profesional, liceal - filiera tehnologică și postliceal cu structura anului școlar 2024-2025 aprobate prin OME nr. 3965/2024 şi metodologia de proiectare şi de organizare a instruirii promovată de ghidurile metodologice de curriculum şi didactică.
 Numărul de ore din prezenta planificare are o valoare orientativă și, de asemenea, intervalul de săptămâni din structura anului școlar. 
 La Art. 4 alin. (2) din OME nr. 3505/31.03.2024 privind structura anului şcolar 2024-2025 se precizează că, pentru clasele din învățământul liceal - filiera tehnologică, în perioadele dedicate programelor „Școala altfel” și „Săptămâna verde” (din intervalul 09 septyembrie – 20 iunie 2025) se organizează activități de instruire practică. 
 Planificarea calendaristică se va modifica/ajusta în funcție de intervalele de desfășurare a celor trei săptămâni de stagii de pregătire practică, stabilite la nivelul fiecărei unități de învățământ.
 Conținuturile evidențiate printr-un asterisc (*) și prin caractere italice reflectă realitatea/ problematica lumii contemporane asumate prin studiul Geografiei și nu sunt obligatorii. Cadrele didactice pot opta sau nu pentru realizarea acestor conținuturi, în funcţie de resursele de timp şi de particularităţile colectivelor de elevi.
image1.png


reading content from D:\SD\SearchEngine_ver1\See\Adeverință.docx


image6.png

image7.png

image8.png

image9.png

image10.png

image11.png

image12.png

image13.png

image1.jpeg

image2.png

image3.png

image4.png

image5.png


reading content from D:\SD\SearchEngine_ver1\See\CHANGELOG.md

# Lab 03
> 2025-03-10

> **Main goal**: Component-based thinking
---

## Hour 1:
- Intro to DBMS history
- ORM vs SQL
    - Explain mappings, like 1d light switches to 2d floor map
    - Link to Dependency Inversion
- "Tech stack" is a bad phrase. Learn about layer above and below you.
    - So if the abstraction fails, you can fix your way around it
    - https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/
    - Don't be a React developer. Be a web developer.
        - LAMP (Linux, Apache, MySQL, PHP)
        - MEAN (MongoDB, Express, Angular, Node)
        - etc.
    - Learn about web standards. Learn about the browser platform.


## Hour 2:
- Show Quirks.cpp
    - Link: https://github.com/WebKit/WebKit/blob/main/Source/WebCore/page/Quirks.cpp#L1130
- Chaos Monkey
    - Link to Antifragile
    - Exercise: how much is 5-nines? 4-nines? 3-nines?
- Snippet indent exercise. Explain the real power of Haskell types (runnable UML!)
    - "functional core, imperative shell" architecture


## Hour 3:
- Write Fizz Buzz in 3 ways (simple, 1 buffer, buffered writer)
- Explain the N+1 problem


#### Sources:
- https://www.martinfowler.com/bliki/BlueGreenDeployment.html
- https://googleblog.blogspot.com/2008/08/search-experiments-large-and-small.html
- https://www.slideshare.net/slideshow/culture-1798664/1798664#23
- https://youtu.be/jeRWyYIgiU8?t=176
- https://0.30000000000000004.com
- https://martinfowler.com/bliki/OrmHate.html
- https://matklad.github.io/2021/02/06/ARCHITECTURE.md.html

- Books mentioned:
    - https://en.wikipedia.org/wiki/Antifragile_(book)
    - https://en.wikipedia.org/wiki/Hacker%27s_Delight
    - https://www.amazon.com/Understanding-Software-Addison-Wesley-Professional-Computing/dp/0137589735


# Lab 02
> 2025-03-03

> **Main goal**: Understand GRASP
---


## Hour 1:
- Go through what 'Clean Code' promotes:
    - Link: https://gist.github.com/wojteklu/73c6914cc446146b8b533c0988cf8d29
    - Show counterexamples
- Write a `pluralize` function
    - Rust version
    - TypeScript version
- Show `gap` command
- Refactor method from the lab guide


## Hour 2:
- GRASP exercise


## Hour 3:
- GRASP exercise


#### Sources:
- https://sandimetz.com/blog/2016/1/20/the-wrong-abstraction
- https://qntm.org/clean
- https://www.codecentric.de/en/knowledge-hub/blog/curly-braces
- https://github.com/tigerbeetle/tigerbeetle/blob/fe681fc34729e7afb3ae4ead33d1093ceb68d164/src/constants.zig#L14
- Style:
    - https://cbea.ms/git-commit/
    - https://go.dev/doc/contribute#commit_messages
    - https://gist.github.com/joshbuchea/6f47e86d2510bce28f8e7f42ae84c716
    - http://number-none.com/blow/john_carmack_on_inlined_code.html
    - https://google.github.io/styleguide/cppguide.html#Exceptions
    - https://github.com/torvalds/linux/blob/master/Documentation/process/coding-style.rst
    - https://testing.googleblog.com/2023/10/improve-readability-with-positive.html
- Big functions:
    - https://github.com/torvalds/linux/blob/master/kernel/fork.c#L2147-L2705
    - https://github.com/gcc-mirror/gcc/blob/master/gcc/c/c-parser.cc#L2306-L3175
- Big comments:
    - https://github.com/golang/go/blob/master/src/math/big/natdiv.go


# Lab 01
> 2025-02-24

> **Main goal**: Understand SOLID
---


## Hour 1: Warm up, important concepts from software engineering
- "Software engineering is programming integrated over time"
- Explained the origins of OOP
    - Simula vs Smalltalk
    - Alan Kay's version
    - Steve Jobs selling objects for the NeXT operating system
- These principles of software design aren't generally applicable
- Style:
    - coding styles
    - why 80 columns
    - case formats
    - why code formatters exist (explain what gofmt does)
    - commit styles
    - version control systems
- Explained why Rust/Golang don't have classes (prefer composition over inheritance)
- Don't try to be Netflix or Google (design for the problem)


## Hour 2:
- Self-check test
- Explained a few items from the test


## Hour 3:
- SOLID live demos
    - S = Single Responsibility Principle
    - O = Open/Closed Principle (OCP)
    - L = Liskov Substitution Principle (LSP)
    - I = Integration Segregation Principle (ISP)
    - D = Dependency Inversion Principle (DIP)


#### Sources:
- https://abseil.io/resources/swe-book/html/ch01.html
- https://overreacted.io/goodbye-clean-code/
- https://www.youtube.com/watch?v=tD5NrevFtbU
- https://www.youtube.com/watch?v=oKg1hTOQXoY (10:00)
- https://www.youtube.com/watch?v=Gk-9Fd2mEnI
- https://simonwillison.net/2024/Jun/17/russ-cox/

- Books mentioned:
    - https://en.wikipedia.org/wiki/Understanding_Media
    - https://en.wikipedia.org/wiki/The_medium_is_the_message


reading content from D:\SD\SearchEngine_ver1\See\CN3a_2022.pdf


LABORATORY WORK NO. 3a 
OPTICAL FIBERS AND COMPONENTS 

 

 

1. Objectives 

 
The objective of this work is gaining knowledge on optical fibers and components, link 

performance analysis and the optical power budget calculus. 

 

2. Theoretical considerations  

 
2.1 Optical fibers and components 

The current laboratory work continues the focus on the Physical layer of the ISO/OSI stack 

by providing knowledge on optical fibers and components. Furthermore, on part 3b, the main 

network devices and elements of structured cabling are presented. 

Once the drop in the price of optical fibers, and appropriate communications equipment, this 

has become the environment of choice for new high-speed connections (exterior and interior).  

To transmit data, optical fibers send light signals along glass or plastic cores (of the order 

tens of microns (μ), which constitutes a wavelength guide for light, obtained from a 

combination of silicon dioxide and other elements).  

An optical fiber strand is the basic element of an optical fiber cable (a cable contains several 

strands). A strand has three layers: core, cladding and coating. A fiber optic cable consists of 

several components: fiber strand(s), buffer, protective materials, outer jacket. 

The core is wrapped by material made of silicon dioxide having a refractive index lower than 

the core called cladding. In order to protect the cladding, this is wrapped in a plastic material. 

This is called buffer and is wrapped in a material, usually Kevlar, which confers resistance of 

fiber at the time of installation. Optical fiber buffers are of two categories: tight (a protective 

covering is applied over the coating of each fiber strand) or  loose-tube (several strands inside 

a tube filled with a protective gel). For outdoor, long-distance installation, loose-tube fiber is 

preferred. The last wrapper is the jacket which protects the fiber against abrasive materials, 

solvents and other factors. The color enclosure in the case of multimode optical fiber is 

usually orange and in the case of single-mode optical fiber is usually yellow. Each fiber 

optics cable is composed of two fibers wrapped separately, a fiber being used for 

transmission and another for the reception, ensuring in this way a full-duplex connection. A 

cable of optical fiber may contain from two up to hundred separate fiber strands (usually in 

LANs, up to 24). Figure 2.1 presents the layer of an optical fiber and an optical fiber 

transversal section. 



COMPUTER NETWORKS 

 2 

  
Figure 2.1 a. Optical fiber layers               b. Optical fiber transversal section 

 

For the signal to be reflected without loss, the following two conditions need to be met: 

• Optical-fiber must have a refractive index higher than the material surrounding it; 

• The angle of incidence of light signal must be greater than the critical angle of fiber 

and of the material surrounding it. The angle of incidence of light signal can be 

controlled by using the next two factors: 

o Numerical aperture of the fiber is the range of angles of the light signal for 

which the reflection is complete; 

o The modes are the ways that the signal light can follow. 

Unlike copper-based transmission media, optical fiber is not susceptible to, and it does not 

generate electromagnetic or crosstalk interference. 

Two main optical fibers are commonly used in LANs and WANs: single-mode and 

multimode. Single-mode optical fiber is used for long distance links and for vertical cabling 

in buildings (building’s backbone). Multimode optical fiber is commonly used in horizontal 

and vertical cabling. Multimode fiber has a larger core diameter compared to single-mode. 

Thus, multimode does not require the same precision as single-mode, resulting in less 

expensive connectors, transmitters etc. 

For the single-mode fiber the core diameter is small enough as to permit only one mode (one 

way) light signal, being sent in a straight line through the middle of the core. Single-mode 

optical fiber cables use cores with diameter between 8μ and 10μ. The most used single-mode 

optical fibers have 9μ diameter and cladding with a diameter of 125μ. They are usually 

referred as 9/125μ optical fibers. Light source used is the infrared laser. It is recommended 

caution when using lasers as source of light since it may affect the eyes. Single-mode fibers 

may transmit data at distances over 100km. The loss on km of single-mode optical fiber is 

specified by the manufacturer. In the case of single-mode fiber, the refractive index of glass 

stays constant. This type of glass is called step index glass.  

 

The core of multimode fiber has a sufficiently large diameter as to permit several modes 

(several ways) for light signal. Standard multimode optical fiber cables have a core diameter 

of 62, 5μ or 50μ and cladding with a diameter of 125μ. They are usually referred as optical 

fibers of 62.5/125μ or 50/125μ. Usually, the light sources used with multimode fibers are 

Infrared Light Emitting Diode (LED) or Vertical Cavity Surface Emitting Lasers (VCSEL). 

LED-s are cheaper and require less safety measures than lasers. The disadvantage of LED is 

that may not transmit light signals at distances as large as lasers. Multimode fibers of 

62.5/125 may transmit data at distances of up to 2000m. The loss of multimode optical fiber 

is specified by the manufacturer. In the case of multimode fiber, the refractive index of glass 

may be constant (multimode step index glass) or may also decreases from the center to the 



OPTICAL FIBRES AND COMPONENTS 

 3 

exterior  (variable or graded-index glass and allows various illuminating modes to reach the 

receiver at the same time).  

 

In optical fiber, beside propagation, the light is subjected to two main phenomena: 

attenuation and dispersion. Attenuation or absorption is essentially due to the presence of 

hydroxyl ions -OH and of the various metal ions. Light may also be spread by micro crystals, 

lower than the wavelength, which form at the cooling of the glass. Attenuation limits the 

length of optical fiber to be used. The dispersion or impulse width widening is mainly due in 

multimode fibers to the different length of the modes. The chromatic dispersion appears due 

to the variation of the refraction index function of the light colour or wavelength. The 

dispersion limits the use of optical fiber in the frequency or in bandwidth. The two limitations 

multiplied characterize most accurate an optical fiber. 20MHz-km values are obtained for 

fiber with step index, 1GHz-km for the variable index and 1000GHz-km for the single-mode 

in which there is no modal dispersion.  

 

Optical fiber transmitters convert electrical signals in equivalent luminous pulses. There are 

two types of light source used by transmitters for optical-fiber: 

• The LED which produces infra-red light having a wavelength of 850nm or 

1310nm. They are used with multimode fibers. Coupling to optical fiber can be 

improved by using a spherical lens; 

• LASER semiconductor diode containing which produces infra-red light having a 

wavelength of 1310nm or 1550nm. They are used with multimode or single-mode 

fibers. 

 

There are two types of basic design for LEDs: with surface emission and with edge emission. 

At surface emission led, the emission of light is perpendicular to the plane of junction 

through a thin transparent layer. They emit in a geometric radial spectrum. At edge emission 

led the light is emitted in a plane parallel to the junction at semiconductor edge. The materials 

used are often compounds III V as GaAs or Al×GA1-XAs for wavelengths of 0.8-0.9 μm and 

Ga×In1-XPYAs1-y for wavelengths of 1.3-1.6 μm. Emission spectrum of a LED is between 25 

to 40 μm for small wavelengths and 50-100 μm for larger wavelengths. 

 

LASER semiconductor diodes, laser diodes (LD), are obtained by introducing a led into an 

optical resonant cavity. The effect of laser only appears at the existence of a direct current 

high enough to achieve an inversion of the population of the electrons and holes from the two 

energy strips of conduction and valence. The current value from which this effect appears is 

called limit current. Under this current the device acts as an ordinary led. Since the light 

emitted by a laser is much more coherent than issued by a LED, the efficiency of the optical 

fiber coupling is higher. Optical power also captured by laser is greater than that emitted by 

the LED. 

 

An analysis compared between the two types of transmitters is clearly in favour of LD 

because the possibility to use higher frequencies, narrower spectrum and in favour of the 

LED due to price and power stability in relation to temperature. 

 

The life expectancy of both devices is equal and is of the order of 10 million hours. 

 



COMPUTER NETWORKS 

 4 

The fiber optics receivers convert luminous pulses into equivalent electrical signals. 

Semiconductor devices normally used for optical fiber are classified in two types: simple and 

with internal gain. The first may be called PIN photodiode by type of doping (p intrinsic and 

n) and the second category is called APD (Avalanche Photo- Diodes). These devices are 

sensible at 850, 1310 and 1550nm wavelengths, wavelengths used by transmitters for optical 

fiber. As semiconductor materials are used Si for wavelengths of 800-900 nm and Ge or 

InGaAsP for 1300 and 1500 nm. Si has optimum sensitivity only within a reduced 

frequencies range but Ge has an appreciable darkness current and is more sensitive to noise. 

For this reason last possibility is the best but requires a more sophisticated manufacturing 

technology and therefore has a higher price.  

In order to connect multiple fibers or for achieving a longer fiber, splices (junctions) may be 

used. Splices are of two types: mechanical and fusion. Attenuations introduced are lower than 

0.5dB (ANSI/TIA-568-C.3 specifies that mechanical or fusions splices shall not exceed a 

maximum optical insertion loss of 0.3dB). At mechanical splices the two ends of the fiber, 

carefully cut, cleaned and polished are caught in a rigid mechanical holder that they fix to 

each other in an fixed ensemble. Fusion splices shall be carried out by heating close to the 

melting point. At this moment the two fibers are pressed against one another and cooled. 

These operations shall be preceded by cutting operations and finishing their ends and prior 

alignment of the two ends which will be connected. Fusion splices also remake draw/bursting 

resistance of the fiber at approximate 90% of the original value. To protect the splices, splice 

enclosures are used. 

Connectors in the optical fiber allow the connection to ports. The common used connectors 

are SC (Subscriber Connector) - snap on type, ST (Straight Tip) - twist on type, FC (Ferrule 

Connector) - screw on type, LC (Lucent Connector) - snap on type and MTP/MPO - 

push/pull type, for multimode optical fibers and for single-mode optical fibers. Attenuation 

introduced by an optical connector, even of superior quality is greater than that introduced by 

a splice, having values of approximately 1 dB. Connectors are high precision mechanical 

equipment and usually one end of the fiber is in the connector and one is free. In this case 

attaching a connector shall be reduced to the execution of a splice. Such a solution is usually 

more advantageous than mounting a connector directly to the end of the fiber because 

prefabricated connectors ensure the accuracy of mounting much higher. If the optical fiber is 

ended into an optical fiber terminator for redistribution this end connector is also called pig-

tail and is prefabricated type. A special category of connectors is optical cords for distribution 

or connection. These are special optical fibers with connectors at both ends allowing small 

fiber curvature radii of approximately 2,5-5 cm. Their color is yellow for single-mode fiber 

and orange for multimode fiber 

 

Repeaters are optical amplifiers receiving light signals attenuated as a result of the distance 

traveled through optical fiber, remake the form, power and time parameters of these signals 

and send them away. 

 

Patch panels for optical fiber are similar with copper cable patch panels, increasing 

flexibility of the optical networks. For connecting different equipment, an optical fiber patch 

cord is used (also known as a zip cord - two flexible optical fibers with connectors at each 

end). 

 



OPTICAL FIBRES AND COMPONENTS 

 5 

Additionally, several other active or passive devices are used with optical fibers (e.q.: optical 

couplers - combines or splits optical signals; optical attenuators - reduce the power level of an 

optical signal; optical isolators; fiber-optic switches; optical multiplexers, etc.). 

 

The ISO/IEC 11801-1 specifies the  requirements for coaxial, twisted-pair copper and optical 

fiber. The ISO/IEC 11801 (Europe) and ANSI/TIA-568-C (USA and Canada) standards 

define 7 classes of optical fibers (single-mode and multimode) as shown in table 2.1, together 

with several important parameters (optical fiber requirements, the cable transmission 

performance and the physical cable requirements): 

 
Table 2.1 Optical fiber characteristics 

 
 

Multimode Single-mode 

Type OM1 

62,5/125 

μm 

OM2 

50/125 

μm 

OM3 

50/125 

μm 

OM4 

50/125 

μm 

OM5 

50/125 

μm 

OS1 

9/125 μm 

OS2 

9/125 μm 

Wavelength 850, 

1300nm 

850, 

1300nm 

850, 

1300nm 

850, 

1300nm 

850, 

1300nm 

1300nm, 

1550nm 

(1383nm) 

1300nm, 

1550nm 

Max. attenuation 

(db/km)  

2.6 /  

2.4 

3.56 / 

2.3 

2.6 /  

1.9 

2.9 /  

1.5 

2.9 /  

1.5 

1 0.4 

Light source LED (Light-Emitting Diode) /  

VCSEL (Vertical Cavity Surface-Emitting Lasers 

Light Source)  

LASER (Light 

Amplification by 

Stimulated Emission of 

Radiation) 

Distance/ 
data rate 

1 Gbps 275m 550m - - - 5-120km 

10Gbps 33m 82m 300m 400m 400m 10-80km 

40-100 

Gbps 

- - 100m 150m 150m 2-80km 

Color orange/ 

slate 

orange aqua violet/ 

aqua 

green/ 

lime 

yellow yellow 

 

Incorrect installation of optical fiber has as result the increase in attenuation for the optical 

signal. The scope or exaggerated than optical fiber may cause cracks in the heart to disperse 

the signal light. Exaggerated stretching or bending of the optical fiber may cause small cracks 

of the core which will scatter the light signal. Exaggerated bending of the optical fiber may 

have as a result the drop in incident angle of the light signal under critical angle of total 

reflection. For the connector installation the heads must be cut off and finished. After 

installation, the heads of the optical fibbers, the fiber connectors and ports must be kept clean 

so that no attenuation will be introduced. Before use of optical fiber cables, their attenuation 

must be tested. At the design of an optical-fiber links, loss of power signal that can be 

https://en.wikipedia.org/wiki/Optical_fiber


COMPUTER NETWORKS 

 6 

tolerated must be calculated. This is called the budget of loss of optical link. Loss of power is 

measured in decibels (dB). 

 

For optical fiber link testing there are several methods: continuity testing, visual fault locator, 

measurement of optical power output, OTDR and BER test error rate. 

 

Continuity testers are used to test the continuity in an optical fiber. A visual fault locator 

(VFL) tool allows a technician to identify breaks, macrobends (refers to the minimum 

bending radius) or poor fusion splices. 

 

The measurement of optical power output determines the loss of power through the optical 

link by measuring the output power at a known input power. The unit of measurement for 

optical power is the miliwatt (mW) but for practical reasons shall be used other unit of 

measure which measure the gain (G) or loss (L) in a system, namely decibel (DB). 

 

The procedure OTDR Optical Time Domain Reflectometer is the procedure by which the 

attenuation characteristics of an optical fiber and its length may be visualized. This procedure 

is the only through which can be detected positions such breaks in optical fibre. OTDR 

displays a graphic having as X axis the fibre length and as Y axis the attenuation. From this 

graphic, the fiber attenuation and the splices and connectors quality can be deduced. Also can 

be determined the braking position in the cable if externally the cable is not affected. 

 

The BER test (Bit Error Rate) is the final test for a data link through optical fiber. This test or 

criterion shows at how many bits transmitted through the fibre an error due fibre will be 

produced. The BER test must meet the requirements imposed by the producers of the DTE 

equipment that are coupled to the optical fibre. For computer networks they ask to be less 

than 1 bit of error at 109/1012 bits transmitted or BER < 10-9/10-12. For the testing is required a 

generator of random bit sequence and an interface to optical fibre if a loop is tested or two if 

a single fibre is tested. In order to have significant results, the test must be carried out over a 

period long enough so as to provide a sufficient number of bits. The test period of one day or 

two are common if it is working at a large bit rate in the use of optical fibre link and small 

BER. A counter may automatically count the number of errors detected. 

 

Calculation of optical power budget shall be made according to the following table. 

 
Table 2.2 Optical power budget 

 

Crt.  Optical loss or power DB  

1.  The km loss in Optical Fibre db/km X _____km fibre _____dB  

2.  The loss in Splices ___dB/splice X _____splices _____dB  

3.  The loss in Connectors __dB/connector X ___ connectors _____dB  

4.  Losses on other components _____dB  

5.  Margin of error _____dB  

6.  Total loss on the Link (1+2+3+4+5) _____dB  

7.  The power of average emission of the transmitter _____dB  

8.  Average power received by the receiver (7-6)  _____dB  

9.  The dynamic of the receiver _____dB at _____dB   

10.  Receiver sensitivity at a rate of errors given by BER _____dB  

11.  Available Remaining Power  (8-10) _____dB  



OPTICAL FIBRES AND COMPONENTS 

 7 

Remarks  

 

For item 3. the transmitter connection losses to the optical will not be taken into account, 

these being already included. The amount calculated in item 8. must be within the range of 

item 9. for the receiver to operate correctly. The amount calculated in item 11 must be 

positive in order to have a functional optical data link.  

 

The error margin is due to take into account the average values for all link components. The 

dispersion of these values around the mean value is known and may take a margin of error 

large enough to cover deviations from an average with a probability of 99.9% or more. As the 

number of items is greater and as it is desirable a larger cover probability than a larger error 

margin will be taken. 

 

Optical emission power of the transmitter is a catalogue data and includes the loss of 

connection at one end of the optical fiber in the case in which the connection is made in 

accordance with recommendations. The power is greater at the LASER diodes and smaller at 

the LED. In the case of LASER usage for relatively short distances an attenuator is necessary 

so that the receiver will not be destroyed. 

 

Receiver dynamics represents the power range which a receiver can transform in electrical 

signal without loss of information. 

 

It is also needed a minimum optical power necessary for fulfilling the tolerated error rate 

condition which for computer networks is situated at the value of 1 bit erroneous at one 

billion bits transmitted. 

 

Calculus example of the optical power budget  

 

Optical fiber diameter: Core 62.5μm/Cladding 125μm. 

Numerical aperture of the fiber NA: 0.275. 

The wavelength of the optical equipment: 1310μm.  

 
Table 2.3 Calculus example 

 
Crt.  Optical loss or power DB  

1.  The km loss in Optical Fiber 1,8db/km X 3,5km fiber 6,3dB  

2.  The loss in Splices 0,5dB/splice X 2 splices 1,0dB  

3.  The loss in Connectors 1,0dB/connector X 2 connectors 2,0dB  

4.  Losses on other components 0,0dB  

5.  Margin of error 2,0dB  

6.  Total loss on the Link (1+2+3+4+5) 11,3dB  

7.  The power of average emission of the transmitter -10,0dB  

8.  Average power received by the receiver (7-6)  -21,3dB  

9.  The dynamic of the receiver _____dB at _____dB  

10.  Receiver sensitivity at a rate of errors given by BER -26,0dB  

11.  Available Remaining Power  (8-10) +4,7dB  

 

The power at the receiver is in the dynamic of the receiver, which makes possible its 

function, and the remaining available power is positive, ensuring a viable connection. 



COMPUTER NETWORKS 

 8 

 

There should be taken into account the fact that during the life of the link, aging phenomena 

may occur, leading to increase the power loss, as well as the fact that optical fiber may be 

broken accidentally and needs to be spliced.  

 

A calculation made to the limit endangers the length of service of a link through optical fiber. 

 

 

 

3. Lab activity 

3.1 The characteristics of various types of optical fibers, components and aspects related to 

the cabling of computer networks using this transmission environment should be discussed. 

3.2 Explore the fiber optic infrastructure deployed in the oceans available at 

https://www.submarinecablemap.com/ 

3.3 A 9/125μ single-mode optical fiber having the length of 2,5km and the loss equal to 

0,5dB/km, which connects two DTE equipments is considered. The attenuation introduced by 

splices and connectors is equal to 0,5 and 1dB respectively. The error margin taken into 

consideration is 3dB. The power of average emission of the transmitter is -15dB, the receiver 

sensitivity at a rate of errors given by BER 10-9 is -25dB and dynamic of the receiver is in the 

range -10 ÷ -30dB. Calculate the optical power budget. 

 

 

Notes 

 



reading content from D:\SD\SearchEngine_ver1\See\CN3b_2022.pdf


LABORATORY WORK NO. 3b 
STRUCTURED CABLING 

 

1. Objectives 

 
The objective of this paper is the knowledge of structured cabling, networks topology and the 

function of the different network devices. 

 

2. Theoretical considerations 

 
2.1 Physical media analysis 

 

In the physical media analysis, we may choose several factors of performance such as: the 

speed of transfer, bandwidth, reliability or the error rate, the duration of service, the average 

duration between the two defects, defects tolerance, direct costs, indirect costs, the cost per 

port or equipment connected, the cost per bandwidth or the total cost per port per bandwidth. 

The bandwidth, LB is a factor of intrinsic performance particular to each medium. The 

reliability, F, is also a factor of intrinsic performance of each medium and shall be the ratio of 

the number of bits erroneously transmitted to the total number of bits transmitted. The service 

duration, De, is the length of time after the environment should be replaced, due to aging 

phenomena. The average duration between two faults, DMDD, is the statistical average time 

between two successive malfunctions of the environment for the standardised period of life. 

Defects tolerance, Td, is a factor of performance induced on the physical environment by the 

technology and network architecture used, but in many cases a given environment does not 

allow a error tolerance architecture or only one limited. Direct costs, Cd, are represented by 

the actual cost of the environment along with connectors, the auxiliary materials necessary 

for correct posing, and the cost of labour for communication environment realisation and 

environment testing. The cost per port, Cp, it is a synthetic factor which has a greater decision 

value, being a global decision criterium and reflecting the total costs for carrying out physical 

infrastructure related to the total number of ports or equipment connected. The cost per port 

per speed of transfer, Cpv, is a factor performance more usefull which alleviates taking a 

correct decision in the implementation of a local area network, including the possibility of 

future extension without the need for change the environment. The total cost per port per 

speed, Ctpv, is a complex factor of performance which characterizes a local area network at 

global level also including the equipment or technology costs. Characterization of 

performance factors above referred of the physical communication media previously 

presented is summarized in the following table. Performance factors, and in particular the 

type of cost, shall be classified relatively without giving absolute values which may be 

affected very rapidly in time. 

 
Table 2.1  Performance factors 

 

 

Medium Lb 

Gbps 

Reliability De 

years 

DMDD Td Cd Cp Cpv Ctpv Recomanded 

in usage 

Further use 

UTP Cat 6,7 >1 Medium 15 years Yes Medium Small Small Small Yes Yes  

Multimode OF >1 Large 30 years Yes Large Medium Medium Medium Yes Yes 

Single-mode OF >1 Large 30 years Yes V. Large V. Large Large Large Yes Yes 



COMPUTER NETWORKS 

 2 

2.2 Structured cabling  

 

There are three standard network topologies bus, star and ring: 

• Bus topology is the oldest method of interconnecting computers in a network. 

Data is transmitted to all the stations but is accepted only by the destination 

station, and the reflection of the signal is stopped using terminators. Figure 2.1 a. 

represents the bus topology; 

• Star topology has replaced the bus topology, the main feature is that it has a 

central component called hub through this component data is transmitted from one 

station to all the others. The star topology offers the resources and means for 

central administration. Figure 2.1 b. represents the star topology; 

• Ring topology stations are connected through a cable shaped as a ring and every 

station is acting as a repeater amplifying the signal. Figure 2.1 c. represents the 

star topology. 

 

Today most of the topologies used are combinations of star, ring and bus topologies. The bus-

star topology supposes connecting networks with star topology through linear branches (bus). 

Problems of connectivity appear when a concentrator fails. The ring-star topology also 

known as ring cabled as a star. In this case there is a central concentrator that connects all the 

other concentrators to which the stations are connected. 

 

 

 

 

 

 

 

 

 

 

 

 

 
      a. bus topology            b. star topology         c. ring topology 

 
Figure 2.1 Standard network topologies 

 

Under the generic name of active elements are grouped all of the network components that 

need a power supply and can work with electric, optic signals or both. Network interface 

cards are active elements of layer 2 providing the stations with the network connectivity. 

Every network interface card has its own 48 bits MAC address assigned from fabrication. 

This address is unique for every network card and it is composed of 2 parts: the 24 most 

significant bits identifies the producer, and the 24 least significant bits are assigned by the 

producer. The network interface cards used in PC’s need an I/O address space and a hardware 

interrupt. The interrupt is activated every time an event (a frame reception in most of the 

cases) appears requiring software attention, and the I/O address space represents the address 

region in which the card registers are accessible (written, read, by its driver). Usually both the 

interrupt and the I/O space are configurable to avoid conflicts with other devices. 

 

Station 

 

 

Station 

 

 

Station 

 

 

Switch 

 

 

Station 

 

 

Station 

 

Station 

 

 

Station 

 

Station 

 

 

Station 

 

 

Station 

 

 

Station 

 

 

Station 

 



STRUCTURED CABLING 

 3 

The overcome of the length limitations of cables is done by using repeaters. These are 

simple devices, connected at many network segments amplifying the signal that passes 

through them. Repeaters operate at the physical layer (they don’t have the frame notion or 

package transmitted through the network) and they broadcast the amplified signals on all 

their outputs.  

 

With the growth of the network dimensions, problems will appear if there are used only 

repeaters. The limitation for the stations that create such a network is the fact that 

repeaters/hubs(multiport repeaters) split the bandwidth, being situated in a single collision 

domain. In order to solve this problem we use bridges, equipments that operate at the second 

layer in the OSI hierarchy, and they represent devices much more complex than repeaters 

because they perform frame filtering based on MAC addresses and a separation of collision 

domains. Bridges don’t forward the frames that are local for a network, but only the ones that 

have destination addresses located in other networks. They store the frames and realize a 

retransmission only to the network in which the destination is situated. When the bridges are 

powered-up they know nothing about the network configuration and the addresses of the 

computers connected to it, but they learn the network topology while they forward the 

frames. Initially they allow all the frames to pass in all directions. But in time, as frames pass 

through, the bridge inspects the source address of each frame and completes the MAC tables, 

with the station address and the port at which the station is connected. Based on these tables 

they decide on which port the frames must be retransmitted. Frames sent at broadcast or 

multicast addresses will be retransmitted further away on all ports. Switches are layer 2 

equipments that take frames forwarding decisions based on the MAC address, so to direct the 

data only on the port corresponding to the destination host. These devices can be seen as 

devices capable to offer the connectivity of a hub and they manage the traffic like a bridge. 

Designing networks with complex topologies is done using switches. 

 

Routers are layer 3 equipments that route the packets based on the address used by routable 

protocols (for example Internet Protocol-IP or Internetwork Packet Exchange – IPX) with the 

help of the routing protocols (for example Routing Information Protocol RIP, Interior 

Gateway Routing Protocol – IGRP, Enhanced Interior Gateway Routing Protocol – EIGRP or 

Open Shortest Path First - OSPF). There are two main router types: dedicated routers and 

routers built from general purpose computers that have more interfaces. The computer routers 

have the advantage of cost and simplicity and can be used for other jobs. Dedicated routers 

are much more efficient and flexible, have much more interfaces and support more protocols 

and medium access types. Dedicated routers are devices specialized for the routing job. Due 

to the specialized hardware and powerfully optimized software, they achieve superior 

performance. They offer a wide range of speeds, physical interfaces and communication 

protocols. Usually these are manufactured by specialized firms (Cisco, Juniper, HPE etc.) 

their operating system is specific and has all the software need for the router to function 

properly. Dedicated routers support almost any transmission medium, used with any 

communication protocol, with a large range of sockets and adaptors. 

 

Taking in consideration the costs for realizing or modifying a network cabling it has been 

proved that once a network has been set in place is better to stay in use as long as possible 

and that it should be able to be used with novel communication technologies. The solution for 

this problem was in the elaboration of the structured cabling concept, defined later through 

several international standards. 



COMPUTER NETWORKS 

 4 

The ISO/IEC 11801 (Europe) and ANSI/TIA-568-C (USA and Canada) standard refer to the 

ways of cabling commercial edifices, specifying the cabling structure, the necessary minimal 

configuration, the categories of cables and components that must be used, ways of 

installation, performance requests that have to be met, acceptable distance limits and other 

parameters, and also ways and methods for testing them. Another problem that is approached 

is the problem of designing the cabling for a much more complex building group, in this way 

a complex project needs to be configured in a hierarchic (tree-like) structure, allowing the 

possibility to add redundant links. The standard specifications refer to some of the following 

aspects: 

• Minimal request for realizing the cabling of a building 

o The cabling topology and allowed distances; 

o Component elements of the cabling; 

o Transmission media used with the needed parameters specification; 

o Vertical and horizontal cabling realization mode; 

o Ways of identifying the cables used; 

o Project documentation. 

• Subsystems and components of the structured cabling system 

o The subsystem from the entrance in the building; 

o The equipment room; 

o The backbone cabling; 

o The telecommunication closet; 

o Horizontal cabling; 

o The work area components. 

 

The cabling topology specified in the ISO/IEC or ANSI/TIA standard is a star, hierarchically 

organized (extended star). The topology center is main distribution facility, the second 

hierarchic level is the intermediary distribution facility afferent to one area edifice, and at the 

lower level is the telecommunication closet related to a floor or a group of rooms. The 

constitutive elements are: 

• The main distribution facility – the distribution center to the other edifices; 

• The intermediary distribution facility – are local to edifices; 

• The telecommunication closet – is represented by the local distribution closets for 

the cables that connect the stations or related to the vertical cabling; 

• The inter-edifice section – identifies the main cables that interconnect the main 

distribution center; 

• The internal section – connects the intermediate commuter with the distribution 

offices; 

• The equipment room – related to a cabling plan with passive and active 

equipments; 

• The entrance infrastructure – for the interfacing of the exterior cabling system 

with the interior one; 

• The work area – the working stations, interconnection cables, external adaptors 

between cables; 

• Intermediate panels – identifies the connection panels for the transmission 

mediums; 

• Terminator blocks – represent the cable mechanical terminators; 

• Communication outlets, cabling adaptors. 



STRUCTURED CABLING 

 5 

 

The usual transmission media are: 

• Twisted cable (category 6 and above); 

• Multimode or single-mode optical fiber; 

 

Types of the connectors used are: 

• RJ-45 connectors for TP cables; 

• LC, SC or ST type connectors for optical fiber; 

 

So, in order to accommodate a much easier and efficient way to manage the network, the 

cabling is structured using concentrators (on different levels). At each level a concentrator 

must be implemented, and if the covered area is too large than several concentrators can be 

used. At the working stations the UTP cable is ended in RJ-45 connectors, and at the 

concentrator in boxes or patch panels. The cumulative length of the cable and UTP patch cord 

used for connecting a computer at the equipment from the concentrator is not allowed to be 

greater than 100m. In the floor concentrator the switches or other equipments are situated. 

 

The advantages concentrators offer (and also the topologies based on concentrators) are: 

• possibility to extend or modify the cable system; 

• usage of different ports, adapted at different types of cables; 

• possibility of a central monitoring of the activity and the network traffic. 

 

Types of concentrators: 

• Active concentrators – that regenerates and transmits the signal; 

• Passive concentrators – can be considered the cabling panels or the connection 

blocks representing only connection points without any signal amplification. Also 

there are hybrid concentrators that allow the usage for connection of different 

cable types. 

 

The cables must be labeled according to the standard, the ventilation must be sufficient to 

prevent equipment overheating, security measures must be set and fire protection must be 

provided. The floor concentrator is connected to the building concentrators, link that can be 

realized with a category 6 cable or with multi-mode optical fiber. Additionally, redundant 

links can be added between the floor concentrators and between the buildings. The building 

group concentrator is connected to the buildings concentrators with multimode or single-

mode optical fiber. Installation standards are referring to the cable installation (maximum 

tension allowed on the cable, mechanical connection type), masked horizontal cabling, 

ground protection, and the specific protection of the optical fibers cables. 

 



COMPUTER NETWORKS 

 6 

3. Lab activity 

 
3.1 The topologies of the computer networks are going to be discussed underlining their 

advantages and disadvantages. 

3.2 The function of the following network devices will be discussed: network interface card, 

concentrator, repeater, bridge, switch and router. 

3.3 Aspects of the structured cabling and ISO-IEC/ANSI-TIA standard will be discussed. 

3.4 Floor cabling will be analyzed, and the elements of the structured cabling will be pointed 

out. 

3.5 Identify and analyze the structured cabling design at your workplace/home. How is your 

network connected to the WAN/ISP (what type of cable, device, etc)? How is your device 

connected to the internal network? 

 

 

 

 

Notes 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 



reading content from D:\SD\SearchEngine_ver1\See\CVGenenral.pdf


0770644019

braica.patricia@yahoo.com

Satu Mare / Cluj Napoca,
Romania

Computer Science Student
Technical University of Cluj-Napoca
expected graduation year 2026

EDUCATION

ABOUT ME

MOST RELEVANT COURSES

English C1
German B1

LANGUAGE

PATRICIA MARIA BRAICA
S T U D E N T

Completing the Fundamental Algorithms and Data Structures in C
course set me on the path to efficiency in programming.

Fundamental Algorithms in C

I successfully completed an Object-Oriented Programming (OOP)
course using Java, which included a mandatory project.

OOP on Java and C++

Through the completion of an SQL course, I acquired the essential
skills required for effective database management.

SQL programming

Romanian (Native)

linkedin.com/in/patricia-
maria-braica-00534b298

Successfully completing the Logic Design of Circuits course has
been instrumental in building a strong foundation for my
understanding of hardware systems.

Logic Design of Circuits, Assembly, VHDL

EXPERIENCE IN IT
I created a Java applications utilizing the JavaFX framework, seamlessly connected to a database using
SQL, and enhanced the user interface with CSS(My projects: Order app for a backery simulation,
Polynomial Calculator, Queue Management Simulator in real time using multithreading, Order management  
simulation using Reflection techiques. )
I successfully implemented a VHDL project on the Nexys 4 board, featuring the display of eight
dynamic animations conveying a message, resembling a digital advertisement.

Through the completion of an SQL course, I acquired the essential skills required for
effective database management.

PROGRAMMING LANGUAGES 
C,C++, Java, SQL, VHDL, Assembly x86, Arduino, Haskell, Git Bash, LaTeX, Python, Prolog

Attended domain related competitions: CodeRun competiotion by BEST, in Cluj-Napoca,
WIDS(Women in Data Science) - predict ADHD in women, on Kagggle.

Github and GitLab repos:
https://github.com/Patriciadah
https://pastebin.com/UtuJW7m2

Organized, results-driven, and experienced in structuring learning
programs. Studying in English enhances my understanding of technical
terms. Broad knowledge in computer science: software engineering, AI,
full-stack development, cybersecurity and more. Strong vision for
teamwork and project execution.

Implemented PDDL-like theorem proving to detect deception in
Among Us. Designed AI solutions for Sliding Tile Puzzle and All Lights
Out using automated planning. Integrated AI into the Pac-Man
framework for decision-making and pathfinding, leveraging
adversarial search.

AI Technologies in Python

https://www.linkedin.com/in/patricia-maria-braica-00534b298
https://www.linkedin.com/in/patricia-maria-braica-00534b298
https://github.com/Patriciadah
https://pastebin.com/UtuJW7m2


reading content from D:\SD\SearchEngine_ver1\See\EY.txt

PE@!HxG433M4hTyt

reading content from D:\SD\SearchEngine_ver1\See\FileIndexRowMapper.java

package com.example.searchengine_ver1.backendapi.repository;

import com.example.searchengine_ver1.model.FileIndex;
import org.springframework.jdbc.core.RowMapper;

import java.sql.ResultSet;
import java.sql.SQLException;

public class FileIndexRowMapper implements RowMapper<FileIndex> {
    @Override
    public FileIndex mapRow(ResultSet rs, int rowNum) throws SQLException {
        return new FileIndex(
                rs.getLong("id"),
                rs.getString("file_name"),
                rs.getString("file_path"),
                rs.getString("file_type"),
                rs.getString("file_content"),
                rs.getTimestamp("indexed_at").toLocalDateTime()
        );
    }
}


reading content from D:\SD\SearchEngine_ver1\See\FileIndexService.java

package com.example.searchengine_ver1.backendapi.service;

import com.example.searchengine_ver1.model.FileIndex;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;

import java.util.List;

@Service
public class FileIndexService {
    private final FileIndexRepository fileIndexRepository;

    @Autowired
    public FileIndexService(FileIndexRepository fileIndexRepository) {
        this.fileIndexRepository = fileIndexRepository;
    }

    public void indexFiles(List<FileIndex> files) {
        fileIndexRepository.saveAll(files);
    }

    public List<FileIndex> searchFiles(String query) {
        return fileIndexRepository.searchFiles(query);
    }
}


reading content from D:\SD\SearchEngine_ver1\See\files_border_tracing.zip


gray_background.bmp


horizontal_ellipse.bmp


object_holes.bmp


skew_ellipse.bmp


star.bmp


star_R90.bmp


triangle_down.bmp


triangle_up.bmp


vertical_ellipse.bmp


reconstruct.txt
159 175
3149
5 4 4 4 5 4 4 5 4 5 4 5 4 5 5 5 4 5 6 5 5 5 6 5 5 6 5 6 6 5 6 6 5 6 6 6 6 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 6 6 6 6 7 6 6 6 7 6 7 6 7 6 7 7 7 6 7 7 0 7 7 7 0 7 7 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 3 3 2 3 3 2 3 3 2 3 3 2 3 2 3 3 2 3 3 2 3 3 2 3 3 2 3 3 2 3 2 3 3 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 2 1 1 2 1 1 2 1 1 2 1 1 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 6 5 6 5 5 6 5 5 6 5 5 6 5 5 6 5 5 6 5 3 2 3 3 2 3 3 2 3 3 2 3 3 2 3 3 2 3 2 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 6 7 7 6 7 7 6 7 7 6 7 7 6 7 7 6 7 6 7 7 6 7 7 6 7 7 6 7 7 6 7 7 6 6 5 5 6 5 6 5 5 6 5 5 6 5 5 6 5 5 6 5 5 6 5 6 5 5 6 5 5 6 5 5 6 5 5 6 5 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 1 2 1 1 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 2 1 7 6 7 7 6 7 6 7 7 6 7 7 6 7 7 6 7 7 6 7 7 6 7 6 7 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 7 6 7 7 6 7 6 7 7 6 7 7 6 7 6 7 7 6 7 6 7 7 6 7 7 6 7 6 7 7 6 7 7 6 7 6 7 7 6 7 7 6 7 6 7 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 6 6 6 6 6 6 6 6 6 6 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 3 2 3 2 3 3 2 3 2 3 3 2 3 3 2 3 2 3 3 2 3 3 2 3 2 3 3 2 3 3 2 3 2 3 3 2 3 2 3 3 2 3 3 2 3 2 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 1 1 0 1 1 1 1 1 1 2 1 1 2 1 2 1 2 2 1 2 4 3 4 4 3 4 4 4 3 4 4 3 4 6 5 6 6 5 6 5 5 6 5 5 5 4 5 4 5 4 5 4 4 4 4 4 4 4 4 3 4 4 3 4 3 4 3 3 3 3 2 3 2 3 2 2 3 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 1 2 1 2 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 7 0 0 7 0 7 7 7 7 7 6 7 6 7 6 0 1 0 0 0 0 1 0 0 0 0 1 0 2 3 2 3 2 2 3 3 2 3 3 3 3 3 3 4 3 3 4 3 4 4 3 4 4 4 3 4 4 4 4 4 4 4 4 4 4 4 4 



reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele (1).docx

Fisa de lucru – Tabele

Aplicatia 1

1. Creaţi un document Word nou, cu următoarele setări de pagină: format A4, margini: dreapta 1.75 cm, stânga 1.62 cm, sus 2.04 cm, jos 2.37 cm, orientarea paginii orizontală(landscape).
 realizaţi un antet aliniat la stânga, care să conţină “Date elevi” ;
 numerotarea paginii: stânga – sus utilizând cifre romane cu dimensiunea de 14, bold, fontul Tahoma.

1. Creati un tabel cu urmatoarea structura :
	
	Nr. crt.
	Numele si Prenumele
	Disciplina

	
	
	Matematica
	Lb. Romana
	Informatica

	
	
	Note
	Media
note 
	Teza
	Media 
finală
	Note
	Teza
	Note
	Teza

	
	
	N1
	N2
	
	
	
	N1
	N2
	
	N1
	N2
	

	1.
	Popescu Ion
	7
	8
	
	5
	
	5
	7
	6
	10
	8
	10

	
	
	
	
	
	
	
	
	
	
	
	
	



 Cerinte :
1. pentru tabel conturul exterior:linie dubla,grosime linie-4 ½ pt, culoare verde
1. -liniile dintre coloane sa fie punctate de culoare albastru si grosime 3 pt
1. Adaugati si pentru disciplinele Lb. Romana si Informatica coloanele Media note și Media finală, ca si la Matematica
1. Completati coloana Media note ca fiind (N1+N2)/2 iar Media finală dupa formula (3*media note +teza)/4
1.  adaugati inca 5 linii pe care le completati cu date
1. Sortati tabelul descrescator dupa nume


Aplicatia 2
Realizati urmatoarele tabele:
	
	INTERNET
	INTERNET
	Cea mai mare retea de informatii si comunicare din lume

	
	TCP/IP
	Protocol prin care retelele comunica intre ele in cadrul retelei mari

	
	URL
	Adresa unei pagini de Internet

	
	Adresa IP
	Adresea unui calculator in Internet

	
	ISP
	Furnizor de servicii Internet (firma care faciliteaza accesul la Internet)



	VOCABULAR

	Site Web
	Loc in www, unde se gasesc mai multe pagini web

	Pagina Web
	In limba engleza web-page; o pagina in www

	Pagina de start (homepage)
	Pagina principala a unui site web




	VOCABULAR

	e-mail
	Electronic mail; posta electronica; metoda de transmitere a mesajelor prin Internet

	attachment
	Fisiere atasate mesajului si trimise impreuna cu acesta





	
O adresa de e-mail (de exemplu: operarepc_1@yahoo.com) este alcatuita din urmatoarele componente: 


	Numele de utilizator
	Numele de utilizator sub care v-at inregistat in serverul de mail (Operarepc_1)

	@
	At, cunoscut si sub denumirea coada de maimuta

	domeniu
	Numele serverului de e-mail sau al furnizorului, care are in administrare casuta postala (Yahoo.com)




	
Alcatuirea e-mail-urilor


	Butonul Compose




	To
	Aici trebuie introdusa adresa destinatarului. 
E-mail-urile cu adresa gresita se intorc cu mesaj de eroare.

	Cc (Carbon copy – copie)
	Daca aici este introdusa o adresa de e-mail, mesajul este transmis si acelei persoane.

	Bcc (Blind carbon copy – copie oarba)
	La fel ca la Cc, numai ca destinatarul nu vede adresa celeilalte persoane careia i-a mai fost transmis e-mail-ul. 

	Subject (subiect)
	Aici scrieti un cuvant cheie (titlul care reprezinta esenta mesajului

	Corpul mesajului
	In acest spatiu se scrie textul. 

	Butonul Send





Aplicatia 3

Realizati in Ms. Word tabelul de mai jos urmand ca pentru fiecare simbol „?” sa inseram formula de calcul necesara fiecarei celule






image1.png


reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele.docx

Fisa de lucru – Tabele

Aplicatia 1

1. Creaţi un document Word nou, cu următoarele setări de pagină: format A4, margini: dreapta 1.75 cm, stânga 1.62 cm, sus 2.04 cm, jos 2.37 cm, orientarea paginii orizontală(landscape).
 realizaţi un antet aliniat la stânga, care să conţină “Date elevi” ;
 numerotarea paginii: stânga – sus utilizând cifre romane cu dimensiunea de 14, bold, fontul Tahoma.

1. Creati un tabel cu urmatoarea structura :
	
	Nr. crt.
	Numele si Prenumele
	Disciplina

	
	
	Matematica
	Lb. Romana
	Informatica

	
	
	Note
	Media
note 
	Teza
	Media 
finală
	Note
	Teza
	Note
	Teza

	
	
	N1
	N2
	
	
	
	N1
	N2
	
	N1
	N2
	

	1.
	Popescu Ion
	7
	8
	
	5
	
	5
	7
	6
	10
	8
	10

	
	
	
	
	
	
	
	
	
	
	
	
	



 Cerinte :
1. pentru tabel conturul exterior:linie dubla,grosime linie-4 ½ pt, culoare verde
1. -liniile dintre coloane sa fie punctate de culoare albastru si grosime 3 pt
1. Adaugati si pentru disciplinele Lb. Romana si Informatica coloanele Media note și Media finală, ca si la Matematica
1. Completati coloana Media note ca fiind (N1+N2)/2 iar Media finală dupa formula (3*media note +teza)/4
1.  adaugati inca 5 linii pe care le completati cu date
1. Sortati tabelul descrescator dupa nume


Aplicatia 2
Realizati urmatoarele tabele:
	
	INTERNET
	INTERNET
	Cea mai mare retea de informatii si comunicare din lume

	
	TCP/IP
	Protocol prin care retelele comunica intre ele in cadrul retelei mari

	
	URL
	Adresa unei pagini de Internet

	
	Adresa IP
	Adresea unui calculator in Internet

	
	ISP
	Furnizor de servicii Internet (firma care faciliteaza accesul la Internet)



	VOCABULAR

	Site Web
	Loc in www, unde se gasesc mai multe pagini web

	Pagina Web
	In limba engleza web-page; o pagina in www

	Pagina de start (homepage)
	Pagina principala a unui site web




	VOCABULAR

	e-mail
	Electronic mail; posta electronica; metoda de transmitere a mesajelor prin Internet

	attachment
	Fisiere atasate mesajului si trimise impreuna cu acesta





	
O adresa de e-mail (de exemplu: operarepc_1@yahoo.com) este alcatuita din urmatoarele componente: 


	Numele de utilizator
	Numele de utilizator sub care v-at inregistat in serverul de mail (Operarepc_1)

	@
	At, cunoscut si sub denumirea coada de maimuta

	domeniu
	Numele serverului de e-mail sau al furnizorului, care are in administrare casuta postala (Yahoo.com)




	
Alcatuirea e-mail-urilor


	Butonul Compose




	To
	Aici trebuie introdusa adresa destinatarului. 
E-mail-urile cu adresa gresita se intorc cu mesaj de eroare.

	Cc (Carbon copy – copie)
	Daca aici este introdusa o adresa de e-mail, mesajul este transmis si acelei persoane.

	Bcc (Blind carbon copy – copie oarba)
	La fel ca la Cc, numai ca destinatarul nu vede adresa celeilalte persoane careia i-a mai fost transmis e-mail-ul. 

	Subject (subiect)
	Aici scrieti un cuvant cheie (titlul care reprezinta esenta mesajului

	Corpul mesajului
	In acest spatiu se scrie textul. 

	Butonul Send





Aplicatia 3

Realizati in Ms. Word tabelul de mai jos urmand ca pentru fiecare simbol „?” sa inseram formula de calcul necesara fiecarei celule






image1.png


reading content from D:\SD\SearchEngine_ver1\See\geometrical_features_images.zip


Single Object/skew_line.bmp


Single Object/horizontal_line.bmp


Single Object/vertical_line.bmp


Single Object/skew_ellipse.bmp


Single Object/horizontal_ellipse.bmp


Single Object/vertical_ellipse.bmp


Single Object/vertical_ellipse_Z150%.bmp


Single Object/star_R90.bmp


Single Object/star.bmp


Single Object/star_Z125%.bmp


Single Object/triangle_down.bmp


Single Object/triangle_up.bmp


Multiple Objects/geometrical_features.bmp


reading content from D:\SD\SearchEngine_ver1\See\lab-05.zip


lab-05/decision_trees.ipynb
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:20.649366400Z",
     "start_time": "2025-03-26T12:20:20.308938400Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#for graphviz install python-graphviz:\n",
    "#conda install python-graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:20.853102400Z",
     "start_time": "2025-03-26T12:20:20.311337400Z"
    }
   },
   "outputs": [],
   "source": [
    "input_file = \"data/restaurant.csv\"\n",
    "# input_file = \"data/restaurant100v3.csv\"\n",
    "\n",
    "# comma delimited is the default\n",
    "data = pd.read_csv(input_file, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.089705200Z",
     "start_time": "2025-03-26T12:20:20.323978700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    Alt  Bar  Fri  Hyn   Pat Price Rain  Res     Type    Est WillWait\n0   Yes   No   No  Yes  Some   $$$   No  Yes   French   0–10      Yes\n1   Yes   No   No  Yes  Full     $   No   No     Thai  30–60       No\n2    No  Yes   No   No  Some     $   No   No   Burger   0–10      Yes\n3   Yes   No  Yes  Yes  Full     $  Yes   No     Thai  10–30      Yes\n4   Yes   No  Yes   No  Full   $$$   No  Yes   French    >60       No\n..  ...  ...  ...  ...   ...   ...  ...  ...      ...    ...      ...\n95   No  Yes  Yes  Yes  Full     $  Yes   No   Burger  30–60      Yes\n96  Yes  Yes  Yes   No  Full    $$   No   No   Burger    >60       No\n97   No  Yes  Yes  Yes  Full     $  Yes  Yes  Italian  10–30       No\n98  Yes   No   No   No   NaN    $$  Yes   No     Thai   0–10       No\n99   No  Yes  Yes  Yes  Full    $$  Yes   No   Burger  30–60      Yes\n\n[100 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Alt</th>\n      <th>Bar</th>\n      <th>Fri</th>\n      <th>Hyn</th>\n      <th>Pat</th>\n      <th>Price</th>\n      <th>Rain</th>\n      <th>Res</th>\n      <th>Type</th>\n      <th>Est</th>\n      <th>WillWait</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Some</td>\n      <td>$$$</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>French</td>\n      <td>0–10</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Full</td>\n      <td>$</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Thai</td>\n      <td>30–60</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Some</td>\n      <td>$</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Burger</td>\n      <td>0–10</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Full</td>\n      <td>$</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Thai</td>\n      <td>10–30</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Full</td>\n      <td>$$$</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>French</td>\n      <td>&gt;60</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Full</td>\n      <td>$</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Burger</td>\n      <td>30–60</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Full</td>\n      <td>$$</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Burger</td>\n      <td>&gt;60</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Full</td>\n      <td>$</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Italian</td>\n      <td>10–30</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>$$</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Thai</td>\n      <td>0–10</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Full</td>\n      <td>$$</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Burger</td>\n      <td>30–60</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.105057900Z",
     "start_time": "2025-03-26T12:20:20.352486800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 11)"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.105057900Z",
     "start_time": "2025-03-26T12:20:20.365469300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Alt', 'Bar', 'Fri', 'Hyn', 'Pat', 'Price', 'Rain', 'Res', 'Type',\n       'Est', 'WillWait'],\n      dtype='object')"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.105057900Z",
     "start_time": "2025-03-26T12:20:20.397138200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Alt  Bar  Fri  Hyn   Pat Price Rain  Res    Type    Est WillWait\n0  Yes   No   No  Yes  Some   $$$   No  Yes  French   0–10      Yes\n1  Yes   No   No  Yes  Full     $   No   No    Thai  30–60       No\n2   No  Yes   No   No  Some     $   No   No  Burger   0–10      Yes\n3  Yes   No  Yes  Yes  Full     $  Yes   No    Thai  10–30      Yes\n4  Yes   No  Yes   No  Full   $$$   No  Yes  French    >60       No",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Alt</th>\n      <th>Bar</th>\n      <th>Fri</th>\n      <th>Hyn</th>\n      <th>Pat</th>\n      <th>Price</th>\n      <th>Rain</th>\n      <th>Res</th>\n      <th>Type</th>\n      <th>Est</th>\n      <th>WillWait</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Some</td>\n      <td>$$$</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>French</td>\n      <td>0–10</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Full</td>\n      <td>$</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Thai</td>\n      <td>30–60</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Some</td>\n      <td>$</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Burger</td>\n      <td>0–10</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Full</td>\n      <td>$</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Thai</td>\n      <td>10–30</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Full</td>\n      <td>$$$</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>French</td>\n      <td>&gt;60</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.105057900Z",
     "start_time": "2025-03-26T12:20:20.400168900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Alt         object\nBar         object\nFri         object\nHyn         object\nPat         object\nPrice       object\nRain        object\nRes         object\nType        object\nEst         object\nWillWait    object\ndtype: object"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.105057900Z",
     "start_time": "2025-03-26T12:20:20.413095900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Alt', 'Bar', 'Fri', 'Hyn', 'Pat', 'Price', 'Rain', 'Res', 'Type',\n       'Est', 'WillWait'], dtype=object)"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.105057900Z",
     "start_time": "2025-03-26T12:20:20.428947700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 3, 0, 3, 1, 2, 0, 3, 0, 2, 3, 0, 1, 3, 0, 3, 1, 2, 0, 3, 0, 2,\n       3, 0, 1, 3, 0, 3, 1, 2, 0, 3, 0, 2, 3, 0, 1, 3, 0, 3, 1, 2, 0, 3,\n       0, 2, 3, 0, 1, 3, 0, 3, 1, 2, 0, 3, 0, 2, 3, 0, 1, 3, 0, 3, 1, 2,\n       0, 3, 0, 2, 3, 0, 1, 3, 0, 3, 1, 2, 0, 3, 0, 2, 3, 0, 1, 3, 0, 3,\n       1, 2, 0, 3, 0, 2, 3, 0, 0, 2, 3, 0])"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(data['Type']) # only for one attribute\n",
    "data_encoded = le.transform(data['Type'])\n",
    "data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.105057900Z",
     "start_time": "2025-03-26T12:20:20.435868300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Burger', 'French', 'Italian', 'Thai'], dtype=object)"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.150275400Z",
     "start_time": "2025-03-26T12:20:20.446589400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    Alt  Bar  Fri  Hyn  Pat  Price  Rain  Res  Type  Est  WillWait\n0     1    0    0    1    1      2     0    1     1    0         1\n1     1    0    0    1    0      0     0    0     3    2         0\n2     0    1    0    0    1      0     0    0     0    0         1\n3     1    0    1    1    0      0     1    0     3    1         1\n4     1    0    1    0    0      2     0    1     1    3         0\n..  ...  ...  ...  ...  ...    ...   ...  ...   ...  ...       ...\n95    0    1    1    1    0      0     1    0     0    2         1\n96    1    1    1    0    0      1     0    0     0    3         0\n97    0    1    1    1    0      0     1    1     2    1         0\n98    1    0    0    0    2      1     1    0     3    0         0\n99    0    1    1    1    0      1     1    0     0    2         1\n\n[100 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Alt</th>\n      <th>Bar</th>\n      <th>Fri</th>\n      <th>Hyn</th>\n      <th>Pat</th>\n      <th>Price</th>\n      <th>Rain</th>\n      <th>Res</th>\n      <th>Type</th>\n      <th>Est</th>\n      <th>WillWait</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded = data.apply(le.fit_transform) # for all the attributes\n",
    "data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.152946400Z",
     "start_time": "2025-03-26T12:20:20.471607500Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf1 = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "x = data_encoded[data.columns.drop('WillWait')]\n",
    "y = data_encoded['WillWait']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.152946400Z",
     "start_time": "2025-03-26T12:20:20.481912500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    Alt  Bar  Fri  Hyn  Pat  Price  Rain  Res  Type  Est\n0     1    0    0    1    1      2     0    1     1    0\n1     1    0    0    1    0      0     0    0     3    2\n2     0    1    0    0    1      0     0    0     0    0\n3     1    0    1    1    0      0     1    0     3    1\n4     1    0    1    0    0      2     0    1     1    3\n..  ...  ...  ...  ...  ...    ...   ...  ...   ...  ...\n95    0    1    1    1    0      0     1    0     0    2\n96    1    1    1    0    0      1     0    0     0    3\n97    0    1    1    1    0      0     1    1     2    1\n98    1    0    0    0    2      1     1    0     3    0\n99    0    1    1    1    0      1     1    0     0    2\n\n[100 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Alt</th>\n      <th>Bar</th>\n      <th>Fri</th>\n      <th>Hyn</th>\n      <th>Pat</th>\n      <th>Price</th>\n      <th>Rain</th>\n      <th>Res</th>\n      <th>Type</th>\n      <th>Est</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.272933300Z",
     "start_time": "2025-03-26T12:20:20.524367100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 12.2.1 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"602pt\" height=\"598pt\"\n viewBox=\"0.00 0.00 601.50 598.25\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 594.25)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-594.25 597.5,-594.25 597.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"363.25,-590.25 254.25,-590.25 254.25,-519.25 363.25,-519.25 363.25,-590.25\"/>\n<text text-anchor=\"middle\" x=\"308.75\" y=\"-572.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Hyn &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"308.75\" y=\"-557.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"308.75\" y=\"-541.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100</text>\n<text text-anchor=\"middle\" x=\"308.75\" y=\"-525.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [51, 49]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"300,-483.25 189.5,-483.25 189.5,-412.25 300,-412.25 300,-483.25\"/>\n<text text-anchor=\"middle\" x=\"244.75\" y=\"-465.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Est &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"244.75\" y=\"-450.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.702</text>\n<text text-anchor=\"middle\" x=\"244.75\" y=\"-434.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 42</text>\n<text text-anchor=\"middle\" x=\"244.75\" y=\"-418.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [34, 8]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M287.44,-518.79C282.47,-510.64 277.12,-501.86 271.94,-493.36\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"274.95,-491.57 266.76,-484.85 268.97,-495.21 274.95,-491.57\"/>\n<text text-anchor=\"middle\" x=\"260.07\" y=\"-502.43\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"429,-483.25 318.5,-483.25 318.5,-412.25 429,-412.25 429,-483.25\"/>\n<text text-anchor=\"middle\" x=\"373.75\" y=\"-465.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Est &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"373.75\" y=\"-450.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.873</text>\n<text text-anchor=\"middle\" x=\"373.75\" y=\"-434.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 58</text>\n<text text-anchor=\"middle\" x=\"373.75\" y=\"-418.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 41]</text>\n</g>\n<!-- 0&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>0&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M330.39,-518.79C335.49,-510.55 340.99,-501.67 346.31,-493.08\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"349.12,-495.19 351.4,-484.85 343.16,-491.51 349.12,-495.19\"/>\n<text text-anchor=\"middle\" x=\"357.93\" y=\"-502.47\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"179,-376.25 68.5,-376.25 68.5,-305.25 179,-305.25 179,-376.25\"/>\n<text text-anchor=\"middle\" x=\"123.75\" y=\"-358.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pat &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"123.75\" y=\"-343.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.904</text>\n<text text-anchor=\"middle\" x=\"123.75\" y=\"-327.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 25</text>\n<text text-anchor=\"middle\" x=\"123.75\" y=\"-311.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 8]</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M204.46,-411.79C194.15,-402.84 182.96,-393.13 172.29,-383.87\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"174.86,-381.46 165.01,-377.55 170.27,-386.75 174.86,-381.46\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"298.5,-368.38 197,-368.38 197,-313.12 298.5,-313.12 298.5,-368.38\"/>\n<text text-anchor=\"middle\" x=\"247.75\" y=\"-351.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"247.75\" y=\"-335.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\n<text text-anchor=\"middle\" x=\"247.75\" y=\"-319.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 0]</text>\n</g>\n<!-- 1&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>1&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M245.75,-411.79C246.04,-401.56 246.36,-390.32 246.66,-379.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"250.15,-380.2 246.94,-370.1 243.16,-380 250.15,-380.2\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"127,-269.25 16.5,-269.25 16.5,-198.25 127,-198.25 127,-269.25\"/>\n<text text-anchor=\"middle\" x=\"71.75\" y=\"-251.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pat &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"71.75\" y=\"-236.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.985</text>\n<text text-anchor=\"middle\" x=\"71.75\" y=\"-220.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14</text>\n<text text-anchor=\"middle\" x=\"71.75\" y=\"-204.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 8]</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106.43,-304.79C102.44,-296.73 98.14,-288.05 93.98,-279.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"97.24,-278.33 89.66,-270.92 90.96,-281.43 97.24,-278.33\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"246.12,-261.38 145.38,-261.38 145.38,-206.12 246.12,-206.12 246.12,-261.38\"/>\n<text text-anchor=\"middle\" x=\"195.75\" y=\"-244.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"195.75\" y=\"-228.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"middle\" x=\"195.75\" y=\"-212.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 0]</text>\n</g>\n<!-- 2&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>2&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M147.72,-304.79C155.19,-293.9 163.44,-281.87 170.96,-270.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"173.72,-273.06 176.49,-262.84 167.95,-269.11 173.72,-273.06\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"95.5,-154.38 0,-154.38 0,-99.12 95.5,-99.12 95.5,-154.38\"/>\n<text text-anchor=\"middle\" x=\"47.75\" y=\"-137.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"47.75\" y=\"-121.33\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"47.75\" y=\"-105.58\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M63.76,-197.79C61.4,-187.45 58.8,-176.08 56.39,-165.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"59.86,-165.03 54.22,-156.07 53.04,-166.59 59.86,-165.03\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"224,-162.25 113.5,-162.25 113.5,-91.25 224,-91.25 224,-162.25\"/>\n<text text-anchor=\"middle\" x=\"168.75\" y=\"-144.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Type &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"168.75\" y=\"-129.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.845</text>\n<text text-anchor=\"middle\" x=\"168.75\" y=\"-113.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"middle\" x=\"168.75\" y=\"-97.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 8]</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M104.05,-197.79C111.98,-189.2 120.57,-179.9 128.82,-170.97\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"131.35,-173.39 135.56,-163.67 126.21,-168.64 131.35,-173.39\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"146.5,-55.25 51,-55.25 51,0 146.5,0 146.5,-55.25\"/>\n<text text-anchor=\"middle\" x=\"98.75\" y=\"-37.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"98.75\" y=\"-22.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"98.75\" y=\"-6.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 8]</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M143.68,-90.96C137.58,-82.5 131.04,-73.43 124.89,-64.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"127.73,-62.85 119.04,-56.78 122.05,-66.94 127.73,-62.85\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"260.5,-55.25 165,-55.25 165,0 260.5,0 260.5,-55.25\"/>\n<text text-anchor=\"middle\" x=\"212.75\" y=\"-37.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"212.75\" y=\"-22.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"212.75\" y=\"-6.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M184.51,-90.96C188.18,-82.86 192.1,-74.2 195.82,-66\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"198.99,-67.49 199.93,-56.93 192.61,-64.6 198.99,-67.49\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"422.5,-368.38 321,-368.38 321,-313.12 422.5,-313.12 422.5,-368.38\"/>\n<text text-anchor=\"middle\" x=\"371.75\" y=\"-351.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"371.75\" y=\"-335.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 24</text>\n<text text-anchor=\"middle\" x=\"371.75\" y=\"-319.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 24]</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M373.08,-411.79C372.89,-401.56 372.68,-390.32 372.48,-379.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"375.98,-380.03 372.29,-370.1 368.98,-380.17 375.98,-380.03\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"549.25,-376.25 440.25,-376.25 440.25,-305.25 549.25,-305.25 549.25,-376.25\"/>\n<text text-anchor=\"middle\" x=\"494.75\" y=\"-358.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Type &lt;= 1.0</text>\n<text text-anchor=\"middle\" x=\"494.75\" y=\"-343.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"494.75\" y=\"-327.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 34</text>\n<text text-anchor=\"middle\" x=\"494.75\" y=\"-311.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 17]</text>\n</g>\n<!-- 10&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>10&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M414.04,-411.79C424.35,-402.84 435.54,-393.13 446.21,-383.87\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"448.23,-386.75 453.49,-377.55 443.64,-381.46 448.23,-386.75\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"455.5,-261.38 360,-261.38 360,-206.12 455.5,-206.12 455.5,-261.38\"/>\n<text text-anchor=\"middle\" x=\"407.75\" y=\"-244.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"407.75\" y=\"-228.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"middle\" x=\"407.75\" y=\"-212.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 9]</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M465.78,-304.79C456.58,-293.68 446.39,-281.38 437.15,-270.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"440.03,-268.22 430.95,-262.76 434.64,-272.69 440.03,-268.22\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"584,-269.25 473.5,-269.25 473.5,-198.25 584,-198.25 584,-269.25\"/>\n<text text-anchor=\"middle\" x=\"528.75\" y=\"-251.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Res &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"528.75\" y=\"-236.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.904</text>\n<text text-anchor=\"middle\" x=\"528.75\" y=\"-220.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 25</text>\n<text text-anchor=\"middle\" x=\"528.75\" y=\"-204.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 8]</text>\n</g>\n<!-- 12&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>12&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M506.07,-304.79C508.59,-296.99 511.31,-288.62 513.95,-280.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"517.26,-281.59 517.01,-271 510.6,-279.44 517.26,-281.59\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"479.62,-162.25 381.88,-162.25 381.88,-91.25 479.62,-91.25 479.62,-162.25\"/>\n<text text-anchor=\"middle\" x=\"430.75\" y=\"-144.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Est &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"430.75\" y=\"-129.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"430.75\" y=\"-113.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"middle\" x=\"430.75\" y=\"-97.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 8]</text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M496.12,-197.79C488.1,-189.2 479.42,-179.9 471.09,-170.97\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"473.65,-168.59 464.27,-163.67 468.54,-173.37 473.65,-168.59\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"593.5,-154.38 498,-154.38 498,-99.12 593.5,-99.12 593.5,-154.38\"/>\n<text text-anchor=\"middle\" x=\"545.75\" y=\"-137.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"545.75\" y=\"-121.33\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"middle\" x=\"545.75\" y=\"-105.58\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 0]</text>\n</g>\n<!-- 14&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>14&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"black\" d=\"M534.41,-197.79C536.07,-187.56 537.89,-176.32 539.57,-165.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"543.02,-166.51 541.16,-156.08 536.11,-165.4 543.02,-166.51\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"382.5,-55.25 287,-55.25 287,0 382.5,0 382.5,-55.25\"/>\n<text text-anchor=\"middle\" x=\"334.75\" y=\"-37.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"334.75\" y=\"-22.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"334.75\" y=\"-6.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 8]</text>\n</g>\n<!-- 15&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>15&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M396.36,-90.96C387.55,-82.04 378.07,-72.45 369.24,-63.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"371.95,-61.28 362.43,-56.63 366.97,-66.2 371.95,-61.28\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"496.5,-55.25 401,-55.25 401,0 496.5,0 496.5,-55.25\"/>\n<text text-anchor=\"middle\" x=\"448.75\" y=\"-37.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"448.75\" y=\"-22.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"448.75\" y=\"-6.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 0]</text>\n</g>\n<!-- 15&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>15&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"black\" d=\"M437.2,-90.96C438.65,-83.13 440.19,-74.79 441.67,-66.83\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"445.1,-67.51 443.48,-57.04 438.22,-66.24 445.1,-67.51\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": "<graphviz.sources.Source at 0x1f1fb0bb820>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(x,y)\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(clf1, out_file = None, feature_names= x.columns)\n",
    "graph1 = graphviz.Source(dot_data)\n",
    "graph1\n",
    "#graph.render(\"restaurant\") # save it to pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.398443200Z",
     "start_time": "2025-03-26T12:20:21.097690600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    Alt_No  Alt_Yes  Bar_No  Bar_Yes  Fri_No  Fri_Yes  Hyn_No  Hyn_Yes  \\\n0    False     True    True    False    True    False   False     True   \n1    False     True    True    False    True    False   False     True   \n2     True    False   False     True    True    False    True    False   \n3    False     True    True    False   False     True   False     True   \n4    False     True    True    False   False     True    True    False   \n..     ...      ...     ...      ...     ...      ...     ...      ...   \n95    True    False   False     True   False     True   False     True   \n96   False     True   False     True   False     True    True    False   \n97    True    False   False     True   False     True   False     True   \n98   False     True    True    False    True    False    True    False   \n99    True    False   False     True   False     True   False     True   \n\n    Pat_Full  Pat_Some  ...  Type_Burger  Type_French  Type_Italian  \\\n0      False      True  ...        False         True         False   \n1       True     False  ...        False        False         False   \n2      False      True  ...         True        False         False   \n3       True     False  ...        False        False         False   \n4       True     False  ...        False         True         False   \n..       ...       ...  ...          ...          ...           ...   \n95      True     False  ...         True        False         False   \n96      True     False  ...         True        False         False   \n97      True     False  ...        False        False          True   \n98     False     False  ...        False        False         False   \n99      True     False  ...         True        False         False   \n\n    Type_Thai  Est_0–10  Est_10–30  Est_30–60  Est_>60  WillWait_No  \\\n0       False      True      False      False    False        False   \n1        True     False      False       True    False         True   \n2       False      True      False      False    False        False   \n3        True     False       True      False    False        False   \n4       False     False      False      False     True         True   \n..        ...       ...        ...        ...      ...          ...   \n95      False     False      False       True    False        False   \n96      False     False      False      False     True         True   \n97      False     False       True      False    False         True   \n98       True      True      False      False    False         True   \n99      False     False      False       True    False        False   \n\n    WillWait_Yes  \n0           True  \n1          False  \n2           True  \n3           True  \n4          False  \n..           ...  \n95          True  \n96         False  \n97         False  \n98         False  \n99          True  \n\n[100 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Alt_No</th>\n      <th>Alt_Yes</th>\n      <th>Bar_No</th>\n      <th>Bar_Yes</th>\n      <th>Fri_No</th>\n      <th>Fri_Yes</th>\n      <th>Hyn_No</th>\n      <th>Hyn_Yes</th>\n      <th>Pat_Full</th>\n      <th>Pat_Some</th>\n      <th>...</th>\n      <th>Type_Burger</th>\n      <th>Type_French</th>\n      <th>Type_Italian</th>\n      <th>Type_Thai</th>\n      <th>Est_0–10</th>\n      <th>Est_10–30</th>\n      <th>Est_30–60</th>\n      <th>Est_&gt;60</th>\n      <th>WillWait_No</th>\n      <th>WillWait_Yes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 27 columns</p>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2 = pd.get_dummies(data, columns=data.columns) #one hot encoding\n",
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.430311600Z",
     "start_time": "2025-03-26T12:20:21.142761900Z"
    }
   },
   "outputs": [],
   "source": [
    "clf2 = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "x2 = data_2[data_2.columns.drop(['WillWait_No', 'WillWait_Yes'])]\n",
    "y2 = data_2['WillWait_Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.571173Z",
     "start_time": "2025-03-26T12:20:21.152946400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Alt_No  Alt_Yes  Bar_No  Bar_Yes  Fri_No  Fri_Yes  Hyn_No  Hyn_Yes  \\\n0   False     True    True    False    True    False   False     True   \n1   False     True    True    False    True    False   False     True   \n2    True    False   False     True    True    False    True    False   \n3   False     True    True    False   False     True   False     True   \n4   False     True    True    False   False     True    True    False   \n\n   Pat_Full  Pat_Some  ...  Res_No  Res_Yes  Type_Burger  Type_French  \\\n0     False      True  ...   False     True        False         True   \n1      True     False  ...    True    False        False        False   \n2     False      True  ...    True    False         True        False   \n3      True     False  ...    True    False        False        False   \n4      True     False  ...   False     True        False         True   \n\n   Type_Italian  Type_Thai  Est_0–10  Est_10–30  Est_30–60  Est_>60  \n0         False      False      True      False      False    False  \n1         False       True     False      False       True    False  \n2         False      False      True      False      False    False  \n3         False       True     False       True      False    False  \n4         False      False     False      False      False     True  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Alt_No</th>\n      <th>Alt_Yes</th>\n      <th>Bar_No</th>\n      <th>Bar_Yes</th>\n      <th>Fri_No</th>\n      <th>Fri_Yes</th>\n      <th>Hyn_No</th>\n      <th>Hyn_Yes</th>\n      <th>Pat_Full</th>\n      <th>Pat_Some</th>\n      <th>...</th>\n      <th>Res_No</th>\n      <th>Res_Yes</th>\n      <th>Type_Burger</th>\n      <th>Type_French</th>\n      <th>Type_Italian</th>\n      <th>Type_Thai</th>\n      <th>Est_0–10</th>\n      <th>Est_10–30</th>\n      <th>Est_30–60</th>\n      <th>Est_&gt;60</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.082465900Z",
     "start_time": "2025-03-26T12:20:21.197712900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 12.2.1 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"673pt\" height=\"598pt\"\n viewBox=\"0.00 0.00 672.50 598.25\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 594.25)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-594.25 668.5,-594.25 668.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"#fefaf7\" stroke=\"black\" points=\"425.25,-590.25 316.25,-590.25 316.25,-519.25 425.25,-519.25 425.25,-590.25\"/>\n<text text-anchor=\"middle\" x=\"370.75\" y=\"-572.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Hyn_No &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"370.75\" y=\"-557.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"370.75\" y=\"-541.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100</text>\n<text text-anchor=\"middle\" x=\"370.75\" y=\"-525.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [51, 49]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#8bc6f0\" stroke=\"black\" points=\"360.62,-483.25 244.88,-483.25 244.88,-412.25 360.62,-412.25 360.62,-483.25\"/>\n<text text-anchor=\"middle\" x=\"302.75\" y=\"-465.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Est_0–10 &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"302.75\" y=\"-450.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.873</text>\n<text text-anchor=\"middle\" x=\"302.75\" y=\"-434.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 58</text>\n<text text-anchor=\"middle\" x=\"302.75\" y=\"-418.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 41]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M348.11,-518.79C342.77,-510.55 337.02,-501.67 331.46,-493.08\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"334.49,-491.32 326.12,-484.83 328.61,-495.13 334.49,-491.32\"/>\n<text text-anchor=\"middle\" x=\"320.07\" y=\"-502.58\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"#eb9f68\" stroke=\"black\" points=\"501,-483.25 378.5,-483.25 378.5,-412.25 501,-412.25 501,-483.25\"/>\n<text text-anchor=\"middle\" x=\"439.75\" y=\"-465.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pat_Some &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"439.75\" y=\"-450.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.702</text>\n<text text-anchor=\"middle\" x=\"439.75\" y=\"-434.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 42</text>\n<text text-anchor=\"middle\" x=\"439.75\" y=\"-418.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [34, 8]</text>\n</g>\n<!-- 0&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>0&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M393.73,-518.79C399.14,-510.55 404.98,-501.67 410.62,-493.08\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"413.48,-495.1 416.04,-484.83 407.63,-491.26 413.48,-495.1\"/>\n<text text-anchor=\"middle\" x=\"421.94\" y=\"-502.62\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#ffffff\" stroke=\"black\" points=\"238.75,-376.25 102.75,-376.25 102.75,-305.25 238.75,-305.25 238.75,-376.25\"/>\n<text text-anchor=\"middle\" x=\"170.75\" y=\"-358.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Type_Burger &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"170.75\" y=\"-343.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"170.75\" y=\"-327.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 34</text>\n<text text-anchor=\"middle\" x=\"170.75\" y=\"-311.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 17]</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M258.8,-411.79C247.44,-402.75 235.1,-392.94 223.35,-383.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"225.7,-380.99 215.7,-377.5 221.34,-386.47 225.7,-380.99\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"358.5,-368.38 257,-368.38 257,-313.12 358.5,-313.12 358.5,-368.38\"/>\n<text text-anchor=\"middle\" x=\"307.75\" y=\"-351.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"307.75\" y=\"-335.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 24</text>\n<text text-anchor=\"middle\" x=\"307.75\" y=\"-319.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 24]</text>\n</g>\n<!-- 1&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>1&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M304.41,-411.79C304.9,-401.56 305.44,-390.32 305.93,-379.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"309.42,-380.26 306.4,-370.1 302.43,-379.92 309.42,-380.26\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"#f1bc96\" stroke=\"black\" points=\"166,-269.25 55.5,-269.25 55.5,-198.25 166,-198.25 166,-269.25\"/>\n<text text-anchor=\"middle\" x=\"110.75\" y=\"-251.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Res_No &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"110.75\" y=\"-236.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.904</text>\n<text text-anchor=\"middle\" x=\"110.75\" y=\"-220.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 25</text>\n<text text-anchor=\"middle\" x=\"110.75\" y=\"-204.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 8]</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M150.77,-304.79C146.12,-296.64 141.1,-287.86 136.24,-279.36\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"139.39,-277.82 131.39,-270.87 133.32,-281.29 139.39,-277.82\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"279.5,-261.38 184,-261.38 184,-206.12 279.5,-206.12 279.5,-261.38\"/>\n<text text-anchor=\"middle\" x=\"231.75\" y=\"-244.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"231.75\" y=\"-228.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"middle\" x=\"231.75\" y=\"-212.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 9]</text>\n</g>\n<!-- 2&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>2&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M191.06,-304.79C197.32,-294.01 204.23,-282.11 210.55,-271.23\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"213.4,-273.3 215.4,-262.9 207.35,-269.79 213.4,-273.3\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"95.5,-154.38 0,-154.38 0,-99.12 95.5,-99.12 95.5,-154.38\"/>\n<text text-anchor=\"middle\" x=\"47.75\" y=\"-137.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"47.75\" y=\"-121.33\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"middle\" x=\"47.75\" y=\"-105.58\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 0]</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M89.77,-197.79C83.3,-187.01 76.17,-175.11 69.64,-164.23\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"72.78,-162.66 64.63,-155.89 66.78,-166.26 72.78,-162.66\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"#ffffff\" stroke=\"black\" points=\"236.38,-162.25 113.12,-162.25 113.12,-91.25 236.38,-91.25 236.38,-162.25\"/>\n<text text-anchor=\"middle\" x=\"174.75\" y=\"-144.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Est_30–60 &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"174.75\" y=\"-129.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"174.75\" y=\"-113.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"middle\" x=\"174.75\" y=\"-97.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 8]</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M132.06,-197.79C137.03,-189.64 142.38,-180.86 147.56,-172.36\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"150.53,-174.21 152.74,-163.85 144.55,-170.57 150.53,-174.21\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"165.5,-55.25 70,-55.25 70,0 165.5,0 165.5,-55.25\"/>\n<text text-anchor=\"middle\" x=\"117.75\" y=\"-37.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"117.75\" y=\"-22.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"117.75\" y=\"-6.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 8]</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154.33,-90.96C149.47,-82.68 144.27,-73.81 139.36,-65.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"142.4,-63.71 134.32,-56.86 136.36,-67.26 142.4,-63.71\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"279.5,-55.25 184,-55.25 184,0 279.5,0 279.5,-55.25\"/>\n<text text-anchor=\"middle\" x=\"231.75\" y=\"-37.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"231.75\" y=\"-22.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"231.75\" y=\"-6.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 0]</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M195.17,-90.96C200.03,-82.68 205.23,-73.81 210.14,-65.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"213.14,-67.26 215.18,-56.86 207.1,-63.71 213.14,-67.26\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"486.5,-368.38 385,-368.38 385,-313.12 486.5,-313.12 486.5,-368.38\"/>\n<text text-anchor=\"middle\" x=\"435.75\" y=\"-351.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"435.75\" y=\"-335.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 31</text>\n<text text-anchor=\"middle\" x=\"435.75\" y=\"-319.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 0]</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M438.42,-411.79C438.03,-401.56 437.6,-390.32 437.2,-379.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"440.71,-379.96 436.83,-370.1 433.71,-380.23 440.71,-379.96\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"#83c2ef\" stroke=\"black\" points=\"615,-376.25 504.5,-376.25 504.5,-305.25 615,-305.25 615,-376.25\"/>\n<text text-anchor=\"middle\" x=\"559.75\" y=\"-358.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Bar_No &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"559.75\" y=\"-343.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.845</text>\n<text text-anchor=\"middle\" x=\"559.75\" y=\"-327.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"middle\" x=\"559.75\" y=\"-311.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 8]</text>\n</g>\n<!-- 10&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>10&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M479.71,-411.79C489.93,-402.84 501.03,-393.13 511.61,-383.87\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"513.61,-386.78 518.83,-377.56 509,-381.51 513.61,-386.78\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"550.5,-261.38 455,-261.38 455,-206.12 550.5,-206.12 550.5,-261.38\"/>\n<text text-anchor=\"middle\" x=\"502.75\" y=\"-244.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"502.75\" y=\"-228.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"502.75\" y=\"-212.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 8]</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M540.77,-304.79C534.98,-294.12 528.59,-282.36 522.74,-271.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"525.89,-270.04 518.04,-262.92 519.74,-273.38 525.89,-270.04\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"664.5,-261.38 569,-261.38 569,-206.12 664.5,-206.12 664.5,-261.38\"/>\n<text text-anchor=\"middle\" x=\"616.75\" y=\"-244.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"616.75\" y=\"-228.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"616.75\" y=\"-212.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 12&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>12&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M578.73,-304.79C584.52,-294.12 590.91,-282.36 596.76,-271.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"599.76,-273.38 601.46,-262.92 593.61,-270.04 599.76,-273.38\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": "<graphviz.sources.Source at 0x1f1fb9405f0>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(x2,y2)\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(clf2, out_file = None, feature_names=x2.columns,  \n",
    "                         filled=True)\n",
    "graph2 = graphviz.Source(dot_data)\n",
    "graph2\n",
    "#graph.render(\"restaurant2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.082465900Z",
     "start_time": "2025-03-26T12:20:21.805604800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gogac\\anaconda3\\envs\\lab04\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([1])"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict \n",
    "my_test=[1,0,0,1,0,2,0,1,1,0]\n",
    "clf1.predict([my_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.082465900Z",
     "start_time": "2025-03-26T12:20:21.809738900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gogac\\anaconda3\\envs\\lab04\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0., 1.]])"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.predict_proba([my_test]) #change the example and see the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.082465900Z",
     "start_time": "2025-03-26T12:20:21.825899100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.122526800Z",
     "start_time": "2025-03-26T12:20:21.848917100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([1.  , 0.94])"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#or use cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(clf1, x,y,cv=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with pandas frame in order to compute InfoGain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.122526800Z",
     "start_time": "2025-03-26T12:20:21.904785800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0     Some\n1     Full\n2     Some\n3     Full\n4     Full\n      ... \n95    Full\n96    Full\n97    Full\n98     NaN\n99    Full\nName: Pat, Length: 100, dtype: object"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Pat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.122526800Z",
     "start_time": "2025-03-26T12:20:21.918347400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Alt  Bar  Fri  Hyn  Price  Rain  Res  Type  Est  WillWait\n",
      "Pat                                                            \n",
      "Full   43   43   43   43     43    43   43    43   43        43\n",
      "Some   25   25   25   25     25    25   25    25   25        25\n"
     ]
    },
    {
     "data": {
      "text/plain": "WillWait\nNo     30\nYes    13\nName: count, dtype: int64"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no, yes = data['WillWait'].value_counts() #how many examples have WillWait='No', respectively Yes\n",
    "print(data.groupby('Pat').count())\n",
    "res = data['WillWait'][data['Pat']=='Full'].value_counts()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.122526800Z",
     "start_time": "2025-03-26T12:20:21.939862800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.0"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "def B(probs):\n",
    "    return sum([-p*log(p,2) for p in probs if p>0])\n",
    "B([1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.122526800Z",
     "start_time": "2025-03-26T12:20:21.952754300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.9997114417528099"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B([no/(no+yes), yes/(no+yes)]) #entropy for WillWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.122526800Z",
     "start_time": "2025-03-26T12:20:21.966622900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Pat\nFull    43\nSome    25\nName: count, dtype: int64"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def remainder(attrib):\n",
    "data['Pat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:22:32.341439900Z",
     "start_time": "2025-03-26T12:22:32.294314900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 51\n",
      "Value of the attribute:  Some\n",
      "WillWait\n",
      "Yes    22\n",
      "No      3\n",
      "Name: count, dtype: int64\n",
      "pozitive and negative number of examples: 22 3\n",
      "Value of the attribute:  Full\n",
      "WillWait\n",
      "No     30\n",
      "Yes    13\n",
      "Name: count, dtype: int64\n",
      "pozitive and negative number of examples: 13 30\n"
     ]
    },
    {
     "data": {
      "text/plain": "np.float64(0.4872017229499642)"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remainder=0\n",
    "attrib='Pat'\n",
    "p=data['WillWait'].value_counts()['Yes']\n",
    "n=data['WillWait'].value_counts()['No']\n",
    "print(p,n)\n",
    "values = np.delete(data[attrib].unique(), 2, 0)\n",
    "for v in values:\n",
    "    print(\"Value of the attribute: \", v)\n",
    "    no_examples = data['WillWait'][data[attrib]==v].value_counts()\n",
    "    print(no_examples)\n",
    "    nk=0\n",
    "    pk=0\n",
    "    if 'No' in no_examples.keys().tolist():\n",
    "        nk=no_examples['No']\n",
    "    if 'Yes' in no_examples.keys().tolist():\n",
    "        pk=no_examples['Yes']\n",
    "    print(\"pozitive and negative number of examples:\", pk,nk)\n",
    "    remainder+=(pk+nk)/(p+n) * B([pk/(pk+nk), nk/(pk+nk)])\n",
    "infoGain = B([n/(n+p), p/(n+p)])-remainder\n",
    "\n",
    "infoGain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn: Apply DecisionTree on the iris dataset.\n",
    "1. Load iris dataset\n",
    "2. see the content of the loaded data\n",
    "3. Identify the classes (target names) & feature names\n",
    "4. View the first 5 examples\n",
    "5. Apply decision tree on the entire dataset\n",
    "6. View the resulting tree\n",
    "7. Predict the result for the flowers with the following characteristics: 4.7 3.3  1.3  0.2 and 5 1.2  3.3  2.2\n",
    "8. Measure accuracy over the entire dataset (use \"accuracy_score\"from sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-26T12:20:21.996218400Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris\n",
    "from sklearn.datasets import load_iris\n",
    "data=load_iris()\n",
    "data #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-26T12:20:21.996218400Z"
    }
   },
   "outputs": [],
   "source": [
    "#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-26T12:20:22.005231400Z"
    }
   },
   "outputs": [],
   "source": [
    "#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-26T12:20:22.005231400Z"
    }
   },
   "outputs": [],
   "source": [
    "#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-26T12:20:22.005231400Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import tree #5\n",
    "clf_your = \"todo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-26T12:20:22.005231400Z"
    }
   },
   "outputs": [],
   "source": [
    "import graphviz  #6\n",
    "dot_data = tree.export_graphviz(clf_your, out_file = None, feature_names=data.feature_names,  \n",
    "                         filled=True)\n",
    "graph2 = graphviz.Source(dot_data)\n",
    "graph2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-26T12:20:22.020882500Z"
    }
   },
   "outputs": [],
   "source": [
    "my_test=[] #7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-26T12:20:22.020882500Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score #8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5.3 XOR Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "# Create the XOR truth table\n",
    "data = {\n",
    "    'X1': [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "    'X2': [0, 0, 1, 1, 0, 0, 1, 1],\n",
    "    'X3': [0, 1, 0, 1, 0, 1, 0, 1],\n",
    "    'Y':  [0, 1, 1, 0, 1, 0, 0, 1]\n",
    "}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5.4 Learning curve"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "# Generate a dataset of 100 random examples\n",
    "random.seed(42)  # for reproducibility\n",
    "num_examples = 100\n",
    "# Define possible values for each column\n",
    "attributes = {\n",
    "    'Alt': ['Yes', 'No'],\n",
    "    'Bar': ['Yes', 'No'],\n",
    "    'Fri': ['Yes', 'No'],\n",
    "    'Hyn': ['Yes', 'No'],\n",
    "    'Pat': ['Some', 'Full', 'None'],\n",
    "    'Price': ['$', '$$', '$$$'],\n",
    "    'Rain': ['Yes', 'No'],\n",
    "    'Res': ['Yes', 'No'],\n",
    "    'Type': ['French', 'Thai', 'Burger', 'Italian'],\n",
    "    'Est': ['0–10', '10–30', '30–60', '>60']\n",
    "}\n",
    "\n",
    "# Generate unique rows\n",
    "rows = []\n",
    "cnt = 0\n",
    "while cnt < num_examples:\n",
    "    row = {col: random.choice(attributes[col]) for col in attributes}\n",
    "    if row not in rows:  # Ensure uniqueness\n",
    "        rows.append(row)\n",
    "        cnt += 1\n",
    "\n",
    "for row in rows:\n",
    "    row['WillWait'] = random.choice(['Yes', 'No'])\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5.5 Overfitting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "attributes = {\n",
    "    'Alt': ['Yes', 'No'],\n",
    "    'Bar': ['Yes', 'No'],\n",
    "    'Fri': ['Yes', 'No'],\n",
    "    'Hyn': ['Yes', 'No'],\n",
    "    'Pat': ['Some', 'Full', 'None'],\n",
    "    'Price': ['$', '$$', '$$$'],\n",
    "    'Rain': ['Yes', 'No'],\n",
    "    'Res': ['Yes', 'No'],\n",
    "    'Type': ['French', 'Thai', 'Burger', 'Italian'],\n",
    "    'Est': ['0–10', '10–30', '30–60', '>60']\n",
    "}\n",
    "num_examples=900\n",
    "# Generate unique rows\n",
    "rows = []\n",
    "cnt = 0\n",
    "while cnt < num_examples:\n",
    "    row = {col: random.choice(attributes[col]) for col in attributes}\n",
    "    if row not in rows:  # Ensure uniqueness\n",
    "        rows.append(row)\n",
    "        cnt += 1\n",
    "\n",
    "for row in rows:\n",
    "    row['WillWait'] = random.choice(['Yes', 'No'])\n",
    "\n",
    "tree_depths = range(1,21)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}




lab-05/restaurant.csv
		Alt		Bar		Fri		Hyn		Pat		Price		Rain		Res		Type		Est		WillWait

		Yes		No		No		Yes		Some		$$$		No		Yes		French		0–10		Yes

		Yes		No		No		Yes		Full		$		No		No		Thai		30–60		No

		No		Yes		No		No		Some		$		No		No		Burger		0–10		Yes

		Yes		No		Yes		Yes		Full		$		Yes		No		Thai		10–30		Yes

		Yes		No		Yes		No		Full		$$$		No		Yes		French		>60		No

		No		Yes		No		Yes		Some		$$		Yes		Yes		Italian		0–10		Yes

		No		Yes		No		No		None		$		Yes		No		Burger		0–10		No

		No		No		No		Yes		Some		$$		Yes		Yes		Thai		0–10		Yes

		No		Yes		Yes		No		Full		$		Yes		No		Burger		>60		No

		Yes		Yes		Yes		Yes		Full		$$$		No		Yes		Italian		10–30		No

		No		No		No		No		None		$		No		No		Thai		0–10		No

		Yes		Yes		Yes		Yes		Full		$		No		No		Burger		30–60		Yes

		Yes		No		No		Yes		Some		$$$		Yes		Yes		French		0–10		Yes

		Yes		No		No		Yes		Full		$		Yes		No		Thai		30–60		No

		No		Yes		No		No		Some		$		Yes		No		Burger		0–10		Yes

		Yes		No		Yes		Yes		Full		$		No		No		Thai		10–30		Yes

		Yes		No		Yes		No		Full		$$$		Yes		Yes		French		>60		No

		No		Yes		No		Yes		Some		$$		No		Yes		Italian		0–10		Yes

		No		Yes		No		No		None		$		No		No		Burger		0–10		No

		No		No		No		Yes		Some		$$		No		Yes		Thai		0–10		Yes

		No		Yes		Yes		No		Full		$		No		No		Burger		>60		No

		Yes		Yes		Yes		Yes		Full		$$$		Yes		Yes		Italian		10–30		No

		No		No		No		No		None		$		Yes		No		Thai		0–10		No

		Yes		Yes		Yes		Yes		Full		$		Yes		No		Burger		30–60		Yes

		No		No		No		Yes		Some		$$$		No		Yes		French		0–10		Yes

		No		No		No		Yes		Full		$		No		No		Thai		30–60		No

		Yes		Yes		No		No		Some		$		No		No		Burger		0–10		Yes

		No		No		Yes		Yes		Full		$		Yes		No		Thai		10–30		Yes

		No		No		Yes		No		Full		$$$		No		Yes		French		>60		No

		Yes		Yes		No		Yes		Some		$$		Yes		Yes		Italian		0–10		Yes

		Yes		Yes		No		No		None		$		Yes		No		Burger		0–10		No

		Yes		No		No		Yes		Some		$$		Yes		Yes		Thai		0–10		Yes

		Yes		Yes		Yes		No		Full		$		Yes		No		Burger		>60		No

		No		Yes		Yes		Yes		Full		$$$		No		Yes		Italian		10–30		No

		Yes		No		No		No		None		$		No		No		Thai		0–10		No

		No		Yes		Yes		Yes		Full		$		No		No		Burger		30–60		Yes

		No		No		No		Yes		Some		$$$		Yes		Yes		French		0–10		Yes

		No		No		No		Yes		Full		$		Yes		No		Thai		30–60		No

		Yes		Yes		No		No		Some		$		Yes		No		Burger		0–10		Yes

		No		No		Yes		Yes		Full		$		No		No		Thai		10–30		Yes

		No		No		Yes		No		Full		$$$		Yes		Yes		French		>60		No

		Yes		Yes		No		Yes		Some		$$		No		Yes		Italian		0–10		Yes

		Yes		Yes		No		No		None		$		No		No		Burger		0–10		No

		Yes		No		No		Yes		Some		$$		No		Yes		Thai		0–10		Yes

		Yes		Yes		Yes		No		Full		$		No		No		Burger		>60		No

		No		Yes		Yes		Yes		Full		$$$		Yes		Yes		Italian		10–30		No

		Yes		No		No		No		None		$		Yes		No		Thai		0–10		No

		No		Yes		Yes		Yes		Full		$		Yes		No		Burger		30–60		Yes

		Yes		No		No		Yes		None		$$$		No		Yes		French		0–10		Yes

		Yes		No		No		Yes		None		$		No		No		Thai		30–60		No

		No		Yes		No		No		Some		$		No		No		Burger		0–10		Yes

		Yes		No		Yes		Yes		None		$		Yes		No		Thai		10–30		Yes

		Yes		No		Yes		No		Full		$$$		No		Yes		French		>60		No

		No		Yes		No		Yes		None		$$		Yes		Yes		Italian		0–10		Yes

		No		Yes		No		No		Full		$		Yes		No		Burger		0–10		No

		No		No		No		Yes		None		$$		Yes		Yes		Thai		0–10		Yes

		No		Yes		Yes		No		None		$		Yes		No		Burger		>60		No

		Yes		Yes		Yes		Yes		Full		$$$		No		Yes		Italian		10–30		No

		No		No		No		No		Some		$		No		No		Thai		0–10		No

		Yes		Yes		Yes		Yes		Full		$		No		No		Burger		30–60		Yes

		Yes		No		No		Yes		None		$$$		Yes		Yes		French		0–10		Yes

		Yes		No		No		Yes		None		$		Yes		No		Thai		30–60		No

		No		Yes		No		No		Some		$		Yes		No		Burger		0–10		Yes

		Yes		No		Yes		Yes		None		$		No		No		Thai		10–30		Yes

		Yes		No		Yes		No		Full		$$$		Yes		Yes		French		>60		No

		No		Yes		No		Yes		None		$$		No		Yes		Italian		0–10		Yes

		No		Yes		No		No		Full		$		No		No		Burger		0–10		No

		No		No		No		Yes		None		$$		No		Yes		Thai		0–10		Yes

		No		Yes		Yes		No		None		$		No		No		Burger		>60		No

		Yes		Yes		Yes		Yes		Full		$$$		Yes		Yes		Italian		10–30		No

		No		No		No		No		Some		$		Yes		No		Thai		0–10		No

		Yes		Yes		Yes		Yes		Full		$		Yes		No		Burger		30–60		Yes

		No		No		No		Yes		None		$$$		No		Yes		French		0–10		Yes

		No		No		No		Yes		None		$		No		No		Thai		30–60		No

		Yes		Yes		No		No		Some		$		No		No		Burger		0–10		Yes

		No		No		Yes		Yes		None		$		Yes		No		Thai		10–30		Yes

		No		No		Yes		No		Full		$$$		No		Yes		French		>60		No

		Yes		Yes		No		Yes		None		$$		Yes		Yes		Italian		0–10		Yes

		Yes		Yes		No		No		Full		$		Yes		No		Burger		0–10		No

		Yes		No		No		Yes		None		$$		Yes		Yes		Thai		0–10		Yes

		Yes		Yes		Yes		No		None		$		Yes		No		Burger		>60		No

		No		Yes		Yes		Yes		Full		$$$		No		Yes		Italian		10–30		No

		Yes		No		No		No		Some		$		No		No		Thai		0–10		No

		No		Yes		Yes		Yes		Full		$		No		No		Burger		30–60		Yes

		No		No		No		Yes		None		$$$		Yes		Yes		French		0–10		Yes

		No		No		No		Yes		None		$		Yes		No		Thai		30–60		No

		Yes		Yes		No		No		Some		$		Yes		No		Burger		0–10		Yes

		No		No		Yes		Yes		None		$		No		No		Thai		10–30		Yes

		No		No		Yes		No		Full		$$$		Yes		Yes		French		>60		No

		Yes		Yes		No		Yes		Some		$$		No		Yes		Italian		0–10		Yes

		Yes		Yes		No		No		None		$		No		No		Burger		0–10		No

		Yes		No		No		Yes		Some		$$		No		Yes		Thai		0–10		Yes

		Yes		Yes		Yes		No		Full		$		No		No		Burger		>60		No

		No		Yes		Yes		Yes		Full		$$$		Yes		Yes		Italian		10–30		No

		Yes		No		No		No		None		$		Yes		No		Thai		0–10		No

		No		Yes		Yes		Yes		Full		$		Yes		No		Burger		30–60		Yes

		Yes		Yes		Yes		No		Full		$$		No		No		Burger		>60		No

		No		Yes		Yes		Yes		Full		$		Yes		Yes		Italian		10–30		No

		Yes		No		No		No		None		$$		Yes		No		Thai		0–10		No

		No		Yes		Yes		Yes		Full		$$		Yes		No		Burger		30–60		Yes





reading content from D:\SD\SearchEngine_ver1\See\labeling_images.zip


crosses.bmp


diagonal.bmp


disks.bmp


letters.bmp


shapes.bmp


text_binary.bmp


reading content from D:\SD\SearchEngine_ver1\See\Laborator 8 FLT (ro).pdf


Laborator 8 

Interpretarea arborilor binari în Haskell/ML 

 

Laboratorul 8 constă în crearea unui analizor lexico-sintactic pentru procesarea arborilor 

binari de căutare în sintaxă Haskell și, comparativ, în sintaxă ML. Partea de ML va apărea pe 

fundal color (albastru), iar pentru implementare vom merge pe una dintre cele două sintaxe. Vom 

avea în vedere citirea arborilor și executarea unor operații pe arbori: insert (inserarea unui nod 

într-un arbore) și count (contorizarea nodurilor, diferite de frunzele vide Lf, dintr-un arbore). 

Exemple de input în Haskell: 

 

Exemple de input în ML: 

 

După cum se poate observa în exemple, sintaxa Haskell a unui arbore binar este 

următoarea:  

Iar sintaxa ML a unui arbore binar este: 

  

Node Lf 2 Lf 
> Node Lf 2 Lf 

Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf) 
> Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf) 

count (insert 16 (Node (Node Lf 2 Lf) 15 Lf)) 
> 3 

insert (count (Node Lf 17 (Node Lf 24 Lf))) (insert 12 (Node Lf 10 Lf)) 
> Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf) 

Node(2, Lf, Lf) 
> Node(2, Lf, Lf) 

Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf)) 
> Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf)) 

count(insert(16, Node(15, Node(2, Lf, Lf), Lf))) 
> 3 

insert(count(Node(17, Lf, Node(24, Lf, Lf))), insert(12, Node(10, Lf, Lf))) 
> Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf)) 

Node (Tree Int) Int (Tree Int) 

Node (int, int Tree, int Tree) 

 



Să luăm ca exemplu arborele binar din imaginea următoare: 

 

Reprezentarea arborelui în sintaxă Haskell este următoarea: 

 

Iar reprezentarea în sintaxă ML este: 

 

Pentru a reprezenta în memorie arborii binari de căutare, vom crea o structură cu trei 

câmpuri: unul pentru cheia nodului (de tip int) și două pentru fiii nodului (pointeri la subarborele 

stâng și la subarborele drept).  

 

Pe stiva de valori vor coexista două tipuri: int, pentru numerele citite din input și pentru 

cheile nodurilor, și o structură de tip arbore, pentru a reduce numerele din input la arbori în 

forma potrivită (reducând partea dreaptă a producțiilor la partea stângă). Astfel, yylval va fi un 

union cu două câmpuri: 

 

În ceea ce privește setul de producții, vom avea un set de reguli (expr) care descriu 
inputul. Putem separa instrucțiunile din input în două categorii, în funcție de tipul rezultatului. 
Citirile arborilor și comanda insert vor returna arbori, în vreme ce comanda count returnează un 

Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf) 

Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf)) 

typedef struct _node { 

int key; 

 struct _node *left, *right;  

} node; 

%union { 

 int ival; 

 struct _node *btree; 

} 



număr întreg. Astfel, reies alte două seturi de reguli, unul pentru situațiile din care rezultă un 
arbore (t_expr) și unul pentru cele din care rezultă numere întregi (i_expr). Cel mai important set 
de reguli este cel care descrie construirea unui arbore binar (tree), cu ajutorul celor doi 
constructori de date Haskell/ML pentru arbori binari: constructorul Node cu trei argumente și 
constructorul Lf cu zero argumente. 

 Setul de producții pentru sintaxă Haskell:

 

Setul de producții pentru sintaxă ML: 

 

  

expr : i_expr 

     | t_expr 

     ; 

i_expr : COUNT t_expr 

  |'(' i_expr ')' 

  | NUMBER 

  ; 

t_expr : INSERT i_expr t_expr 

       | '(' t_expr ')' 

       | tree 

       ; 

tree : NODE tree NUMBER tree 

     | '(' tree ')'    

     | LF    

     ; 

expr : i_expr 

     | t_expr 

     ; 

i_expr : COUNT '(' t_expr ')' 

  | NUMBER 

  ; 

t_expr : INSERT '(' i_expr ',' t_expr ')' 

       | tree 

       ; 

tree : NODE '(' NUMBER ',' tree ',' tree ')' 

     | LF    

     ; 



Exerciții propuse: 

1. Implementați o funcție pentru căutarea unui nod într-un arbore.  

Exemple în Haskell: 

find 12 (Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf)) 
> true 
find 17 (Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf)) 
> false 

Exemple în ML: 

 

2. Implementați o funcție pentru ștergerea unui nod dintr-un arbore. Verificați întâi dacă 

nodul căutat există în arbore.  

Exemplu în Haskell: 

delete 12 (Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf)) 
> Node (Node Lf 2 Lf) 10 Lf 

Exemplu în ML: 

 
 

3. Creați o funcție pentru a verifica dacă un arbore binar este echilibrat.  

Exemple în Haskell: 

balanced (Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf)) 
> true 
balanced (Node (Node Lf 2 Lf) 10 Lf) 
> false 

Exemple în ML: 

 

find(12, Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf))) 
> true 
find(17, Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf))) 
> false 

 

delete(12, Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf))) 
> Node(10, Node(2, Lf, Lf), Lf) 

balanced(Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf))) 
> true 
balanced(Node(10, Node(2, Lf, Lf), Lf)) 
> false 



reading content from D:\SD\SearchEngine_ver1\See\Letter of Intent.pdf


Letter of Intent 

For Participation in the MHP Internship 

I, Braica Patricia Maria, am a third-year student at the Faculty of Automation and Computers, within the 

Technical University of Cluj-Napoca, specializing in Computer Science and Information Technology in 

English. I wish to apply for the MHP internship in Cluj-Napoca. 

I would like to bring to your attention the reasons why I believe I am a strong candidate for this project. 

Firstly, I aim to bring innovation and contribute to improving the results of MHP. I feel well-prepared to 

engage in the complex field of Java programming. My qualifications are supported by the excellent 

results I have achieved in relevant subjects throughout my three years of study. 

Secondly, I want to develop my practical skills in the technical field, particularly in software solutions 

implementation. I believe this project will provide me with the opportunity to learn from professionals 

and apply theoretical knowledge in practice. I am highly motivated by the chance to work in an 

interdisciplinary team and contribute to the development of a real-world project. 

It is essential to mention that I have already worked with this type of technology in Web Development 

during the “Software Engineering” course, where I developed a project on restaurant recommendation 

systems using Google Location and Weather APIs, implemented with Java Spring Boot. 

Additionally, I have completed the "Object-Oriented Programming (OOP) in Java and C++" course, where 

I worked on a mandatory project that strengthened my knowledge of OOP-based application 

development. 

The "SQL Programming" course provided me with fundamental skills in database management, which 

are crucial for any project involving data storage and manipulation. 

Throughout my studies, I have taken relevant courses that have equipped me with essential skills in 

computer science and applied technologies. For example, through the "Fundamental Algorithms and 

Data Structures in C" course, I learned efficient programming techniques for developing high-

performance solutions. 

During the "AI Technologies in Python" course, my teammates and I implemented complex AI solutions 

such as theorem proving and the DPLL algorithm. 

My objectives are to expand my experience in advanced technologies, particularly in web development, 

while remaining open to exploring other IT specializations. Through this project, I wish to gain insight 

into different fields where I can contribute and discover what best suits my skills and interests. My goal 

is to acquire valuable knowledge and experiment with various types of projects to eventually become an 

expert in a specific domain or position, based on the skills and passions I develop along the way. 

If you consider that my motivation and expertise make me a suitable candidate for this project, I am 

available for an interview with the selection committee. Thank you for your time and consideration. 

Sincerely, 

Braica Patricia Maria 



reading content from D:\SD\SearchEngine_ver1\See\Letter of IntentEng.docx

Letter of Intent
For Participation in the MHP Internship
I, Braica Patricia Maria, am a third-year student at the Faculty of Automation and Computers, within the Technical University of Cluj-Napoca, specializing in Computer Science and Information Technology in English. I wish to apply for the MHP internship in Cluj-Napoca.
I would like to bring to your attention the reasons why I believe I am a strong candidate for this project.
Firstly, I aim to bring innovation and contribute to improving the results of MHP. I feel well-prepared to engage in the complex field of Java programming. My qualifications are supported by the excellent results I have achieved in relevant subjects throughout my three years of study.
Secondly, I want to develop my practical skills in the technical field, particularly in software solutions implementation. I believe this project will provide me with the opportunity to learn from professionals and apply theoretical knowledge in practice. I am highly motivated by the chance to work in an interdisciplinary team and contribute to the development of a real-world project.
It is essential to mention that I have already worked with this type of technology in Web Development during the “Software Engineering” course, where I developed a project on restaurant recommendation systems using Google Location and Weather APIs, implemented with Java Spring Boot.
Additionally, I have completed the "Object-Oriented Programming (OOP) in Java and C++" course, where I worked on a mandatory project that strengthened my knowledge of OOP-based application development.
The "SQL Programming" course provided me with fundamental skills in database management, which are crucial for any project involving data storage and manipulation.
Throughout my studies, I have taken relevant courses that have equipped me with essential skills in computer science and applied technologies. For example, through the "Fundamental Algorithms and Data Structures in C" course, I learned efficient programming techniques for developing high-performance solutions.
During the "AI Technologies in Python" course, my teammates and I implemented complex AI solutions such as theorem proving and the DPLL algorithm.
My objectives are to expand my experience in advanced technologies, particularly in web development, while remaining open to exploring other IT specializations. Through this project, I wish to gain insight into different fields where I can contribute and discover what best suits my skills and interests. My goal is to acquire valuable knowledge and experiment with various types of projects to eventually become an expert in a specific domain or position, based on the skills and passions I develop along the way.
If you consider that my motivation and expertise make me a suitable candidate for this project, I am available for an interview with the selection committee. Thank you for your time and consideration.
Sincerely,
Braica Patricia Maria

reading content from D:\SD\SearchEngine_ver1\See\lisp.l

/* lisp.l - Analizor lexical pentru microinterpretorul Lisp */
%{
#include "y.tab.h"
%}

%%
\s+                 ; /* Ignoră spațiile albe */
\(                  return '(';
\)                  return ')';
CONS                return CONS;
CAR                 return CAR;
CDR                 return CDR;
APPEND              return APPEND;
[0-9]+              { yylval.ival = atoi(yytext); return NUMBER; }
\'\([0-9 ]+\)      { yylval.sval = strdup(yytext); return LIST; }
.                   ;
%%

int yywrap() { return 1; }



reading content from D:\SD\SearchEngine_ver1\See\lisp.y

/* lisp.y - Analizor sintactic pentru microinterpretorul Lisp */
%{
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

typedef struct list {
    int value;
    struct list *next;
} list;

list *cons(int val, list *lst) {
    list *node = (list *)malloc(sizeof(list));
    node->value = val;
    node->next = lst;
    return node;
}

int car(list *lst) { return lst ? lst->value : 0; }
list *cdr(list *lst) { return lst ? lst->next : NULL; }
list *append(list *l1, list *l2) {
    if (!l1) return l2;
    list *head = l1;
    while (l1->next) l1 = l1->next;
    l1->next = l2;
    return head;
}

void print_list(list *lst) {
    printf("(");
    while (lst) {
        printf("%d ", lst->value);
        lst = lst->next;
    }
    printf(")\n");
}
%}

%union {
    int ival;
    list *lst;
}

%token <ival> NUMBER
%token CONS CAR CDR APPEND
%type <lst> form i_form l_form enum

%%
form: i_form  { $$ = $1; print_list($$); }
    | l_form  { $$ = $1; print_list($$); }
    ;

i_form: '(' i_command ')' { $$ = $2; }
      | NUMBER { $$ = cons($1, NULL); }
      ;

l_form: '(' l_command ')' { $$ = $2; }
      | enum ')' { $$ = $1; }
      ;

i_command: CAR l_form { $$ = cons(car($2), NULL); }
         | '+' form i_form { $$ = cons(car($2) + car($3), NULL); }
         ;

l_command: CDR l_form { $$ = cdr($2); }
         | CONS i_form l_form { $$ = cons(car($2), $3); }
         | APPEND l_form l_form { $$ = append($2, $3); }
         ;

enum: NUMBER enum { $$ = cons($1, $2); }
     | NUMBER { $$ = cons($1, NULL); }
     ;

file: file form '\n' | file '\n' | /* empty */ ;
%%

int main() {
    yyparse();
    return 0;
}

void yyerror(const char *msg) {
    fprintf(stderr, "Error: %s\n", msg);
}


reading content from D:\SD\SearchEngine_ver1\See\0_geografie_planificari_calendaristice_liceu_tehnologic_9.docx

PLANIFICARE CALENDARISTICĂ ANUALĂ 
PENTRU ANUL ȘCOLAR  - 2025, LA DISCIPLINA GEOGRAFIE 
 ÎNVĂȚĂMÂNT LICEAL, FILIERA TEHNOLOGICĂ
CLASA a IX-a

În baza prevederilor OME nr. 3.694/01.02  privind structura anului școlar  2024- 2025 și ale OME nr. 3965/2024 privind măsuri de aplicare şi corelare a planurilor de învăţământ pentru învăţământul profesional, liceal - filiera tehnologică şi postliceal cu structura anului şcolar 2024 - 2025, în organizarea procesului de învățământ se vor avea în vedere următoarele reglementări:
• Pentru clasele a IX-a – a XI-a zi și a IX-a – a XII-a seral din învățământul liceal și profesional, filiera tehnologică, anul școlar are o durată de 37 de săptămâni de cursuri și se încheie la data de 23 iunie 2025.
• Pentru clasele a XII-a zi și a XIII-a seral din învățământul liceal și profesional, filiera tehnologică, anul școlar are o durată de 34 de săptămâni de cursuri și se încheie la data de 2 iunie 2025. 
• Pentru clasele din învățământul liceal și profesional, filiera tehnologică, ale căror planuri-cadru de învățământ în vigoare prevăd un număr mai mare de 37 de săptămâni, în organizarea procesului de învățământ se va avea în vedere menținerea structurii, a numărului total de ore/săptămână și a numărului de săptămâni alocate stagiilor de pregătire practică prevăzute în planurile-cadru de învățământ în vigoare, dar cu reducerea numărului de săptămâni de cursuri pentru disciplinele și modulele din ariile curriculare, astfel:
1. Învățământ de zi:
 Pentru clasa a IX-a liceu: 
· 34 de săptămâni de pregătire teoretică și pregătire practică; 
· 3 săptămâni de stagii de pregătire practică; 
 Pentru clasa a IX-a învățământ profesional: 
· 32 de săptămâni de pregătire teoretică și pregătire practică săptămânală; 
· 5 săptămâni de stagii de pregătire practică;
 Pentru clasa a X-a liceu: 
· 34 de săptămâni de pregătire teoretică și pregătire practică; 
· 3 săptămâni de stagii de pregătire practică; 
 Pentru clasa a XI-a liceu, profil Tehnic și Resurse naturale și protecția mediului: 
· 32 de săptămâni de pregătire teoretică și pregătire practică; 
· 5 săptămâni de stagii de pregătire practică; 
 Pentru clasa a XI-a liceu, profil Servicii: 
· 33 de săptămâni de pregătire teoretică și pregătire practică;
· 4 săptămâni de stagii de pregătire practică; 
 Pentru clasa a XII-a liceu: 
· 29 de săptămâni de pregătire teoretică și pregătire practică; 
· 5 săptămâni de stagii de pregătire practică. 

2. Învățământ seral:
 Pentru clasele din învățământul liceal, cu excepția claselor a XIII-a, se respectă numărul de săptămâni de cursuri stabilit prin planurile-cadru de învățământ în vigoare.
 Pentru clasa a XIII-a învățământ seral: 
· 29 de săptămâni de pregătire teoretică și pregătire practică; 
· 5 săptămâni de stagii de pregătire practică.




CLASA A IX-A
(pentru toate profilurile și specializările)

• Număr de ore alocate: - 1 oră pe săptămână (TC), respectiv 34 de ore pe an 
• Structura avută în vedere la realizarea planificării calendaristice:
Modul 1: 09.09.2024 - 25.10.2024
Modul 2: 04.11.2024 - 20.12.2024
Modul 3: 08.01.2025 - 21.02.2025*
Modul 4: 03.03.2025 – 17.04.2025  
Modul 5: 28.04.2025 - 27.06.2025 
– cu două săptămâni de instruire practică în perioada celor 2 programe ”Școala Altfel” și ” Săptămâna Verde”**
– cu o săptămână de instruire practică** 

  *  Se va modifica în funcție de decizia ISJ/ISMB
**  Se va modifica/ajusta în funcție de intervalele (săptămânile) de desfășurare a stagiilor de instruire practică stabilite la nivelul fiecărei unități de învățământ.

PLANIFICARE CALENDARISTICĂ ANUALĂ 
GEOGRAFIE FIZICĂ (,,PĂMÂNTUL PLANETA OAMENILOR”)
	Unitatea de învățare
	Competențe specifice
	Conținuturi
	Nr. de ore alocate
	Săptămâna
	Observații/
Evaluare

	MODUL DE ÎNVĂȚARE 1

	1. Pământul - o entitate a Universului
	1.1.
1.2.
1.3.
2.1.
3.2.
	· Elemente de geografie generală. (evaluare inițială)
· Universul şi Sistemul solar
· Evoluţia Universului şi a Terrei
· Caracteristicile Pământului şi consecinţele geografice 
	4
	1 – 4
	Observarea sistematică
Autoevaluare/
Interevaluare
Evaluare orală

	2. Măsurarea 
şi reprezentarea spaţiului terestru

	1.1.
2.2.
4.1.
4.2.
4.3.
4.4.
4.5.
	· Coordonatele geografice
· Reprezentări cartografice
· Măsurarea şi calculul distanţelor şi al suprafeţelor pe hărţi geografice şi în orizontul local
· Reprezentările cartografice şi societatea omenească
· *GIS, teledetecție, imagini satelitare
Recapitulare și evaluare
	3
	5 – 7
	
Observarea sistematică

Autoevaluare/
Interevaluare

Evaluare scrisă (T1)

	Vacanță (28.10.2024 – 31.10.2024)

	MODUL DE ÎNVĂȚARE 2

	3. Relieful terestru

	1.1.
1.2.
3.2.
4.2.
4.5.
5.3.
5.4.

	· Scoarţa terestră ca suport al reliefului: structură şi alcătuire petrografică
· Unităţile majore ale reliefului terestru
· Agenţi, procese şi forme de relief
· Tipuri şi unităţi de relief
· Analiza şi interpretarea  reliefului
· Relieful şi societatea omenească
· Relieful orizontului local
· Aplicaţii practice în orizontul local
· *Modificări naturale actuale ale reliefului. Modificări accentuate antropic
Recapitulare și evaluare
	






7
	






8 – 14
	
Observarea sistematică


Autoevaluare/
Interevaluare







Evaluare scrisă (T2)

	Vacanță (21.12.2024 – 7.01.2025)

	MODUL DE ÎNVĂȚARE 3

	4. Atmosfera terestră 
	1.1.
1.2.
3.2.
4.1.
4.5.
4.6.
5.4.

	· Alcătuirea şi structura atmosferei
·  Factorii genetici ai climei
·  Climatele Terrei 
· Evoluţia şi tendinţele de evoluţie a climei
· Hărţile climatice şi harta sinoptică. Analiza şi interpretarea datelor
· Clima şi societatea omenească
· Clima orizontului local
*Modificări climatice actuale și impactul acestora asupra societății umane
Recapitulare și evaluare
	7
	15 – 21
	


Observarea sistematică

Autoevaluare/
Interevaluare




Evaluare scrisă (T3)

	Vacanță de ski(22.02.2025 – 02.03.2025)

	MODUL DE ÎNVĂȚARE 4*

	5. Apele Terrei
	1.1.
1.2.
3.2.
4.1.
4.5.
4.6.
5.4.
5.5.
	· Componentele hidrosferei
· Apele oceanice (oceanosfera) și apele continentale
· Analiza şi interpretarea unor date hidrologice
· Hidrosfera şi societatea omenească
· Hidrografia orizontului local
· Aplicaţii practice în orizontul local
*Modificări ale componentelor hidrosferei (naturale și antropice)
Recapitulare și evaluare
	7
	22 – 28
(orientativ)
	

Observarea sistematică

Autoevaluare/
Interevaluare


Evaluare scrisă (T4)

	Vacanță (18.04.2025 – 27.04.2025)

	MODUL DE ÎNVĂȚARE 5*

	6. Viaţa şi solurile pe Terra
	1.1.
1.2.
3.2.
4.5.
4.6.
5.4.
5.5.
	· Biosfera şi organizarea ei.
   Evoluţia vieţii pe Terra
· Pedosfera
· Zonele biopedoclimatice
· Biosfera, solurile şi activitatea omenească
· Aplicaţii în orizontul local
*Transformări recente în învelișul biotic cu implicații asupra societății umane
Recapitulare și evaluare
	2
	29 – 30
(orientativ)
	


Observarea sistematică

Autoevaluare/
Interevaluare


Evaluare scrisă (T5)

	7. Mediul, peisajul şi societatea omenească 
	1.1. 
1.4.
2.3.
2.4. 
2.5. 
5.5.


	· Interacţiunile dintre elementele
   naturale ale mediului
· Interacţiunile dintre om şi
   mediul terestru
· Peisajele naturale
· Factorii geoecologici naturali
· Tipurile de mediu natural
· Rolul mediului geografic în evoluţia şi dezvoltarea  societăţii omeneşti 
· Mediul orizontului local
Recapitulare și evaluare
	2
	31 – 32 
(orientativ)
	


Observarea sistematică

Autoevaluare/
Interevaluare




Evaluare orală

	8. *Modificări 
globale ale mediului 
natural
	1.1.
1.2.
1.3.
1.4.
2.4.
2.5.
4.1.
4.6.
5.4.
5.5.
	· *Mediul natural ca sistem global. Interacțiuni, sisteme, structuri
· *Modificări naturale
· *Modificări influențate antropic
· *Intercondiționarea transformărilor mediului natural
Recapitulare și evaluare finală
	


4






	


33 – 37
(orientativ)





	Observarea sistematică

Autoevaluare/
Interevaluare

Evaluare finală

	*include o  săptămână de instruire practică 
(la decizia unității de învățământ, între S29 și S37)



 Planificarea calendaristică este întocmită în conformitate cu programa școlară pentru disciplina Geografie, clasa a IX-a, aprobată prin OMECT nr. 3458/09.03.2004, structura anului școlar 2024-2025 aprobată prin OME nr. 3.694/01.02 2024, măsurile de aplicare și corelare a planurilor de învățământ pentru învățământul profesional, liceal - filiera tehnologică și postliceal cu structura anului școlar 2024-2025 aprobate prin OME nr. 3965/2024 şi metodologia de proiectare şi de organizare a instruirii promovată de ghidurile metodologice de curriculum şi didactică.
 Numărul de ore din prezenta planificare are o valoare orientativă și, de asemenea, intervalul de săptămâni din structura anului școlar. 
 La Art. 4 alin. (2) din OME nr. 3505/31.03.2024 privind structura anului şcolar 2024-2025 se precizează că, pentru clasele din învățământul liceal - filiera tehnologică, în perioadele dedicate programelor „Școala altfel” și „Săptămâna verde” (din intervalul 09 septyembrie – 20 iunie 2025) se organizează activități de instruire practică. 
 Planificarea calendaristică se va modifica/ajusta în funcție de intervalele de desfășurare a celor trei săptămâni de stagii de pregătire practică, stabilite la nivelul fiecărei unități de învățământ.
 Conținuturile evidențiate printr-un asterisc (*) și prin caractere italice reflectă realitatea/ problematica lumii contemporane asumate prin studiul Geografiei și nu sunt obligatorii. Cadrele didactice pot opta sau nu pentru realizarea acestor conținuturi, în funcţie de resursele de timp şi de particularităţile colectivelor de elevi.
image1.png


reading content from D:\SD\SearchEngine_ver1\See\Adeverință.docx


image6.png

image7.png

image8.png

image9.png

image10.png

image11.png

image12.png

image13.png

image1.jpeg

image2.png

image3.png

image4.png

image5.png


reading content from D:\SD\SearchEngine_ver1\See\CHANGELOG.md

# Lab 03
> 2025-03-10

> **Main goal**: Component-based thinking
---

## Hour 1:
- Intro to DBMS history
- ORM vs SQL
    - Explain mappings, like 1d light switches to 2d floor map
    - Link to Dependency Inversion
- "Tech stack" is a bad phrase. Learn about layer above and below you.
    - So if the abstraction fails, you can fix your way around it
    - https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/
    - Don't be a React developer. Be a web developer.
        - LAMP (Linux, Apache, MySQL, PHP)
        - MEAN (MongoDB, Express, Angular, Node)
        - etc.
    - Learn about web standards. Learn about the browser platform.


## Hour 2:
- Show Quirks.cpp
    - Link: https://github.com/WebKit/WebKit/blob/main/Source/WebCore/page/Quirks.cpp#L1130
- Chaos Monkey
    - Link to Antifragile
    - Exercise: how much is 5-nines? 4-nines? 3-nines?
- Snippet indent exercise. Explain the real power of Haskell types (runnable UML!)
    - "functional core, imperative shell" architecture


## Hour 3:
- Write Fizz Buzz in 3 ways (simple, 1 buffer, buffered writer)
- Explain the N+1 problem


#### Sources:
- https://www.martinfowler.com/bliki/BlueGreenDeployment.html
- https://googleblog.blogspot.com/2008/08/search-experiments-large-and-small.html
- https://www.slideshare.net/slideshow/culture-1798664/1798664#23
- https://youtu.be/jeRWyYIgiU8?t=176
- https://0.30000000000000004.com
- https://martinfowler.com/bliki/OrmHate.html
- https://matklad.github.io/2021/02/06/ARCHITECTURE.md.html

- Books mentioned:
    - https://en.wikipedia.org/wiki/Antifragile_(book)
    - https://en.wikipedia.org/wiki/Hacker%27s_Delight
    - https://www.amazon.com/Understanding-Software-Addison-Wesley-Professional-Computing/dp/0137589735


# Lab 02
> 2025-03-03

> **Main goal**: Understand GRASP
---


## Hour 1:
- Go through what 'Clean Code' promotes:
    - Link: https://gist.github.com/wojteklu/73c6914cc446146b8b533c0988cf8d29
    - Show counterexamples
- Write a `pluralize` function
    - Rust version
    - TypeScript version
- Show `gap` command
- Refactor method from the lab guide


## Hour 2:
- GRASP exercise


## Hour 3:
- GRASP exercise


#### Sources:
- https://sandimetz.com/blog/2016/1/20/the-wrong-abstraction
- https://qntm.org/clean
- https://www.codecentric.de/en/knowledge-hub/blog/curly-braces
- https://github.com/tigerbeetle/tigerbeetle/blob/fe681fc34729e7afb3ae4ead33d1093ceb68d164/src/constants.zig#L14
- Style:
    - https://cbea.ms/git-commit/
    - https://go.dev/doc/contribute#commit_messages
    - https://gist.github.com/joshbuchea/6f47e86d2510bce28f8e7f42ae84c716
    - http://number-none.com/blow/john_carmack_on_inlined_code.html
    - https://google.github.io/styleguide/cppguide.html#Exceptions
    - https://github.com/torvalds/linux/blob/master/Documentation/process/coding-style.rst
    - https://testing.googleblog.com/2023/10/improve-readability-with-positive.html
- Big functions:
    - https://github.com/torvalds/linux/blob/master/kernel/fork.c#L2147-L2705
    - https://github.com/gcc-mirror/gcc/blob/master/gcc/c/c-parser.cc#L2306-L3175
- Big comments:
    - https://github.com/golang/go/blob/master/src/math/big/natdiv.go


# Lab 01
> 2025-02-24

> **Main goal**: Understand SOLID
---


## Hour 1: Warm up, important concepts from software engineering
- "Software engineering is programming integrated over time"
- Explained the origins of OOP
    - Simula vs Smalltalk
    - Alan Kay's version
    - Steve Jobs selling objects for the NeXT operating system
- These principles of software design aren't generally applicable
- Style:
    - coding styles
    - why 80 columns
    - case formats
    - why code formatters exist (explain what gofmt does)
    - commit styles
    - version control systems
- Explained why Rust/Golang don't have classes (prefer composition over inheritance)
- Don't try to be Netflix or Google (design for the problem)


## Hour 2:
- Self-check test
- Explained a few items from the test


## Hour 3:
- SOLID live demos
    - S = Single Responsibility Principle
    - O = Open/Closed Principle (OCP)
    - L = Liskov Substitution Principle (LSP)
    - I = Integration Segregation Principle (ISP)
    - D = Dependency Inversion Principle (DIP)


#### Sources:
- https://abseil.io/resources/swe-book/html/ch01.html
- https://overreacted.io/goodbye-clean-code/
- https://www.youtube.com/watch?v=tD5NrevFtbU
- https://www.youtube.com/watch?v=oKg1hTOQXoY (10:00)
- https://www.youtube.com/watch?v=Gk-9Fd2mEnI
- https://simonwillison.net/2024/Jun/17/russ-cox/

- Books mentioned:
    - https://en.wikipedia.org/wiki/Understanding_Media
    - https://en.wikipedia.org/wiki/The_medium_is_the_message


reading content from D:\SD\SearchEngine_ver1\See\CN3a_2022.pdf


LABORATORY WORK NO. 3a 
OPTICAL FIBERS AND COMPONENTS 

 

 

1. Objectives 

 
The objective of this work is gaining knowledge on optical fibers and components, link 

performance analysis and the optical power budget calculus. 

 

2. Theoretical considerations  

 
2.1 Optical fibers and components 

The current laboratory work continues the focus on the Physical layer of the ISO/OSI stack 

by providing knowledge on optical fibers and components. Furthermore, on part 3b, the main 

network devices and elements of structured cabling are presented. 

Once the drop in the price of optical fibers, and appropriate communications equipment, this 

has become the environment of choice for new high-speed connections (exterior and interior).  

To transmit data, optical fibers send light signals along glass or plastic cores (of the order 

tens of microns (μ), which constitutes a wavelength guide for light, obtained from a 

combination of silicon dioxide and other elements).  

An optical fiber strand is the basic element of an optical fiber cable (a cable contains several 

strands). A strand has three layers: core, cladding and coating. A fiber optic cable consists of 

several components: fiber strand(s), buffer, protective materials, outer jacket. 

The core is wrapped by material made of silicon dioxide having a refractive index lower than 

the core called cladding. In order to protect the cladding, this is wrapped in a plastic material. 

This is called buffer and is wrapped in a material, usually Kevlar, which confers resistance of 

fiber at the time of installation. Optical fiber buffers are of two categories: tight (a protective 

covering is applied over the coating of each fiber strand) or  loose-tube (several strands inside 

a tube filled with a protective gel). For outdoor, long-distance installation, loose-tube fiber is 

preferred. The last wrapper is the jacket which protects the fiber against abrasive materials, 

solvents and other factors. The color enclosure in the case of multimode optical fiber is 

usually orange and in the case of single-mode optical fiber is usually yellow. Each fiber 

optics cable is composed of two fibers wrapped separately, a fiber being used for 

transmission and another for the reception, ensuring in this way a full-duplex connection. A 

cable of optical fiber may contain from two up to hundred separate fiber strands (usually in 

LANs, up to 24). Figure 2.1 presents the layer of an optical fiber and an optical fiber 

transversal section. 



COMPUTER NETWORKS 

 2 

  
Figure 2.1 a. Optical fiber layers               b. Optical fiber transversal section 

 

For the signal to be reflected without loss, the following two conditions need to be met: 

• Optical-fiber must have a refractive index higher than the material surrounding it; 

• The angle of incidence of light signal must be greater than the critical angle of fiber 

and of the material surrounding it. The angle of incidence of light signal can be 

controlled by using the next two factors: 

o Numerical aperture of the fiber is the range of angles of the light signal for 

which the reflection is complete; 

o The modes are the ways that the signal light can follow. 

Unlike copper-based transmission media, optical fiber is not susceptible to, and it does not 

generate electromagnetic or crosstalk interference. 

Two main optical fibers are commonly used in LANs and WANs: single-mode and 

multimode. Single-mode optical fiber is used for long distance links and for vertical cabling 

in buildings (building’s backbone). Multimode optical fiber is commonly used in horizontal 

and vertical cabling. Multimode fiber has a larger core diameter compared to single-mode. 

Thus, multimode does not require the same precision as single-mode, resulting in less 

expensive connectors, transmitters etc. 

For the single-mode fiber the core diameter is small enough as to permit only one mode (one 

way) light signal, being sent in a straight line through the middle of the core. Single-mode 

optical fiber cables use cores with diameter between 8μ and 10μ. The most used single-mode 

optical fibers have 9μ diameter and cladding with a diameter of 125μ. They are usually 

referred as 9/125μ optical fibers. Light source used is the infrared laser. It is recommended 

caution when using lasers as source of light since it may affect the eyes. Single-mode fibers 

may transmit data at distances over 100km. The loss on km of single-mode optical fiber is 

specified by the manufacturer. In the case of single-mode fiber, the refractive index of glass 

stays constant. This type of glass is called step index glass.  

 

The core of multimode fiber has a sufficiently large diameter as to permit several modes 

(several ways) for light signal. Standard multimode optical fiber cables have a core diameter 

of 62, 5μ or 50μ and cladding with a diameter of 125μ. They are usually referred as optical 

fibers of 62.5/125μ or 50/125μ. Usually, the light sources used with multimode fibers are 

Infrared Light Emitting Diode (LED) or Vertical Cavity Surface Emitting Lasers (VCSEL). 

LED-s are cheaper and require less safety measures than lasers. The disadvantage of LED is 

that may not transmit light signals at distances as large as lasers. Multimode fibers of 

62.5/125 may transmit data at distances of up to 2000m. The loss of multimode optical fiber 

is specified by the manufacturer. In the case of multimode fiber, the refractive index of glass 

may be constant (multimode step index glass) or may also decreases from the center to the 



OPTICAL FIBRES AND COMPONENTS 

 3 

exterior  (variable or graded-index glass and allows various illuminating modes to reach the 

receiver at the same time).  

 

In optical fiber, beside propagation, the light is subjected to two main phenomena: 

attenuation and dispersion. Attenuation or absorption is essentially due to the presence of 

hydroxyl ions -OH and of the various metal ions. Light may also be spread by micro crystals, 

lower than the wavelength, which form at the cooling of the glass. Attenuation limits the 

length of optical fiber to be used. The dispersion or impulse width widening is mainly due in 

multimode fibers to the different length of the modes. The chromatic dispersion appears due 

to the variation of the refraction index function of the light colour or wavelength. The 

dispersion limits the use of optical fiber in the frequency or in bandwidth. The two limitations 

multiplied characterize most accurate an optical fiber. 20MHz-km values are obtained for 

fiber with step index, 1GHz-km for the variable index and 1000GHz-km for the single-mode 

in which there is no modal dispersion.  

 

Optical fiber transmitters convert electrical signals in equivalent luminous pulses. There are 

two types of light source used by transmitters for optical-fiber: 

• The LED which produces infra-red light having a wavelength of 850nm or 

1310nm. They are used with multimode fibers. Coupling to optical fiber can be 

improved by using a spherical lens; 

• LASER semiconductor diode containing which produces infra-red light having a 

wavelength of 1310nm or 1550nm. They are used with multimode or single-mode 

fibers. 

 

There are two types of basic design for LEDs: with surface emission and with edge emission. 

At surface emission led, the emission of light is perpendicular to the plane of junction 

through a thin transparent layer. They emit in a geometric radial spectrum. At edge emission 

led the light is emitted in a plane parallel to the junction at semiconductor edge. The materials 

used are often compounds III V as GaAs or Al×GA1-XAs for wavelengths of 0.8-0.9 μm and 

Ga×In1-XPYAs1-y for wavelengths of 1.3-1.6 μm. Emission spectrum of a LED is between 25 

to 40 μm for small wavelengths and 50-100 μm for larger wavelengths. 

 

LASER semiconductor diodes, laser diodes (LD), are obtained by introducing a led into an 

optical resonant cavity. The effect of laser only appears at the existence of a direct current 

high enough to achieve an inversion of the population of the electrons and holes from the two 

energy strips of conduction and valence. The current value from which this effect appears is 

called limit current. Under this current the device acts as an ordinary led. Since the light 

emitted by a laser is much more coherent than issued by a LED, the efficiency of the optical 

fiber coupling is higher. Optical power also captured by laser is greater than that emitted by 

the LED. 

 

An analysis compared between the two types of transmitters is clearly in favour of LD 

because the possibility to use higher frequencies, narrower spectrum and in favour of the 

LED due to price and power stability in relation to temperature. 

 

The life expectancy of both devices is equal and is of the order of 10 million hours. 

 



COMPUTER NETWORKS 

 4 

The fiber optics receivers convert luminous pulses into equivalent electrical signals. 

Semiconductor devices normally used for optical fiber are classified in two types: simple and 

with internal gain. The first may be called PIN photodiode by type of doping (p intrinsic and 

n) and the second category is called APD (Avalanche Photo- Diodes). These devices are 

sensible at 850, 1310 and 1550nm wavelengths, wavelengths used by transmitters for optical 

fiber. As semiconductor materials are used Si for wavelengths of 800-900 nm and Ge or 

InGaAsP for 1300 and 1500 nm. Si has optimum sensitivity only within a reduced 

frequencies range but Ge has an appreciable darkness current and is more sensitive to noise. 

For this reason last possibility is the best but requires a more sophisticated manufacturing 

technology and therefore has a higher price.  

In order to connect multiple fibers or for achieving a longer fiber, splices (junctions) may be 

used. Splices are of two types: mechanical and fusion. Attenuations introduced are lower than 

0.5dB (ANSI/TIA-568-C.3 specifies that mechanical or fusions splices shall not exceed a 

maximum optical insertion loss of 0.3dB). At mechanical splices the two ends of the fiber, 

carefully cut, cleaned and polished are caught in a rigid mechanical holder that they fix to 

each other in an fixed ensemble. Fusion splices shall be carried out by heating close to the 

melting point. At this moment the two fibers are pressed against one another and cooled. 

These operations shall be preceded by cutting operations and finishing their ends and prior 

alignment of the two ends which will be connected. Fusion splices also remake draw/bursting 

resistance of the fiber at approximate 90% of the original value. To protect the splices, splice 

enclosures are used. 

Connectors in the optical fiber allow the connection to ports. The common used connectors 

are SC (Subscriber Connector) - snap on type, ST (Straight Tip) - twist on type, FC (Ferrule 

Connector) - screw on type, LC (Lucent Connector) - snap on type and MTP/MPO - 

push/pull type, for multimode optical fibers and for single-mode optical fibers. Attenuation 

introduced by an optical connector, even of superior quality is greater than that introduced by 

a splice, having values of approximately 1 dB. Connectors are high precision mechanical 

equipment and usually one end of the fiber is in the connector and one is free. In this case 

attaching a connector shall be reduced to the execution of a splice. Such a solution is usually 

more advantageous than mounting a connector directly to the end of the fiber because 

prefabricated connectors ensure the accuracy of mounting much higher. If the optical fiber is 

ended into an optical fiber terminator for redistribution this end connector is also called pig-

tail and is prefabricated type. A special category of connectors is optical cords for distribution 

or connection. These are special optical fibers with connectors at both ends allowing small 

fiber curvature radii of approximately 2,5-5 cm. Their color is yellow for single-mode fiber 

and orange for multimode fiber 

 

Repeaters are optical amplifiers receiving light signals attenuated as a result of the distance 

traveled through optical fiber, remake the form, power and time parameters of these signals 

and send them away. 

 

Patch panels for optical fiber are similar with copper cable patch panels, increasing 

flexibility of the optical networks. For connecting different equipment, an optical fiber patch 

cord is used (also known as a zip cord - two flexible optical fibers with connectors at each 

end). 

 



OPTICAL FIBRES AND COMPONENTS 

 5 

Additionally, several other active or passive devices are used with optical fibers (e.q.: optical 

couplers - combines or splits optical signals; optical attenuators - reduce the power level of an 

optical signal; optical isolators; fiber-optic switches; optical multiplexers, etc.). 

 

The ISO/IEC 11801-1 specifies the  requirements for coaxial, twisted-pair copper and optical 

fiber. The ISO/IEC 11801 (Europe) and ANSI/TIA-568-C (USA and Canada) standards 

define 7 classes of optical fibers (single-mode and multimode) as shown in table 2.1, together 

with several important parameters (optical fiber requirements, the cable transmission 

performance and the physical cable requirements): 

 
Table 2.1 Optical fiber characteristics 

 
 

Multimode Single-mode 

Type OM1 

62,5/125 

μm 

OM2 

50/125 

μm 

OM3 

50/125 

μm 

OM4 

50/125 

μm 

OM5 

50/125 

μm 

OS1 

9/125 μm 

OS2 

9/125 μm 

Wavelength 850, 

1300nm 

850, 

1300nm 

850, 

1300nm 

850, 

1300nm 

850, 

1300nm 

1300nm, 

1550nm 

(1383nm) 

1300nm, 

1550nm 

Max. attenuation 

(db/km)  

2.6 /  

2.4 

3.56 / 

2.3 

2.6 /  

1.9 

2.9 /  

1.5 

2.9 /  

1.5 

1 0.4 

Light source LED (Light-Emitting Diode) /  

VCSEL (Vertical Cavity Surface-Emitting Lasers 

Light Source)  

LASER (Light 

Amplification by 

Stimulated Emission of 

Radiation) 

Distance/ 
data rate 

1 Gbps 275m 550m - - - 5-120km 

10Gbps 33m 82m 300m 400m 400m 10-80km 

40-100 

Gbps 

- - 100m 150m 150m 2-80km 

Color orange/ 

slate 

orange aqua violet/ 

aqua 

green/ 

lime 

yellow yellow 

 

Incorrect installation of optical fiber has as result the increase in attenuation for the optical 

signal. The scope or exaggerated than optical fiber may cause cracks in the heart to disperse 

the signal light. Exaggerated stretching or bending of the optical fiber may cause small cracks 

of the core which will scatter the light signal. Exaggerated bending of the optical fiber may 

have as a result the drop in incident angle of the light signal under critical angle of total 

reflection. For the connector installation the heads must be cut off and finished. After 

installation, the heads of the optical fibbers, the fiber connectors and ports must be kept clean 

so that no attenuation will be introduced. Before use of optical fiber cables, their attenuation 

must be tested. At the design of an optical-fiber links, loss of power signal that can be 

https://en.wikipedia.org/wiki/Optical_fiber


COMPUTER NETWORKS 

 6 

tolerated must be calculated. This is called the budget of loss of optical link. Loss of power is 

measured in decibels (dB). 

 

For optical fiber link testing there are several methods: continuity testing, visual fault locator, 

measurement of optical power output, OTDR and BER test error rate. 

 

Continuity testers are used to test the continuity in an optical fiber. A visual fault locator 

(VFL) tool allows a technician to identify breaks, macrobends (refers to the minimum 

bending radius) or poor fusion splices. 

 

The measurement of optical power output determines the loss of power through the optical 

link by measuring the output power at a known input power. The unit of measurement for 

optical power is the miliwatt (mW) but for practical reasons shall be used other unit of 

measure which measure the gain (G) or loss (L) in a system, namely decibel (DB). 

 

The procedure OTDR Optical Time Domain Reflectometer is the procedure by which the 

attenuation characteristics of an optical fiber and its length may be visualized. This procedure 

is the only through which can be detected positions such breaks in optical fibre. OTDR 

displays a graphic having as X axis the fibre length and as Y axis the attenuation. From this 

graphic, the fiber attenuation and the splices and connectors quality can be deduced. Also can 

be determined the braking position in the cable if externally the cable is not affected. 

 

The BER test (Bit Error Rate) is the final test for a data link through optical fiber. This test or 

criterion shows at how many bits transmitted through the fibre an error due fibre will be 

produced. The BER test must meet the requirements imposed by the producers of the DTE 

equipment that are coupled to the optical fibre. For computer networks they ask to be less 

than 1 bit of error at 109/1012 bits transmitted or BER < 10-9/10-12. For the testing is required a 

generator of random bit sequence and an interface to optical fibre if a loop is tested or two if 

a single fibre is tested. In order to have significant results, the test must be carried out over a 

period long enough so as to provide a sufficient number of bits. The test period of one day or 

two are common if it is working at a large bit rate in the use of optical fibre link and small 

BER. A counter may automatically count the number of errors detected. 

 

Calculation of optical power budget shall be made according to the following table. 

 
Table 2.2 Optical power budget 

 

Crt.  Optical loss or power DB  

1.  The km loss in Optical Fibre db/km X _____km fibre _____dB  

2.  The loss in Splices ___dB/splice X _____splices _____dB  

3.  The loss in Connectors __dB/connector X ___ connectors _____dB  

4.  Losses on other components _____dB  

5.  Margin of error _____dB  

6.  Total loss on the Link (1+2+3+4+5) _____dB  

7.  The power of average emission of the transmitter _____dB  

8.  Average power received by the receiver (7-6)  _____dB  

9.  The dynamic of the receiver _____dB at _____dB   

10.  Receiver sensitivity at a rate of errors given by BER _____dB  

11.  Available Remaining Power  (8-10) _____dB  



OPTICAL FIBRES AND COMPONENTS 

 7 

Remarks  

 

For item 3. the transmitter connection losses to the optical will not be taken into account, 

these being already included. The amount calculated in item 8. must be within the range of 

item 9. for the receiver to operate correctly. The amount calculated in item 11 must be 

positive in order to have a functional optical data link.  

 

The error margin is due to take into account the average values for all link components. The 

dispersion of these values around the mean value is known and may take a margin of error 

large enough to cover deviations from an average with a probability of 99.9% or more. As the 

number of items is greater and as it is desirable a larger cover probability than a larger error 

margin will be taken. 

 

Optical emission power of the transmitter is a catalogue data and includes the loss of 

connection at one end of the optical fiber in the case in which the connection is made in 

accordance with recommendations. The power is greater at the LASER diodes and smaller at 

the LED. In the case of LASER usage for relatively short distances an attenuator is necessary 

so that the receiver will not be destroyed. 

 

Receiver dynamics represents the power range which a receiver can transform in electrical 

signal without loss of information. 

 

It is also needed a minimum optical power necessary for fulfilling the tolerated error rate 

condition which for computer networks is situated at the value of 1 bit erroneous at one 

billion bits transmitted. 

 

Calculus example of the optical power budget  

 

Optical fiber diameter: Core 62.5μm/Cladding 125μm. 

Numerical aperture of the fiber NA: 0.275. 

The wavelength of the optical equipment: 1310μm.  

 
Table 2.3 Calculus example 

 
Crt.  Optical loss or power DB  

1.  The km loss in Optical Fiber 1,8db/km X 3,5km fiber 6,3dB  

2.  The loss in Splices 0,5dB/splice X 2 splices 1,0dB  

3.  The loss in Connectors 1,0dB/connector X 2 connectors 2,0dB  

4.  Losses on other components 0,0dB  

5.  Margin of error 2,0dB  

6.  Total loss on the Link (1+2+3+4+5) 11,3dB  

7.  The power of average emission of the transmitter -10,0dB  

8.  Average power received by the receiver (7-6)  -21,3dB  

9.  The dynamic of the receiver _____dB at _____dB  

10.  Receiver sensitivity at a rate of errors given by BER -26,0dB  

11.  Available Remaining Power  (8-10) +4,7dB  

 

The power at the receiver is in the dynamic of the receiver, which makes possible its 

function, and the remaining available power is positive, ensuring a viable connection. 



COMPUTER NETWORKS 

 8 

 

There should be taken into account the fact that during the life of the link, aging phenomena 

may occur, leading to increase the power loss, as well as the fact that optical fiber may be 

broken accidentally and needs to be spliced.  

 

A calculation made to the limit endangers the length of service of a link through optical fiber. 

 

 

 

3. Lab activity 

3.1 The characteristics of various types of optical fibers, components and aspects related to 

the cabling of computer networks using this transmission environment should be discussed. 

3.2 Explore the fiber optic infrastructure deployed in the oceans available at 

https://www.submarinecablemap.com/ 

3.3 A 9/125μ single-mode optical fiber having the length of 2,5km and the loss equal to 

0,5dB/km, which connects two DTE equipments is considered. The attenuation introduced by 

splices and connectors is equal to 0,5 and 1dB respectively. The error margin taken into 

consideration is 3dB. The power of average emission of the transmitter is -15dB, the receiver 

sensitivity at a rate of errors given by BER 10-9 is -25dB and dynamic of the receiver is in the 

range -10 ÷ -30dB. Calculate the optical power budget. 

 

 

Notes 

 



reading content from D:\SD\SearchEngine_ver1\See\CN3b_2022.pdf


LABORATORY WORK NO. 3b 
STRUCTURED CABLING 

 

1. Objectives 

 
The objective of this paper is the knowledge of structured cabling, networks topology and the 

function of the different network devices. 

 

2. Theoretical considerations 

 
2.1 Physical media analysis 

 

In the physical media analysis, we may choose several factors of performance such as: the 

speed of transfer, bandwidth, reliability or the error rate, the duration of service, the average 

duration between the two defects, defects tolerance, direct costs, indirect costs, the cost per 

port or equipment connected, the cost per bandwidth or the total cost per port per bandwidth. 

The bandwidth, LB is a factor of intrinsic performance particular to each medium. The 

reliability, F, is also a factor of intrinsic performance of each medium and shall be the ratio of 

the number of bits erroneously transmitted to the total number of bits transmitted. The service 

duration, De, is the length of time after the environment should be replaced, due to aging 

phenomena. The average duration between two faults, DMDD, is the statistical average time 

between two successive malfunctions of the environment for the standardised period of life. 

Defects tolerance, Td, is a factor of performance induced on the physical environment by the 

technology and network architecture used, but in many cases a given environment does not 

allow a error tolerance architecture or only one limited. Direct costs, Cd, are represented by 

the actual cost of the environment along with connectors, the auxiliary materials necessary 

for correct posing, and the cost of labour for communication environment realisation and 

environment testing. The cost per port, Cp, it is a synthetic factor which has a greater decision 

value, being a global decision criterium and reflecting the total costs for carrying out physical 

infrastructure related to the total number of ports or equipment connected. The cost per port 

per speed of transfer, Cpv, is a factor performance more usefull which alleviates taking a 

correct decision in the implementation of a local area network, including the possibility of 

future extension without the need for change the environment. The total cost per port per 

speed, Ctpv, is a complex factor of performance which characterizes a local area network at 

global level also including the equipment or technology costs. Characterization of 

performance factors above referred of the physical communication media previously 

presented is summarized in the following table. Performance factors, and in particular the 

type of cost, shall be classified relatively without giving absolute values which may be 

affected very rapidly in time. 

 
Table 2.1  Performance factors 

 

 

Medium Lb 

Gbps 

Reliability De 

years 

DMDD Td Cd Cp Cpv Ctpv Recomanded 

in usage 

Further use 

UTP Cat 6,7 >1 Medium 15 years Yes Medium Small Small Small Yes Yes  

Multimode OF >1 Large 30 years Yes Large Medium Medium Medium Yes Yes 

Single-mode OF >1 Large 30 years Yes V. Large V. Large Large Large Yes Yes 



COMPUTER NETWORKS 

 2 

2.2 Structured cabling  

 

There are three standard network topologies bus, star and ring: 

• Bus topology is the oldest method of interconnecting computers in a network. 

Data is transmitted to all the stations but is accepted only by the destination 

station, and the reflection of the signal is stopped using terminators. Figure 2.1 a. 

represents the bus topology; 

• Star topology has replaced the bus topology, the main feature is that it has a 

central component called hub through this component data is transmitted from one 

station to all the others. The star topology offers the resources and means for 

central administration. Figure 2.1 b. represents the star topology; 

• Ring topology stations are connected through a cable shaped as a ring and every 

station is acting as a repeater amplifying the signal. Figure 2.1 c. represents the 

star topology. 

 

Today most of the topologies used are combinations of star, ring and bus topologies. The bus-

star topology supposes connecting networks with star topology through linear branches (bus). 

Problems of connectivity appear when a concentrator fails. The ring-star topology also 

known as ring cabled as a star. In this case there is a central concentrator that connects all the 

other concentrators to which the stations are connected. 

 

 

 

 

 

 

 

 

 

 

 

 

 
      a. bus topology            b. star topology         c. ring topology 

 
Figure 2.1 Standard network topologies 

 

Under the generic name of active elements are grouped all of the network components that 

need a power supply and can work with electric, optic signals or both. Network interface 

cards are active elements of layer 2 providing the stations with the network connectivity. 

Every network interface card has its own 48 bits MAC address assigned from fabrication. 

This address is unique for every network card and it is composed of 2 parts: the 24 most 

significant bits identifies the producer, and the 24 least significant bits are assigned by the 

producer. The network interface cards used in PC’s need an I/O address space and a hardware 

interrupt. The interrupt is activated every time an event (a frame reception in most of the 

cases) appears requiring software attention, and the I/O address space represents the address 

region in which the card registers are accessible (written, read, by its driver). Usually both the 

interrupt and the I/O space are configurable to avoid conflicts with other devices. 

 

Station 

 

 

Station 

 

 

Station 

 

 

Switch 

 

 

Station 

 

 

Station 

 

Station 

 

 

Station 

 

Station 

 

 

Station 

 

 

Station 

 

 

Station 

 

 

Station 

 



STRUCTURED CABLING 

 3 

The overcome of the length limitations of cables is done by using repeaters. These are 

simple devices, connected at many network segments amplifying the signal that passes 

through them. Repeaters operate at the physical layer (they don’t have the frame notion or 

package transmitted through the network) and they broadcast the amplified signals on all 

their outputs.  

 

With the growth of the network dimensions, problems will appear if there are used only 

repeaters. The limitation for the stations that create such a network is the fact that 

repeaters/hubs(multiport repeaters) split the bandwidth, being situated in a single collision 

domain. In order to solve this problem we use bridges, equipments that operate at the second 

layer in the OSI hierarchy, and they represent devices much more complex than repeaters 

because they perform frame filtering based on MAC addresses and a separation of collision 

domains. Bridges don’t forward the frames that are local for a network, but only the ones that 

have destination addresses located in other networks. They store the frames and realize a 

retransmission only to the network in which the destination is situated. When the bridges are 

powered-up they know nothing about the network configuration and the addresses of the 

computers connected to it, but they learn the network topology while they forward the 

frames. Initially they allow all the frames to pass in all directions. But in time, as frames pass 

through, the bridge inspects the source address of each frame and completes the MAC tables, 

with the station address and the port at which the station is connected. Based on these tables 

they decide on which port the frames must be retransmitted. Frames sent at broadcast or 

multicast addresses will be retransmitted further away on all ports. Switches are layer 2 

equipments that take frames forwarding decisions based on the MAC address, so to direct the 

data only on the port corresponding to the destination host. These devices can be seen as 

devices capable to offer the connectivity of a hub and they manage the traffic like a bridge. 

Designing networks with complex topologies is done using switches. 

 

Routers are layer 3 equipments that route the packets based on the address used by routable 

protocols (for example Internet Protocol-IP or Internetwork Packet Exchange – IPX) with the 

help of the routing protocols (for example Routing Information Protocol RIP, Interior 

Gateway Routing Protocol – IGRP, Enhanced Interior Gateway Routing Protocol – EIGRP or 

Open Shortest Path First - OSPF). There are two main router types: dedicated routers and 

routers built from general purpose computers that have more interfaces. The computer routers 

have the advantage of cost and simplicity and can be used for other jobs. Dedicated routers 

are much more efficient and flexible, have much more interfaces and support more protocols 

and medium access types. Dedicated routers are devices specialized for the routing job. Due 

to the specialized hardware and powerfully optimized software, they achieve superior 

performance. They offer a wide range of speeds, physical interfaces and communication 

protocols. Usually these are manufactured by specialized firms (Cisco, Juniper, HPE etc.) 

their operating system is specific and has all the software need for the router to function 

properly. Dedicated routers support almost any transmission medium, used with any 

communication protocol, with a large range of sockets and adaptors. 

 

Taking in consideration the costs for realizing or modifying a network cabling it has been 

proved that once a network has been set in place is better to stay in use as long as possible 

and that it should be able to be used with novel communication technologies. The solution for 

this problem was in the elaboration of the structured cabling concept, defined later through 

several international standards. 



COMPUTER NETWORKS 

 4 

The ISO/IEC 11801 (Europe) and ANSI/TIA-568-C (USA and Canada) standard refer to the 

ways of cabling commercial edifices, specifying the cabling structure, the necessary minimal 

configuration, the categories of cables and components that must be used, ways of 

installation, performance requests that have to be met, acceptable distance limits and other 

parameters, and also ways and methods for testing them. Another problem that is approached 

is the problem of designing the cabling for a much more complex building group, in this way 

a complex project needs to be configured in a hierarchic (tree-like) structure, allowing the 

possibility to add redundant links. The standard specifications refer to some of the following 

aspects: 

• Minimal request for realizing the cabling of a building 

o The cabling topology and allowed distances; 

o Component elements of the cabling; 

o Transmission media used with the needed parameters specification; 

o Vertical and horizontal cabling realization mode; 

o Ways of identifying the cables used; 

o Project documentation. 

• Subsystems and components of the structured cabling system 

o The subsystem from the entrance in the building; 

o The equipment room; 

o The backbone cabling; 

o The telecommunication closet; 

o Horizontal cabling; 

o The work area components. 

 

The cabling topology specified in the ISO/IEC or ANSI/TIA standard is a star, hierarchically 

organized (extended star). The topology center is main distribution facility, the second 

hierarchic level is the intermediary distribution facility afferent to one area edifice, and at the 

lower level is the telecommunication closet related to a floor or a group of rooms. The 

constitutive elements are: 

• The main distribution facility – the distribution center to the other edifices; 

• The intermediary distribution facility – are local to edifices; 

• The telecommunication closet – is represented by the local distribution closets for 

the cables that connect the stations or related to the vertical cabling; 

• The inter-edifice section – identifies the main cables that interconnect the main 

distribution center; 

• The internal section – connects the intermediate commuter with the distribution 

offices; 

• The equipment room – related to a cabling plan with passive and active 

equipments; 

• The entrance infrastructure – for the interfacing of the exterior cabling system 

with the interior one; 

• The work area – the working stations, interconnection cables, external adaptors 

between cables; 

• Intermediate panels – identifies the connection panels for the transmission 

mediums; 

• Terminator blocks – represent the cable mechanical terminators; 

• Communication outlets, cabling adaptors. 



STRUCTURED CABLING 

 5 

 

The usual transmission media are: 

• Twisted cable (category 6 and above); 

• Multimode or single-mode optical fiber; 

 

Types of the connectors used are: 

• RJ-45 connectors for TP cables; 

• LC, SC or ST type connectors for optical fiber; 

 

So, in order to accommodate a much easier and efficient way to manage the network, the 

cabling is structured using concentrators (on different levels). At each level a concentrator 

must be implemented, and if the covered area is too large than several concentrators can be 

used. At the working stations the UTP cable is ended in RJ-45 connectors, and at the 

concentrator in boxes or patch panels. The cumulative length of the cable and UTP patch cord 

used for connecting a computer at the equipment from the concentrator is not allowed to be 

greater than 100m. In the floor concentrator the switches or other equipments are situated. 

 

The advantages concentrators offer (and also the topologies based on concentrators) are: 

• possibility to extend or modify the cable system; 

• usage of different ports, adapted at different types of cables; 

• possibility of a central monitoring of the activity and the network traffic. 

 

Types of concentrators: 

• Active concentrators – that regenerates and transmits the signal; 

• Passive concentrators – can be considered the cabling panels or the connection 

blocks representing only connection points without any signal amplification. Also 

there are hybrid concentrators that allow the usage for connection of different 

cable types. 

 

The cables must be labeled according to the standard, the ventilation must be sufficient to 

prevent equipment overheating, security measures must be set and fire protection must be 

provided. The floor concentrator is connected to the building concentrators, link that can be 

realized with a category 6 cable or with multi-mode optical fiber. Additionally, redundant 

links can be added between the floor concentrators and between the buildings. The building 

group concentrator is connected to the buildings concentrators with multimode or single-

mode optical fiber. Installation standards are referring to the cable installation (maximum 

tension allowed on the cable, mechanical connection type), masked horizontal cabling, 

ground protection, and the specific protection of the optical fibers cables. 

 



COMPUTER NETWORKS 

 6 

3. Lab activity 

 
3.1 The topologies of the computer networks are going to be discussed underlining their 

advantages and disadvantages. 

3.2 The function of the following network devices will be discussed: network interface card, 

concentrator, repeater, bridge, switch and router. 

3.3 Aspects of the structured cabling and ISO-IEC/ANSI-TIA standard will be discussed. 

3.4 Floor cabling will be analyzed, and the elements of the structured cabling will be pointed 

out. 

3.5 Identify and analyze the structured cabling design at your workplace/home. How is your 

network connected to the WAN/ISP (what type of cable, device, etc)? How is your device 

connected to the internal network? 

 

 

 

 

Notes 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 



reading content from D:\SD\SearchEngine_ver1\See\CVGenenral.pdf


0770644019

braica.patricia@yahoo.com

Satu Mare / Cluj Napoca,
Romania

Computer Science Student
Technical University of Cluj-Napoca
expected graduation year 2026

EDUCATION

ABOUT ME

MOST RELEVANT COURSES

English C1
German B1

LANGUAGE

PATRICIA MARIA BRAICA
S T U D E N T

Completing the Fundamental Algorithms and Data Structures in C
course set me on the path to efficiency in programming.

Fundamental Algorithms in C

I successfully completed an Object-Oriented Programming (OOP)
course using Java, which included a mandatory project.

OOP on Java and C++

Through the completion of an SQL course, I acquired the essential
skills required for effective database management.

SQL programming

Romanian (Native)

linkedin.com/in/patricia-
maria-braica-00534b298

Successfully completing the Logic Design of Circuits course has
been instrumental in building a strong foundation for my
understanding of hardware systems.

Logic Design of Circuits, Assembly, VHDL

EXPERIENCE IN IT
I created a Java applications utilizing the JavaFX framework, seamlessly connected to a database using
SQL, and enhanced the user interface with CSS(My projects: Order app for a backery simulation,
Polynomial Calculator, Queue Management Simulator in real time using multithreading, Order management  
simulation using Reflection techiques. )
I successfully implemented a VHDL project on the Nexys 4 board, featuring the display of eight
dynamic animations conveying a message, resembling a digital advertisement.

Through the completion of an SQL course, I acquired the essential skills required for
effective database management.

PROGRAMMING LANGUAGES 
C,C++, Java, SQL, VHDL, Assembly x86, Arduino, Haskell, Git Bash, LaTeX, Python, Prolog

Attended domain related competitions: CodeRun competiotion by BEST, in Cluj-Napoca,
WIDS(Women in Data Science) - predict ADHD in women, on Kagggle.

Github and GitLab repos:
https://github.com/Patriciadah
https://pastebin.com/UtuJW7m2

Organized, results-driven, and experienced in structuring learning
programs. Studying in English enhances my understanding of technical
terms. Broad knowledge in computer science: software engineering, AI,
full-stack development, cybersecurity and more. Strong vision for
teamwork and project execution.

Implemented PDDL-like theorem proving to detect deception in
Among Us. Designed AI solutions for Sliding Tile Puzzle and All Lights
Out using automated planning. Integrated AI into the Pac-Man
framework for decision-making and pathfinding, leveraging
adversarial search.

AI Technologies in Python

https://www.linkedin.com/in/patricia-maria-braica-00534b298
https://www.linkedin.com/in/patricia-maria-braica-00534b298
https://github.com/Patriciadah
https://pastebin.com/UtuJW7m2


reading content from D:\SD\SearchEngine_ver1\See\EY.txt

PE@!HxG433M4hTyt

reading content from D:\SD\SearchEngine_ver1\See\FileIndexRowMapper.java

package com.example.searchengine_ver1.backendapi.repository;

import com.example.searchengine_ver1.model.FileIndex;
import org.springframework.jdbc.core.RowMapper;

import java.sql.ResultSet;
import java.sql.SQLException;

public class FileIndexRowMapper implements RowMapper<FileIndex> {
    @Override
    public FileIndex mapRow(ResultSet rs, int rowNum) throws SQLException {
        return new FileIndex(
                rs.getLong("id"),
                rs.getString("file_name"),
                rs.getString("file_path"),
                rs.getString("file_type"),
                rs.getString("file_content"),
                rs.getTimestamp("indexed_at").toLocalDateTime()
        );
    }
}


reading content from D:\SD\SearchEngine_ver1\See\FileIndexService.java

package com.example.searchengine_ver1.backendapi.service;

import com.example.searchengine_ver1.model.FileIndex;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;

import java.util.List;

@Service
public class FileIndexService {
    private final FileIndexRepository fileIndexRepository;

    @Autowired
    public FileIndexService(FileIndexRepository fileIndexRepository) {
        this.fileIndexRepository = fileIndexRepository;
    }

    public void indexFiles(List<FileIndex> files) {
        fileIndexRepository.saveAll(files);
    }

    public List<FileIndex> searchFiles(String query) {
        return fileIndexRepository.searchFiles(query);
    }
}


reading content from D:\SD\SearchEngine_ver1\See\files_border_tracing.zip


gray_background.bmp


horizontal_ellipse.bmp


object_holes.bmp


skew_ellipse.bmp


star.bmp


star_R90.bmp


triangle_down.bmp


triangle_up.bmp


vertical_ellipse.bmp


reconstruct.txt
159 175
3149
5 4 4 4 5 4 4 5 4 5 4 5 4 5 5 5 4 5 6 5 5 5 6 5 5 6 5 6 6 5 6 6 5 6 6 6 6 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 6 6 6 6 7 6 6 6 7 6 7 6 7 6 7 7 7 6 7 7 0 7 7 7 0 7 7 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 3 3 2 3 3 2 3 3 2 3 3 2 3 2 3 3 2 3 3 2 3 3 2 3 3 2 3 3 2 3 2 3 3 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 2 1 1 2 1 1 2 1 1 2 1 1 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 6 5 6 5 5 6 5 5 6 5 5 6 5 5 6 5 5 6 5 3 2 3 3 2 3 3 2 3 3 2 3 3 2 3 3 2 3 2 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 6 7 7 6 7 7 6 7 7 6 7 7 6 7 7 6 7 6 7 7 6 7 7 6 7 7 6 7 7 6 7 7 6 6 5 5 6 5 6 5 5 6 5 5 6 5 5 6 5 5 6 5 5 6 5 6 5 5 6 5 5 6 5 5 6 5 5 6 5 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 1 2 1 1 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 2 1 7 6 7 7 6 7 6 7 7 6 7 7 6 7 7 6 7 7 6 7 7 6 7 6 7 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 7 6 7 7 6 7 6 7 7 6 7 7 6 7 6 7 7 6 7 6 7 7 6 7 7 6 7 6 7 7 6 7 7 6 7 6 7 7 6 7 7 6 7 6 7 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 6 6 6 6 6 6 6 6 6 6 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 3 2 3 2 3 3 2 3 2 3 3 2 3 3 2 3 2 3 3 2 3 3 2 3 2 3 3 2 3 3 2 3 2 3 3 2 3 2 3 3 2 3 3 2 3 2 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 1 1 0 1 1 1 1 1 1 2 1 1 2 1 2 1 2 2 1 2 4 3 4 4 3 4 4 4 3 4 4 3 4 6 5 6 6 5 6 5 5 6 5 5 5 4 5 4 5 4 5 4 4 4 4 4 4 4 4 3 4 4 3 4 3 4 3 3 3 3 2 3 2 3 2 2 3 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 1 2 1 2 1 1 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 7 0 0 7 0 7 7 7 7 7 6 7 6 7 6 0 1 0 0 0 0 1 0 0 0 0 1 0 2 3 2 3 2 2 3 3 2 3 3 3 3 3 3 4 3 3 4 3 4 4 3 4 4 4 3 4 4 4 4 4 4 4 4 4 4 4 4 



reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele (1).docx

Fisa de lucru – Tabele

Aplicatia 1

1. Creaţi un document Word nou, cu următoarele setări de pagină: format A4, margini: dreapta 1.75 cm, stânga 1.62 cm, sus 2.04 cm, jos 2.37 cm, orientarea paginii orizontală(landscape).
 realizaţi un antet aliniat la stânga, care să conţină “Date elevi” ;
 numerotarea paginii: stânga – sus utilizând cifre romane cu dimensiunea de 14, bold, fontul Tahoma.

1. Creati un tabel cu urmatoarea structura :
	
	Nr. crt.
	Numele si Prenumele
	Disciplina

	
	
	Matematica
	Lb. Romana
	Informatica

	
	
	Note
	Media
note 
	Teza
	Media 
finală
	Note
	Teza
	Note
	Teza

	
	
	N1
	N2
	
	
	
	N1
	N2
	
	N1
	N2
	

	1.
	Popescu Ion
	7
	8
	
	5
	
	5
	7
	6
	10
	8
	10

	
	
	
	
	
	
	
	
	
	
	
	
	



 Cerinte :
1. pentru tabel conturul exterior:linie dubla,grosime linie-4 ½ pt, culoare verde
1. -liniile dintre coloane sa fie punctate de culoare albastru si grosime 3 pt
1. Adaugati si pentru disciplinele Lb. Romana si Informatica coloanele Media note și Media finală, ca si la Matematica
1. Completati coloana Media note ca fiind (N1+N2)/2 iar Media finală dupa formula (3*media note +teza)/4
1.  adaugati inca 5 linii pe care le completati cu date
1. Sortati tabelul descrescator dupa nume


Aplicatia 2
Realizati urmatoarele tabele:
	
	INTERNET
	INTERNET
	Cea mai mare retea de informatii si comunicare din lume

	
	TCP/IP
	Protocol prin care retelele comunica intre ele in cadrul retelei mari

	
	URL
	Adresa unei pagini de Internet

	
	Adresa IP
	Adresea unui calculator in Internet

	
	ISP
	Furnizor de servicii Internet (firma care faciliteaza accesul la Internet)



	VOCABULAR

	Site Web
	Loc in www, unde se gasesc mai multe pagini web

	Pagina Web
	In limba engleza web-page; o pagina in www

	Pagina de start (homepage)
	Pagina principala a unui site web




	VOCABULAR

	e-mail
	Electronic mail; posta electronica; metoda de transmitere a mesajelor prin Internet

	attachment
	Fisiere atasate mesajului si trimise impreuna cu acesta





	
O adresa de e-mail (de exemplu: operarepc_1@yahoo.com) este alcatuita din urmatoarele componente: 


	Numele de utilizator
	Numele de utilizator sub care v-at inregistat in serverul de mail (Operarepc_1)

	@
	At, cunoscut si sub denumirea coada de maimuta

	domeniu
	Numele serverului de e-mail sau al furnizorului, care are in administrare casuta postala (Yahoo.com)




	
Alcatuirea e-mail-urilor


	Butonul Compose




	To
	Aici trebuie introdusa adresa destinatarului. 
E-mail-urile cu adresa gresita se intorc cu mesaj de eroare.

	Cc (Carbon copy – copie)
	Daca aici este introdusa o adresa de e-mail, mesajul este transmis si acelei persoane.

	Bcc (Blind carbon copy – copie oarba)
	La fel ca la Cc, numai ca destinatarul nu vede adresa celeilalte persoane careia i-a mai fost transmis e-mail-ul. 

	Subject (subiect)
	Aici scrieti un cuvant cheie (titlul care reprezinta esenta mesajului

	Corpul mesajului
	In acest spatiu se scrie textul. 

	Butonul Send





Aplicatia 3

Realizati in Ms. Word tabelul de mai jos urmand ca pentru fiecare simbol „?” sa inseram formula de calcul necesara fiecarei celule






image1.png


reading content from D:\SD\SearchEngine_ver1\See\fisa_tabele.docx

Fisa de lucru – Tabele

Aplicatia 1

1. Creaţi un document Word nou, cu următoarele setări de pagină: format A4, margini: dreapta 1.75 cm, stânga 1.62 cm, sus 2.04 cm, jos 2.37 cm, orientarea paginii orizontală(landscape).
 realizaţi un antet aliniat la stânga, care să conţină “Date elevi” ;
 numerotarea paginii: stânga – sus utilizând cifre romane cu dimensiunea de 14, bold, fontul Tahoma.

1. Creati un tabel cu urmatoarea structura :
	
	Nr. crt.
	Numele si Prenumele
	Disciplina

	
	
	Matematica
	Lb. Romana
	Informatica

	
	
	Note
	Media
note 
	Teza
	Media 
finală
	Note
	Teza
	Note
	Teza

	
	
	N1
	N2
	
	
	
	N1
	N2
	
	N1
	N2
	

	1.
	Popescu Ion
	7
	8
	
	5
	
	5
	7
	6
	10
	8
	10

	
	
	
	
	
	
	
	
	
	
	
	
	



 Cerinte :
1. pentru tabel conturul exterior:linie dubla,grosime linie-4 ½ pt, culoare verde
1. -liniile dintre coloane sa fie punctate de culoare albastru si grosime 3 pt
1. Adaugati si pentru disciplinele Lb. Romana si Informatica coloanele Media note și Media finală, ca si la Matematica
1. Completati coloana Media note ca fiind (N1+N2)/2 iar Media finală dupa formula (3*media note +teza)/4
1.  adaugati inca 5 linii pe care le completati cu date
1. Sortati tabelul descrescator dupa nume


Aplicatia 2
Realizati urmatoarele tabele:
	
	INTERNET
	INTERNET
	Cea mai mare retea de informatii si comunicare din lume

	
	TCP/IP
	Protocol prin care retelele comunica intre ele in cadrul retelei mari

	
	URL
	Adresa unei pagini de Internet

	
	Adresa IP
	Adresea unui calculator in Internet

	
	ISP
	Furnizor de servicii Internet (firma care faciliteaza accesul la Internet)



	VOCABULAR

	Site Web
	Loc in www, unde se gasesc mai multe pagini web

	Pagina Web
	In limba engleza web-page; o pagina in www

	Pagina de start (homepage)
	Pagina principala a unui site web




	VOCABULAR

	e-mail
	Electronic mail; posta electronica; metoda de transmitere a mesajelor prin Internet

	attachment
	Fisiere atasate mesajului si trimise impreuna cu acesta





	
O adresa de e-mail (de exemplu: operarepc_1@yahoo.com) este alcatuita din urmatoarele componente: 


	Numele de utilizator
	Numele de utilizator sub care v-at inregistat in serverul de mail (Operarepc_1)

	@
	At, cunoscut si sub denumirea coada de maimuta

	domeniu
	Numele serverului de e-mail sau al furnizorului, care are in administrare casuta postala (Yahoo.com)




	
Alcatuirea e-mail-urilor


	Butonul Compose




	To
	Aici trebuie introdusa adresa destinatarului. 
E-mail-urile cu adresa gresita se intorc cu mesaj de eroare.

	Cc (Carbon copy – copie)
	Daca aici este introdusa o adresa de e-mail, mesajul este transmis si acelei persoane.

	Bcc (Blind carbon copy – copie oarba)
	La fel ca la Cc, numai ca destinatarul nu vede adresa celeilalte persoane careia i-a mai fost transmis e-mail-ul. 

	Subject (subiect)
	Aici scrieti un cuvant cheie (titlul care reprezinta esenta mesajului

	Corpul mesajului
	In acest spatiu se scrie textul. 

	Butonul Send





Aplicatia 3

Realizati in Ms. Word tabelul de mai jos urmand ca pentru fiecare simbol „?” sa inseram formula de calcul necesara fiecarei celule






image1.png


reading content from D:\SD\SearchEngine_ver1\See\geometrical_features_images.zip


Single Object/skew_line.bmp


Single Object/horizontal_line.bmp


Single Object/vertical_line.bmp


Single Object/skew_ellipse.bmp


Single Object/horizontal_ellipse.bmp


Single Object/vertical_ellipse.bmp


Single Object/vertical_ellipse_Z150%.bmp


Single Object/star_R90.bmp


Single Object/star.bmp


Single Object/star_Z125%.bmp


Single Object/triangle_down.bmp


Single Object/triangle_up.bmp


Multiple Objects/geometrical_features.bmp


reading content from D:\SD\SearchEngine_ver1\See\lab-05.zip


lab-05/decision_trees.ipynb
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:20.649366400Z",
     "start_time": "2025-03-26T12:20:20.308938400Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#for graphviz install python-graphviz:\n",
    "#conda install python-graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:20.853102400Z",
     "start_time": "2025-03-26T12:20:20.311337400Z"
    }
   },
   "outputs": [],
   "source": [
    "input_file = \"data/restaurant.csv\"\n",
    "# input_file = \"data/restaurant100v3.csv\"\n",
    "\n",
    "# comma delimited is the default\n",
    "data = pd.read_csv(input_file, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.089705200Z",
     "start_time": "2025-03-26T12:20:20.323978700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    Alt  Bar  Fri  Hyn   Pat Price Rain  Res     Type    Est WillWait\n0   Yes   No   No  Yes  Some   $$$   No  Yes   French   0–10      Yes\n1   Yes   No   No  Yes  Full     $   No   No     Thai  30–60       No\n2    No  Yes   No   No  Some     $   No   No   Burger   0–10      Yes\n3   Yes   No  Yes  Yes  Full     $  Yes   No     Thai  10–30      Yes\n4   Yes   No  Yes   No  Full   $$$   No  Yes   French    >60       No\n..  ...  ...  ...  ...   ...   ...  ...  ...      ...    ...      ...\n95   No  Yes  Yes  Yes  Full     $  Yes   No   Burger  30–60      Yes\n96  Yes  Yes  Yes   No  Full    $$   No   No   Burger    >60       No\n97   No  Yes  Yes  Yes  Full     $  Yes  Yes  Italian  10–30       No\n98  Yes   No   No   No   NaN    $$  Yes   No     Thai   0–10       No\n99   No  Yes  Yes  Yes  Full    $$  Yes   No   Burger  30–60      Yes\n\n[100 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Alt</th>\n      <th>Bar</th>\n      <th>Fri</th>\n      <th>Hyn</th>\n      <th>Pat</th>\n      <th>Price</th>\n      <th>Rain</th>\n      <th>Res</th>\n      <th>Type</th>\n      <th>Est</th>\n      <th>WillWait</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Some</td>\n      <td>$$$</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>French</td>\n      <td>0–10</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Full</td>\n      <td>$</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Thai</td>\n      <td>30–60</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Some</td>\n      <td>$</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Burger</td>\n      <td>0–10</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Full</td>\n      <td>$</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Thai</td>\n      <td>10–30</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Full</td>\n      <td>$$$</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>French</td>\n      <td>&gt;60</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Full</td>\n      <td>$</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Burger</td>\n      <td>30–60</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Full</td>\n      <td>$$</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Burger</td>\n      <td>&gt;60</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Full</td>\n      <td>$</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Italian</td>\n      <td>10–30</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>$$</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Thai</td>\n      <td>0–10</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Full</td>\n      <td>$$</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Burger</td>\n      <td>30–60</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.105057900Z",
     "start_time": "2025-03-26T12:20:20.352486800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 11)"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.105057900Z",
     "start_time": "2025-03-26T12:20:20.365469300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Alt', 'Bar', 'Fri', 'Hyn', 'Pat', 'Price', 'Rain', 'Res', 'Type',\n       'Est', 'WillWait'],\n      dtype='object')"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.105057900Z",
     "start_time": "2025-03-26T12:20:20.397138200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Alt  Bar  Fri  Hyn   Pat Price Rain  Res    Type    Est WillWait\n0  Yes   No   No  Yes  Some   $$$   No  Yes  French   0–10      Yes\n1  Yes   No   No  Yes  Full     $   No   No    Thai  30–60       No\n2   No  Yes   No   No  Some     $   No   No  Burger   0–10      Yes\n3  Yes   No  Yes  Yes  Full     $  Yes   No    Thai  10–30      Yes\n4  Yes   No  Yes   No  Full   $$$   No  Yes  French    >60       No",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Alt</th>\n      <th>Bar</th>\n      <th>Fri</th>\n      <th>Hyn</th>\n      <th>Pat</th>\n      <th>Price</th>\n      <th>Rain</th>\n      <th>Res</th>\n      <th>Type</th>\n      <th>Est</th>\n      <th>WillWait</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Some</td>\n      <td>$$$</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>French</td>\n      <td>0–10</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Full</td>\n      <td>$</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Thai</td>\n      <td>30–60</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Some</td>\n      <td>$</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Burger</td>\n      <td>0–10</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Full</td>\n      <td>$</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Thai</td>\n      <td>10–30</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Full</td>\n      <td>$$$</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>French</td>\n      <td>&gt;60</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.105057900Z",
     "start_time": "2025-03-26T12:20:20.400168900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Alt         object\nBar         object\nFri         object\nHyn         object\nPat         object\nPrice       object\nRain        object\nRes         object\nType        object\nEst         object\nWillWait    object\ndtype: object"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.105057900Z",
     "start_time": "2025-03-26T12:20:20.413095900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Alt', 'Bar', 'Fri', 'Hyn', 'Pat', 'Price', 'Rain', 'Res', 'Type',\n       'Est', 'WillWait'], dtype=object)"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.105057900Z",
     "start_time": "2025-03-26T12:20:20.428947700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 3, 0, 3, 1, 2, 0, 3, 0, 2, 3, 0, 1, 3, 0, 3, 1, 2, 0, 3, 0, 2,\n       3, 0, 1, 3, 0, 3, 1, 2, 0, 3, 0, 2, 3, 0, 1, 3, 0, 3, 1, 2, 0, 3,\n       0, 2, 3, 0, 1, 3, 0, 3, 1, 2, 0, 3, 0, 2, 3, 0, 1, 3, 0, 3, 1, 2,\n       0, 3, 0, 2, 3, 0, 1, 3, 0, 3, 1, 2, 0, 3, 0, 2, 3, 0, 1, 3, 0, 3,\n       1, 2, 0, 3, 0, 2, 3, 0, 0, 2, 3, 0])"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(data['Type']) # only for one attribute\n",
    "data_encoded = le.transform(data['Type'])\n",
    "data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.105057900Z",
     "start_time": "2025-03-26T12:20:20.435868300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Burger', 'French', 'Italian', 'Thai'], dtype=object)"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.150275400Z",
     "start_time": "2025-03-26T12:20:20.446589400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    Alt  Bar  Fri  Hyn  Pat  Price  Rain  Res  Type  Est  WillWait\n0     1    0    0    1    1      2     0    1     1    0         1\n1     1    0    0    1    0      0     0    0     3    2         0\n2     0    1    0    0    1      0     0    0     0    0         1\n3     1    0    1    1    0      0     1    0     3    1         1\n4     1    0    1    0    0      2     0    1     1    3         0\n..  ...  ...  ...  ...  ...    ...   ...  ...   ...  ...       ...\n95    0    1    1    1    0      0     1    0     0    2         1\n96    1    1    1    0    0      1     0    0     0    3         0\n97    0    1    1    1    0      0     1    1     2    1         0\n98    1    0    0    0    2      1     1    0     3    0         0\n99    0    1    1    1    0      1     1    0     0    2         1\n\n[100 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Alt</th>\n      <th>Bar</th>\n      <th>Fri</th>\n      <th>Hyn</th>\n      <th>Pat</th>\n      <th>Price</th>\n      <th>Rain</th>\n      <th>Res</th>\n      <th>Type</th>\n      <th>Est</th>\n      <th>WillWait</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded = data.apply(le.fit_transform) # for all the attributes\n",
    "data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.152946400Z",
     "start_time": "2025-03-26T12:20:20.471607500Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf1 = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "x = data_encoded[data.columns.drop('WillWait')]\n",
    "y = data_encoded['WillWait']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.152946400Z",
     "start_time": "2025-03-26T12:20:20.481912500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    Alt  Bar  Fri  Hyn  Pat  Price  Rain  Res  Type  Est\n0     1    0    0    1    1      2     0    1     1    0\n1     1    0    0    1    0      0     0    0     3    2\n2     0    1    0    0    1      0     0    0     0    0\n3     1    0    1    1    0      0     1    0     3    1\n4     1    0    1    0    0      2     0    1     1    3\n..  ...  ...  ...  ...  ...    ...   ...  ...   ...  ...\n95    0    1    1    1    0      0     1    0     0    2\n96    1    1    1    0    0      1     0    0     0    3\n97    0    1    1    1    0      0     1    1     2    1\n98    1    0    0    0    2      1     1    0     3    0\n99    0    1    1    1    0      1     1    0     0    2\n\n[100 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Alt</th>\n      <th>Bar</th>\n      <th>Fri</th>\n      <th>Hyn</th>\n      <th>Pat</th>\n      <th>Price</th>\n      <th>Rain</th>\n      <th>Res</th>\n      <th>Type</th>\n      <th>Est</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.272933300Z",
     "start_time": "2025-03-26T12:20:20.524367100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 12.2.1 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"602pt\" height=\"598pt\"\n viewBox=\"0.00 0.00 601.50 598.25\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 594.25)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-594.25 597.5,-594.25 597.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"363.25,-590.25 254.25,-590.25 254.25,-519.25 363.25,-519.25 363.25,-590.25\"/>\n<text text-anchor=\"middle\" x=\"308.75\" y=\"-572.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Hyn &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"308.75\" y=\"-557.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"308.75\" y=\"-541.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100</text>\n<text text-anchor=\"middle\" x=\"308.75\" y=\"-525.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [51, 49]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"300,-483.25 189.5,-483.25 189.5,-412.25 300,-412.25 300,-483.25\"/>\n<text text-anchor=\"middle\" x=\"244.75\" y=\"-465.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Est &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"244.75\" y=\"-450.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.702</text>\n<text text-anchor=\"middle\" x=\"244.75\" y=\"-434.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 42</text>\n<text text-anchor=\"middle\" x=\"244.75\" y=\"-418.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [34, 8]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M287.44,-518.79C282.47,-510.64 277.12,-501.86 271.94,-493.36\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"274.95,-491.57 266.76,-484.85 268.97,-495.21 274.95,-491.57\"/>\n<text text-anchor=\"middle\" x=\"260.07\" y=\"-502.43\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"429,-483.25 318.5,-483.25 318.5,-412.25 429,-412.25 429,-483.25\"/>\n<text text-anchor=\"middle\" x=\"373.75\" y=\"-465.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Est &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"373.75\" y=\"-450.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.873</text>\n<text text-anchor=\"middle\" x=\"373.75\" y=\"-434.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 58</text>\n<text text-anchor=\"middle\" x=\"373.75\" y=\"-418.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 41]</text>\n</g>\n<!-- 0&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>0&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M330.39,-518.79C335.49,-510.55 340.99,-501.67 346.31,-493.08\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"349.12,-495.19 351.4,-484.85 343.16,-491.51 349.12,-495.19\"/>\n<text text-anchor=\"middle\" x=\"357.93\" y=\"-502.47\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"179,-376.25 68.5,-376.25 68.5,-305.25 179,-305.25 179,-376.25\"/>\n<text text-anchor=\"middle\" x=\"123.75\" y=\"-358.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pat &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"123.75\" y=\"-343.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.904</text>\n<text text-anchor=\"middle\" x=\"123.75\" y=\"-327.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 25</text>\n<text text-anchor=\"middle\" x=\"123.75\" y=\"-311.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 8]</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M204.46,-411.79C194.15,-402.84 182.96,-393.13 172.29,-383.87\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"174.86,-381.46 165.01,-377.55 170.27,-386.75 174.86,-381.46\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"298.5,-368.38 197,-368.38 197,-313.12 298.5,-313.12 298.5,-368.38\"/>\n<text text-anchor=\"middle\" x=\"247.75\" y=\"-351.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"247.75\" y=\"-335.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\n<text text-anchor=\"middle\" x=\"247.75\" y=\"-319.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 0]</text>\n</g>\n<!-- 1&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>1&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M245.75,-411.79C246.04,-401.56 246.36,-390.32 246.66,-379.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"250.15,-380.2 246.94,-370.1 243.16,-380 250.15,-380.2\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"127,-269.25 16.5,-269.25 16.5,-198.25 127,-198.25 127,-269.25\"/>\n<text text-anchor=\"middle\" x=\"71.75\" y=\"-251.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pat &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"71.75\" y=\"-236.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.985</text>\n<text text-anchor=\"middle\" x=\"71.75\" y=\"-220.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14</text>\n<text text-anchor=\"middle\" x=\"71.75\" y=\"-204.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 8]</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106.43,-304.79C102.44,-296.73 98.14,-288.05 93.98,-279.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"97.24,-278.33 89.66,-270.92 90.96,-281.43 97.24,-278.33\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"246.12,-261.38 145.38,-261.38 145.38,-206.12 246.12,-206.12 246.12,-261.38\"/>\n<text text-anchor=\"middle\" x=\"195.75\" y=\"-244.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"195.75\" y=\"-228.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"middle\" x=\"195.75\" y=\"-212.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 0]</text>\n</g>\n<!-- 2&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>2&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M147.72,-304.79C155.19,-293.9 163.44,-281.87 170.96,-270.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"173.72,-273.06 176.49,-262.84 167.95,-269.11 173.72,-273.06\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"95.5,-154.38 0,-154.38 0,-99.12 95.5,-99.12 95.5,-154.38\"/>\n<text text-anchor=\"middle\" x=\"47.75\" y=\"-137.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"47.75\" y=\"-121.33\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"47.75\" y=\"-105.58\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M63.76,-197.79C61.4,-187.45 58.8,-176.08 56.39,-165.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"59.86,-165.03 54.22,-156.07 53.04,-166.59 59.86,-165.03\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"224,-162.25 113.5,-162.25 113.5,-91.25 224,-91.25 224,-162.25\"/>\n<text text-anchor=\"middle\" x=\"168.75\" y=\"-144.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Type &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"168.75\" y=\"-129.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.845</text>\n<text text-anchor=\"middle\" x=\"168.75\" y=\"-113.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"middle\" x=\"168.75\" y=\"-97.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 8]</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M104.05,-197.79C111.98,-189.2 120.57,-179.9 128.82,-170.97\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"131.35,-173.39 135.56,-163.67 126.21,-168.64 131.35,-173.39\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"146.5,-55.25 51,-55.25 51,0 146.5,0 146.5,-55.25\"/>\n<text text-anchor=\"middle\" x=\"98.75\" y=\"-37.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"98.75\" y=\"-22.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"98.75\" y=\"-6.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 8]</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M143.68,-90.96C137.58,-82.5 131.04,-73.43 124.89,-64.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"127.73,-62.85 119.04,-56.78 122.05,-66.94 127.73,-62.85\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"260.5,-55.25 165,-55.25 165,0 260.5,0 260.5,-55.25\"/>\n<text text-anchor=\"middle\" x=\"212.75\" y=\"-37.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"212.75\" y=\"-22.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"212.75\" y=\"-6.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M184.51,-90.96C188.18,-82.86 192.1,-74.2 195.82,-66\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"198.99,-67.49 199.93,-56.93 192.61,-64.6 198.99,-67.49\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"422.5,-368.38 321,-368.38 321,-313.12 422.5,-313.12 422.5,-368.38\"/>\n<text text-anchor=\"middle\" x=\"371.75\" y=\"-351.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"371.75\" y=\"-335.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 24</text>\n<text text-anchor=\"middle\" x=\"371.75\" y=\"-319.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 24]</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M373.08,-411.79C372.89,-401.56 372.68,-390.32 372.48,-379.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"375.98,-380.03 372.29,-370.1 368.98,-380.17 375.98,-380.03\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"549.25,-376.25 440.25,-376.25 440.25,-305.25 549.25,-305.25 549.25,-376.25\"/>\n<text text-anchor=\"middle\" x=\"494.75\" y=\"-358.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Type &lt;= 1.0</text>\n<text text-anchor=\"middle\" x=\"494.75\" y=\"-343.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"494.75\" y=\"-327.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 34</text>\n<text text-anchor=\"middle\" x=\"494.75\" y=\"-311.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 17]</text>\n</g>\n<!-- 10&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>10&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M414.04,-411.79C424.35,-402.84 435.54,-393.13 446.21,-383.87\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"448.23,-386.75 453.49,-377.55 443.64,-381.46 448.23,-386.75\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"455.5,-261.38 360,-261.38 360,-206.12 455.5,-206.12 455.5,-261.38\"/>\n<text text-anchor=\"middle\" x=\"407.75\" y=\"-244.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"407.75\" y=\"-228.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"middle\" x=\"407.75\" y=\"-212.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 9]</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M465.78,-304.79C456.58,-293.68 446.39,-281.38 437.15,-270.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"440.03,-268.22 430.95,-262.76 434.64,-272.69 440.03,-268.22\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"584,-269.25 473.5,-269.25 473.5,-198.25 584,-198.25 584,-269.25\"/>\n<text text-anchor=\"middle\" x=\"528.75\" y=\"-251.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Res &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"528.75\" y=\"-236.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.904</text>\n<text text-anchor=\"middle\" x=\"528.75\" y=\"-220.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 25</text>\n<text text-anchor=\"middle\" x=\"528.75\" y=\"-204.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 8]</text>\n</g>\n<!-- 12&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>12&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M506.07,-304.79C508.59,-296.99 511.31,-288.62 513.95,-280.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"517.26,-281.59 517.01,-271 510.6,-279.44 517.26,-281.59\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"479.62,-162.25 381.88,-162.25 381.88,-91.25 479.62,-91.25 479.62,-162.25\"/>\n<text text-anchor=\"middle\" x=\"430.75\" y=\"-144.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Est &lt;= 1.5</text>\n<text text-anchor=\"middle\" x=\"430.75\" y=\"-129.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"430.75\" y=\"-113.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"middle\" x=\"430.75\" y=\"-97.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 8]</text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M496.12,-197.79C488.1,-189.2 479.42,-179.9 471.09,-170.97\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"473.65,-168.59 464.27,-163.67 468.54,-173.37 473.65,-168.59\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"593.5,-154.38 498,-154.38 498,-99.12 593.5,-99.12 593.5,-154.38\"/>\n<text text-anchor=\"middle\" x=\"545.75\" y=\"-137.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"545.75\" y=\"-121.33\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"middle\" x=\"545.75\" y=\"-105.58\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 0]</text>\n</g>\n<!-- 14&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>14&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"black\" d=\"M534.41,-197.79C536.07,-187.56 537.89,-176.32 539.57,-165.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"543.02,-166.51 541.16,-156.08 536.11,-165.4 543.02,-166.51\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"382.5,-55.25 287,-55.25 287,0 382.5,0 382.5,-55.25\"/>\n<text text-anchor=\"middle\" x=\"334.75\" y=\"-37.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"334.75\" y=\"-22.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"334.75\" y=\"-6.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 8]</text>\n</g>\n<!-- 15&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>15&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M396.36,-90.96C387.55,-82.04 378.07,-72.45 369.24,-63.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"371.95,-61.28 362.43,-56.63 366.97,-66.2 371.95,-61.28\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"496.5,-55.25 401,-55.25 401,0 496.5,0 496.5,-55.25\"/>\n<text text-anchor=\"middle\" x=\"448.75\" y=\"-37.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"448.75\" y=\"-22.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"448.75\" y=\"-6.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 0]</text>\n</g>\n<!-- 15&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>15&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"black\" d=\"M437.2,-90.96C438.65,-83.13 440.19,-74.79 441.67,-66.83\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"445.1,-67.51 443.48,-57.04 438.22,-66.24 445.1,-67.51\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": "<graphviz.sources.Source at 0x1f1fb0bb820>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(x,y)\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(clf1, out_file = None, feature_names= x.columns)\n",
    "graph1 = graphviz.Source(dot_data)\n",
    "graph1\n",
    "#graph.render(\"restaurant\") # save it to pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.398443200Z",
     "start_time": "2025-03-26T12:20:21.097690600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    Alt_No  Alt_Yes  Bar_No  Bar_Yes  Fri_No  Fri_Yes  Hyn_No  Hyn_Yes  \\\n0    False     True    True    False    True    False   False     True   \n1    False     True    True    False    True    False   False     True   \n2     True    False   False     True    True    False    True    False   \n3    False     True    True    False   False     True   False     True   \n4    False     True    True    False   False     True    True    False   \n..     ...      ...     ...      ...     ...      ...     ...      ...   \n95    True    False   False     True   False     True   False     True   \n96   False     True   False     True   False     True    True    False   \n97    True    False   False     True   False     True   False     True   \n98   False     True    True    False    True    False    True    False   \n99    True    False   False     True   False     True   False     True   \n\n    Pat_Full  Pat_Some  ...  Type_Burger  Type_French  Type_Italian  \\\n0      False      True  ...        False         True         False   \n1       True     False  ...        False        False         False   \n2      False      True  ...         True        False         False   \n3       True     False  ...        False        False         False   \n4       True     False  ...        False         True         False   \n..       ...       ...  ...          ...          ...           ...   \n95      True     False  ...         True        False         False   \n96      True     False  ...         True        False         False   \n97      True     False  ...        False        False          True   \n98     False     False  ...        False        False         False   \n99      True     False  ...         True        False         False   \n\n    Type_Thai  Est_0–10  Est_10–30  Est_30–60  Est_>60  WillWait_No  \\\n0       False      True      False      False    False        False   \n1        True     False      False       True    False         True   \n2       False      True      False      False    False        False   \n3        True     False       True      False    False        False   \n4       False     False      False      False     True         True   \n..        ...       ...        ...        ...      ...          ...   \n95      False     False      False       True    False        False   \n96      False     False      False      False     True         True   \n97      False     False       True      False    False         True   \n98       True      True      False      False    False         True   \n99      False     False      False       True    False        False   \n\n    WillWait_Yes  \n0           True  \n1          False  \n2           True  \n3           True  \n4          False  \n..           ...  \n95          True  \n96         False  \n97         False  \n98         False  \n99          True  \n\n[100 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Alt_No</th>\n      <th>Alt_Yes</th>\n      <th>Bar_No</th>\n      <th>Bar_Yes</th>\n      <th>Fri_No</th>\n      <th>Fri_Yes</th>\n      <th>Hyn_No</th>\n      <th>Hyn_Yes</th>\n      <th>Pat_Full</th>\n      <th>Pat_Some</th>\n      <th>...</th>\n      <th>Type_Burger</th>\n      <th>Type_French</th>\n      <th>Type_Italian</th>\n      <th>Type_Thai</th>\n      <th>Est_0–10</th>\n      <th>Est_10–30</th>\n      <th>Est_30–60</th>\n      <th>Est_&gt;60</th>\n      <th>WillWait_No</th>\n      <th>WillWait_Yes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 27 columns</p>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2 = pd.get_dummies(data, columns=data.columns) #one hot encoding\n",
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.430311600Z",
     "start_time": "2025-03-26T12:20:21.142761900Z"
    }
   },
   "outputs": [],
   "source": [
    "clf2 = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "x2 = data_2[data_2.columns.drop(['WillWait_No', 'WillWait_Yes'])]\n",
    "y2 = data_2['WillWait_Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:21.571173Z",
     "start_time": "2025-03-26T12:20:21.152946400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Alt_No  Alt_Yes  Bar_No  Bar_Yes  Fri_No  Fri_Yes  Hyn_No  Hyn_Yes  \\\n0   False     True    True    False    True    False   False     True   \n1   False     True    True    False    True    False   False     True   \n2    True    False   False     True    True    False    True    False   \n3   False     True    True    False   False     True   False     True   \n4   False     True    True    False   False     True    True    False   \n\n   Pat_Full  Pat_Some  ...  Res_No  Res_Yes  Type_Burger  Type_French  \\\n0     False      True  ...   False     True        False         True   \n1      True     False  ...    True    False        False        False   \n2     False      True  ...    True    False         True        False   \n3      True     False  ...    True    False        False        False   \n4      True     False  ...   False     True        False         True   \n\n   Type_Italian  Type_Thai  Est_0–10  Est_10–30  Est_30–60  Est_>60  \n0         False      False      True      False      False    False  \n1         False       True     False      False       True    False  \n2         False      False      True      False      False    False  \n3         False       True     False       True      False    False  \n4         False      False     False      False      False     True  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Alt_No</th>\n      <th>Alt_Yes</th>\n      <th>Bar_No</th>\n      <th>Bar_Yes</th>\n      <th>Fri_No</th>\n      <th>Fri_Yes</th>\n      <th>Hyn_No</th>\n      <th>Hyn_Yes</th>\n      <th>Pat_Full</th>\n      <th>Pat_Some</th>\n      <th>...</th>\n      <th>Res_No</th>\n      <th>Res_Yes</th>\n      <th>Type_Burger</th>\n      <th>Type_French</th>\n      <th>Type_Italian</th>\n      <th>Type_Thai</th>\n      <th>Est_0–10</th>\n      <th>Est_10–30</th>\n      <th>Est_30–60</th>\n      <th>Est_&gt;60</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.082465900Z",
     "start_time": "2025-03-26T12:20:21.197712900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 12.2.1 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"673pt\" height=\"598pt\"\n viewBox=\"0.00 0.00 672.50 598.25\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 594.25)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-594.25 668.5,-594.25 668.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"#fefaf7\" stroke=\"black\" points=\"425.25,-590.25 316.25,-590.25 316.25,-519.25 425.25,-519.25 425.25,-590.25\"/>\n<text text-anchor=\"middle\" x=\"370.75\" y=\"-572.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Hyn_No &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"370.75\" y=\"-557.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"370.75\" y=\"-541.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100</text>\n<text text-anchor=\"middle\" x=\"370.75\" y=\"-525.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [51, 49]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#8bc6f0\" stroke=\"black\" points=\"360.62,-483.25 244.88,-483.25 244.88,-412.25 360.62,-412.25 360.62,-483.25\"/>\n<text text-anchor=\"middle\" x=\"302.75\" y=\"-465.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Est_0–10 &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"302.75\" y=\"-450.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.873</text>\n<text text-anchor=\"middle\" x=\"302.75\" y=\"-434.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 58</text>\n<text text-anchor=\"middle\" x=\"302.75\" y=\"-418.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 41]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M348.11,-518.79C342.77,-510.55 337.02,-501.67 331.46,-493.08\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"334.49,-491.32 326.12,-484.83 328.61,-495.13 334.49,-491.32\"/>\n<text text-anchor=\"middle\" x=\"320.07\" y=\"-502.58\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"#eb9f68\" stroke=\"black\" points=\"501,-483.25 378.5,-483.25 378.5,-412.25 501,-412.25 501,-483.25\"/>\n<text text-anchor=\"middle\" x=\"439.75\" y=\"-465.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pat_Some &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"439.75\" y=\"-450.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.702</text>\n<text text-anchor=\"middle\" x=\"439.75\" y=\"-434.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 42</text>\n<text text-anchor=\"middle\" x=\"439.75\" y=\"-418.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [34, 8]</text>\n</g>\n<!-- 0&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>0&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M393.73,-518.79C399.14,-510.55 404.98,-501.67 410.62,-493.08\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"413.48,-495.1 416.04,-484.83 407.63,-491.26 413.48,-495.1\"/>\n<text text-anchor=\"middle\" x=\"421.94\" y=\"-502.62\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#ffffff\" stroke=\"black\" points=\"238.75,-376.25 102.75,-376.25 102.75,-305.25 238.75,-305.25 238.75,-376.25\"/>\n<text text-anchor=\"middle\" x=\"170.75\" y=\"-358.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Type_Burger &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"170.75\" y=\"-343.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"170.75\" y=\"-327.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 34</text>\n<text text-anchor=\"middle\" x=\"170.75\" y=\"-311.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 17]</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M258.8,-411.79C247.44,-402.75 235.1,-392.94 223.35,-383.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"225.7,-380.99 215.7,-377.5 221.34,-386.47 225.7,-380.99\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"358.5,-368.38 257,-368.38 257,-313.12 358.5,-313.12 358.5,-368.38\"/>\n<text text-anchor=\"middle\" x=\"307.75\" y=\"-351.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"307.75\" y=\"-335.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 24</text>\n<text text-anchor=\"middle\" x=\"307.75\" y=\"-319.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 24]</text>\n</g>\n<!-- 1&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>1&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M304.41,-411.79C304.9,-401.56 305.44,-390.32 305.93,-379.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"309.42,-380.26 306.4,-370.1 302.43,-379.92 309.42,-380.26\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"#f1bc96\" stroke=\"black\" points=\"166,-269.25 55.5,-269.25 55.5,-198.25 166,-198.25 166,-269.25\"/>\n<text text-anchor=\"middle\" x=\"110.75\" y=\"-251.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Res_No &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"110.75\" y=\"-236.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.904</text>\n<text text-anchor=\"middle\" x=\"110.75\" y=\"-220.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 25</text>\n<text text-anchor=\"middle\" x=\"110.75\" y=\"-204.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 8]</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M150.77,-304.79C146.12,-296.64 141.1,-287.86 136.24,-279.36\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"139.39,-277.82 131.39,-270.87 133.32,-281.29 139.39,-277.82\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"279.5,-261.38 184,-261.38 184,-206.12 279.5,-206.12 279.5,-261.38\"/>\n<text text-anchor=\"middle\" x=\"231.75\" y=\"-244.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"231.75\" y=\"-228.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"middle\" x=\"231.75\" y=\"-212.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 9]</text>\n</g>\n<!-- 2&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>2&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M191.06,-304.79C197.32,-294.01 204.23,-282.11 210.55,-271.23\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"213.4,-273.3 215.4,-262.9 207.35,-269.79 213.4,-273.3\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"95.5,-154.38 0,-154.38 0,-99.12 95.5,-99.12 95.5,-154.38\"/>\n<text text-anchor=\"middle\" x=\"47.75\" y=\"-137.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"47.75\" y=\"-121.33\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"middle\" x=\"47.75\" y=\"-105.58\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 0]</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M89.77,-197.79C83.3,-187.01 76.17,-175.11 69.64,-164.23\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"72.78,-162.66 64.63,-155.89 66.78,-166.26 72.78,-162.66\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"#ffffff\" stroke=\"black\" points=\"236.38,-162.25 113.12,-162.25 113.12,-91.25 236.38,-91.25 236.38,-162.25\"/>\n<text text-anchor=\"middle\" x=\"174.75\" y=\"-144.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Est_30–60 &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"174.75\" y=\"-129.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\n<text text-anchor=\"middle\" x=\"174.75\" y=\"-113.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"middle\" x=\"174.75\" y=\"-97.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 8]</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M132.06,-197.79C137.03,-189.64 142.38,-180.86 147.56,-172.36\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"150.53,-174.21 152.74,-163.85 144.55,-170.57 150.53,-174.21\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"165.5,-55.25 70,-55.25 70,0 165.5,0 165.5,-55.25\"/>\n<text text-anchor=\"middle\" x=\"117.75\" y=\"-37.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"117.75\" y=\"-22.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"117.75\" y=\"-6.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 8]</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154.33,-90.96C149.47,-82.68 144.27,-73.81 139.36,-65.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"142.4,-63.71 134.32,-56.86 136.36,-67.26 142.4,-63.71\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"279.5,-55.25 184,-55.25 184,0 279.5,0 279.5,-55.25\"/>\n<text text-anchor=\"middle\" x=\"231.75\" y=\"-37.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"231.75\" y=\"-22.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"231.75\" y=\"-6.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 0]</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M195.17,-90.96C200.03,-82.68 205.23,-73.81 210.14,-65.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"213.14,-67.26 215.18,-56.86 207.1,-63.71 213.14,-67.26\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"486.5,-368.38 385,-368.38 385,-313.12 486.5,-313.12 486.5,-368.38\"/>\n<text text-anchor=\"middle\" x=\"435.75\" y=\"-351.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"435.75\" y=\"-335.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 31</text>\n<text text-anchor=\"middle\" x=\"435.75\" y=\"-319.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 0]</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M438.42,-411.79C438.03,-401.56 437.6,-390.32 437.2,-379.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"440.71,-379.96 436.83,-370.1 433.71,-380.23 440.71,-379.96\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"#83c2ef\" stroke=\"black\" points=\"615,-376.25 504.5,-376.25 504.5,-305.25 615,-305.25 615,-376.25\"/>\n<text text-anchor=\"middle\" x=\"559.75\" y=\"-358.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Bar_No &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"559.75\" y=\"-343.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.845</text>\n<text text-anchor=\"middle\" x=\"559.75\" y=\"-327.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"middle\" x=\"559.75\" y=\"-311.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 8]</text>\n</g>\n<!-- 10&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>10&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M479.71,-411.79C489.93,-402.84 501.03,-393.13 511.61,-383.87\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"513.61,-386.78 518.83,-377.56 509,-381.51 513.61,-386.78\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"#399de5\" stroke=\"black\" points=\"550.5,-261.38 455,-261.38 455,-206.12 550.5,-206.12 550.5,-261.38\"/>\n<text text-anchor=\"middle\" x=\"502.75\" y=\"-244.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"502.75\" y=\"-228.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"middle\" x=\"502.75\" y=\"-212.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 8]</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M540.77,-304.79C534.98,-294.12 528.59,-282.36 522.74,-271.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"525.89,-270.04 518.04,-262.92 519.74,-273.38 525.89,-270.04\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"#e58139\" stroke=\"black\" points=\"664.5,-261.38 569,-261.38 569,-206.12 664.5,-206.12 664.5,-261.38\"/>\n<text text-anchor=\"middle\" x=\"616.75\" y=\"-244.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"616.75\" y=\"-228.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"middle\" x=\"616.75\" y=\"-212.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 12&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>12&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M578.73,-304.79C584.52,-294.12 590.91,-282.36 596.76,-271.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"599.76,-273.38 601.46,-262.92 593.61,-270.04 599.76,-273.38\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": "<graphviz.sources.Source at 0x1f1fb9405f0>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(x2,y2)\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(clf2, out_file = None, feature_names=x2.columns,  \n",
    "                         filled=True)\n",
    "graph2 = graphviz.Source(dot_data)\n",
    "graph2\n",
    "#graph.render(\"restaurant2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.082465900Z",
     "start_time": "2025-03-26T12:20:21.805604800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gogac\\anaconda3\\envs\\lab04\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([1])"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict \n",
    "my_test=[1,0,0,1,0,2,0,1,1,0]\n",
    "clf1.predict([my_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.082465900Z",
     "start_time": "2025-03-26T12:20:21.809738900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gogac\\anaconda3\\envs\\lab04\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0., 1.]])"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.predict_proba([my_test]) #change the example and see the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.082465900Z",
     "start_time": "2025-03-26T12:20:21.825899100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.122526800Z",
     "start_time": "2025-03-26T12:20:21.848917100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([1.  , 0.94])"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#or use cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(clf1, x,y,cv=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with pandas frame in order to compute InfoGain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.122526800Z",
     "start_time": "2025-03-26T12:20:21.904785800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0     Some\n1     Full\n2     Some\n3     Full\n4     Full\n      ... \n95    Full\n96    Full\n97    Full\n98     NaN\n99    Full\nName: Pat, Length: 100, dtype: object"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Pat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.122526800Z",
     "start_time": "2025-03-26T12:20:21.918347400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Alt  Bar  Fri  Hyn  Price  Rain  Res  Type  Est  WillWait\n",
      "Pat                                                            \n",
      "Full   43   43   43   43     43    43   43    43   43        43\n",
      "Some   25   25   25   25     25    25   25    25   25        25\n"
     ]
    },
    {
     "data": {
      "text/plain": "WillWait\nNo     30\nYes    13\nName: count, dtype: int64"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no, yes = data['WillWait'].value_counts() #how many examples have WillWait='No', respectively Yes\n",
    "print(data.groupby('Pat').count())\n",
    "res = data['WillWait'][data['Pat']=='Full'].value_counts()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.122526800Z",
     "start_time": "2025-03-26T12:20:21.939862800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.0"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "def B(probs):\n",
    "    return sum([-p*log(p,2) for p in probs if p>0])\n",
    "B([1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.122526800Z",
     "start_time": "2025-03-26T12:20:21.952754300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.9997114417528099"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B([no/(no+yes), yes/(no+yes)]) #entropy for WillWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:20:22.122526800Z",
     "start_time": "2025-03-26T12:20:21.966622900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Pat\nFull    43\nSome    25\nName: count, dtype: int64"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def remainder(attrib):\n",
    "data['Pat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T12:22:32.341439900Z",
     "start_time": "2025-03-26T12:22:32.294314900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 51\n",
      "Value of the attribute:  Some\n",
      "WillWait\n",
      "Yes    22\n",
      "No      3\n",
      "Name: count, dtype: int64\n",
      "pozitive and negative number of examples: 22 3\n",
      "Value of the attribute:  Full\n",
      "WillWait\n",
      "No     30\n",
      "Yes    13\n",
      "Name: count, dtype: int64\n",
      "pozitive and negative number of examples: 13 30\n"
     ]
    },
    {
     "data": {
      "text/plain": "np.float64(0.4872017229499642)"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remainder=0\n",
    "attrib='Pat'\n",
    "p=data['WillWait'].value_counts()['Yes']\n",
    "n=data['WillWait'].value_counts()['No']\n",
    "print(p,n)\n",
    "values = np.delete(data[attrib].unique(), 2, 0)\n",
    "for v in values:\n",
    "    print(\"Value of the attribute: \", v)\n",
    "    no_examples = data['WillWait'][data[attrib]==v].value_counts()\n",
    "    print(no_examples)\n",
    "    nk=0\n",
    "    pk=0\n",
    "    if 'No' in no_examples.keys().tolist():\n",
    "        nk=no_examples['No']\n",
    "    if 'Yes' in no_examples.keys().tolist():\n",
    "        pk=no_examples['Yes']\n",
    "    print(\"pozitive and negative number of examples:\", pk,nk)\n",
    "    remainder+=(pk+nk)/(p+n) * B([pk/(pk+nk), nk/(pk+nk)])\n",
    "infoGain = B([n/(n+p), p/(n+p)])-remainder\n",
    "\n",
    "infoGain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn: Apply DecisionTree on the iris dataset.\n",
    "1. Load iris dataset\n",
    "2. see the content of the loaded data\n",
    "3. Identify the classes (target names) & feature names\n",
    "4. View the first 5 examples\n",
    "5. Apply decision tree on the entire dataset\n",
    "6. View the resulting tree\n",
    "7. Predict the result for the flowers with the following characteristics: 4.7 3.3  1.3  0.2 and 5 1.2  3.3  2.2\n",
    "8. Measure accuracy over the entire dataset (use \"accuracy_score\"from sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-26T12:20:21.996218400Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris\n",
    "from sklearn.datasets import load_iris\n",
    "data=load_iris()\n",
    "data #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-26T12:20:21.996218400Z"
    }
   },
   "outputs": [],
   "source": [
    "#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-26T12:20:22.005231400Z"
    }
   },
   "outputs": [],
   "source": [
    "#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-26T12:20:22.005231400Z"
    }
   },
   "outputs": [],
   "source": [
    "#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-26T12:20:22.005231400Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import tree #5\n",
    "clf_your = \"todo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-26T12:20:22.005231400Z"
    }
   },
   "outputs": [],
   "source": [
    "import graphviz  #6\n",
    "dot_data = tree.export_graphviz(clf_your, out_file = None, feature_names=data.feature_names,  \n",
    "                         filled=True)\n",
    "graph2 = graphviz.Source(dot_data)\n",
    "graph2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-26T12:20:22.020882500Z"
    }
   },
   "outputs": [],
   "source": [
    "my_test=[] #7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-26T12:20:22.020882500Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score #8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5.3 XOR Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "# Create the XOR truth table\n",
    "data = {\n",
    "    'X1': [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "    'X2': [0, 0, 1, 1, 0, 0, 1, 1],\n",
    "    'X3': [0, 1, 0, 1, 0, 1, 0, 1],\n",
    "    'Y':  [0, 1, 1, 0, 1, 0, 0, 1]\n",
    "}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5.4 Learning curve"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "# Generate a dataset of 100 random examples\n",
    "random.seed(42)  # for reproducibility\n",
    "num_examples = 100\n",
    "# Define possible values for each column\n",
    "attributes = {\n",
    "    'Alt': ['Yes', 'No'],\n",
    "    'Bar': ['Yes', 'No'],\n",
    "    'Fri': ['Yes', 'No'],\n",
    "    'Hyn': ['Yes', 'No'],\n",
    "    'Pat': ['Some', 'Full', 'None'],\n",
    "    'Price': ['$', '$$', '$$$'],\n",
    "    'Rain': ['Yes', 'No'],\n",
    "    'Res': ['Yes', 'No'],\n",
    "    'Type': ['French', 'Thai', 'Burger', 'Italian'],\n",
    "    'Est': ['0–10', '10–30', '30–60', '>60']\n",
    "}\n",
    "\n",
    "# Generate unique rows\n",
    "rows = []\n",
    "cnt = 0\n",
    "while cnt < num_examples:\n",
    "    row = {col: random.choice(attributes[col]) for col in attributes}\n",
    "    if row not in rows:  # Ensure uniqueness\n",
    "        rows.append(row)\n",
    "        cnt += 1\n",
    "\n",
    "for row in rows:\n",
    "    row['WillWait'] = random.choice(['Yes', 'No'])\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5.5 Overfitting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "attributes = {\n",
    "    'Alt': ['Yes', 'No'],\n",
    "    'Bar': ['Yes', 'No'],\n",
    "    'Fri': ['Yes', 'No'],\n",
    "    'Hyn': ['Yes', 'No'],\n",
    "    'Pat': ['Some', 'Full', 'None'],\n",
    "    'Price': ['$', '$$', '$$$'],\n",
    "    'Rain': ['Yes', 'No'],\n",
    "    'Res': ['Yes', 'No'],\n",
    "    'Type': ['French', 'Thai', 'Burger', 'Italian'],\n",
    "    'Est': ['0–10', '10–30', '30–60', '>60']\n",
    "}\n",
    "num_examples=900\n",
    "# Generate unique rows\n",
    "rows = []\n",
    "cnt = 0\n",
    "while cnt < num_examples:\n",
    "    row = {col: random.choice(attributes[col]) for col in attributes}\n",
    "    if row not in rows:  # Ensure uniqueness\n",
    "        rows.append(row)\n",
    "        cnt += 1\n",
    "\n",
    "for row in rows:\n",
    "    row['WillWait'] = random.choice(['Yes', 'No'])\n",
    "\n",
    "tree_depths = range(1,21)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}




lab-05/restaurant.csv
		Alt		Bar		Fri		Hyn		Pat		Price		Rain		Res		Type		Est		WillWait

		Yes		No		No		Yes		Some		$$$		No		Yes		French		0–10		Yes

		Yes		No		No		Yes		Full		$		No		No		Thai		30–60		No

		No		Yes		No		No		Some		$		No		No		Burger		0–10		Yes

		Yes		No		Yes		Yes		Full		$		Yes		No		Thai		10–30		Yes

		Yes		No		Yes		No		Full		$$$		No		Yes		French		>60		No

		No		Yes		No		Yes		Some		$$		Yes		Yes		Italian		0–10		Yes

		No		Yes		No		No		None		$		Yes		No		Burger		0–10		No

		No		No		No		Yes		Some		$$		Yes		Yes		Thai		0–10		Yes

		No		Yes		Yes		No		Full		$		Yes		No		Burger		>60		No

		Yes		Yes		Yes		Yes		Full		$$$		No		Yes		Italian		10–30		No

		No		No		No		No		None		$		No		No		Thai		0–10		No

		Yes		Yes		Yes		Yes		Full		$		No		No		Burger		30–60		Yes

		Yes		No		No		Yes		Some		$$$		Yes		Yes		French		0–10		Yes

		Yes		No		No		Yes		Full		$		Yes		No		Thai		30–60		No

		No		Yes		No		No		Some		$		Yes		No		Burger		0–10		Yes

		Yes		No		Yes		Yes		Full		$		No		No		Thai		10–30		Yes

		Yes		No		Yes		No		Full		$$$		Yes		Yes		French		>60		No

		No		Yes		No		Yes		Some		$$		No		Yes		Italian		0–10		Yes

		No		Yes		No		No		None		$		No		No		Burger		0–10		No

		No		No		No		Yes		Some		$$		No		Yes		Thai		0–10		Yes

		No		Yes		Yes		No		Full		$		No		No		Burger		>60		No

		Yes		Yes		Yes		Yes		Full		$$$		Yes		Yes		Italian		10–30		No

		No		No		No		No		None		$		Yes		No		Thai		0–10		No

		Yes		Yes		Yes		Yes		Full		$		Yes		No		Burger		30–60		Yes

		No		No		No		Yes		Some		$$$		No		Yes		French		0–10		Yes

		No		No		No		Yes		Full		$		No		No		Thai		30–60		No

		Yes		Yes		No		No		Some		$		No		No		Burger		0–10		Yes

		No		No		Yes		Yes		Full		$		Yes		No		Thai		10–30		Yes

		No		No		Yes		No		Full		$$$		No		Yes		French		>60		No

		Yes		Yes		No		Yes		Some		$$		Yes		Yes		Italian		0–10		Yes

		Yes		Yes		No		No		None		$		Yes		No		Burger		0–10		No

		Yes		No		No		Yes		Some		$$		Yes		Yes		Thai		0–10		Yes

		Yes		Yes		Yes		No		Full		$		Yes		No		Burger		>60		No

		No		Yes		Yes		Yes		Full		$$$		No		Yes		Italian		10–30		No

		Yes		No		No		No		None		$		No		No		Thai		0–10		No

		No		Yes		Yes		Yes		Full		$		No		No		Burger		30–60		Yes

		No		No		No		Yes		Some		$$$		Yes		Yes		French		0–10		Yes

		No		No		No		Yes		Full		$		Yes		No		Thai		30–60		No

		Yes		Yes		No		No		Some		$		Yes		No		Burger		0–10		Yes

		No		No		Yes		Yes		Full		$		No		No		Thai		10–30		Yes

		No		No		Yes		No		Full		$$$		Yes		Yes		French		>60		No

		Yes		Yes		No		Yes		Some		$$		No		Yes		Italian		0–10		Yes

		Yes		Yes		No		No		None		$		No		No		Burger		0–10		No

		Yes		No		No		Yes		Some		$$		No		Yes		Thai		0–10		Yes

		Yes		Yes		Yes		No		Full		$		No		No		Burger		>60		No

		No		Yes		Yes		Yes		Full		$$$		Yes		Yes		Italian		10–30		No

		Yes		No		No		No		None		$		Yes		No		Thai		0–10		No

		No		Yes		Yes		Yes		Full		$		Yes		No		Burger		30–60		Yes

		Yes		No		No		Yes		None		$$$		No		Yes		French		0–10		Yes

		Yes		No		No		Yes		None		$		No		No		Thai		30–60		No

		No		Yes		No		No		Some		$		No		No		Burger		0–10		Yes

		Yes		No		Yes		Yes		None		$		Yes		No		Thai		10–30		Yes

		Yes		No		Yes		No		Full		$$$		No		Yes		French		>60		No

		No		Yes		No		Yes		None		$$		Yes		Yes		Italian		0–10		Yes

		No		Yes		No		No		Full		$		Yes		No		Burger		0–10		No

		No		No		No		Yes		None		$$		Yes		Yes		Thai		0–10		Yes

		No		Yes		Yes		No		None		$		Yes		No		Burger		>60		No

		Yes		Yes		Yes		Yes		Full		$$$		No		Yes		Italian		10–30		No

		No		No		No		No		Some		$		No		No		Thai		0–10		No

		Yes		Yes		Yes		Yes		Full		$		No		No		Burger		30–60		Yes

		Yes		No		No		Yes		None		$$$		Yes		Yes		French		0–10		Yes

		Yes		No		No		Yes		None		$		Yes		No		Thai		30–60		No

		No		Yes		No		No		Some		$		Yes		No		Burger		0–10		Yes

		Yes		No		Yes		Yes		None		$		No		No		Thai		10–30		Yes

		Yes		No		Yes		No		Full		$$$		Yes		Yes		French		>60		No

		No		Yes		No		Yes		None		$$		No		Yes		Italian		0–10		Yes

		No		Yes		No		No		Full		$		No		No		Burger		0–10		No

		No		No		No		Yes		None		$$		No		Yes		Thai		0–10		Yes

		No		Yes		Yes		No		None		$		No		No		Burger		>60		No

		Yes		Yes		Yes		Yes		Full		$$$		Yes		Yes		Italian		10–30		No

		No		No		No		No		Some		$		Yes		No		Thai		0–10		No

		Yes		Yes		Yes		Yes		Full		$		Yes		No		Burger		30–60		Yes

		No		No		No		Yes		None		$$$		No		Yes		French		0–10		Yes

		No		No		No		Yes		None		$		No		No		Thai		30–60		No

		Yes		Yes		No		No		Some		$		No		No		Burger		0–10		Yes

		No		No		Yes		Yes		None		$		Yes		No		Thai		10–30		Yes

		No		No		Yes		No		Full		$$$		No		Yes		French		>60		No

		Yes		Yes		No		Yes		None		$$		Yes		Yes		Italian		0–10		Yes

		Yes		Yes		No		No		Full		$		Yes		No		Burger		0–10		No

		Yes		No		No		Yes		None		$$		Yes		Yes		Thai		0–10		Yes

		Yes		Yes		Yes		No		None		$		Yes		No		Burger		>60		No

		No		Yes		Yes		Yes		Full		$$$		No		Yes		Italian		10–30		No

		Yes		No		No		No		Some		$		No		No		Thai		0–10		No

		No		Yes		Yes		Yes		Full		$		No		No		Burger		30–60		Yes

		No		No		No		Yes		None		$$$		Yes		Yes		French		0–10		Yes

		No		No		No		Yes		None		$		Yes		No		Thai		30–60		No

		Yes		Yes		No		No		Some		$		Yes		No		Burger		0–10		Yes

		No		No		Yes		Yes		None		$		No		No		Thai		10–30		Yes

		No		No		Yes		No		Full		$$$		Yes		Yes		French		>60		No

		Yes		Yes		No		Yes		Some		$$		No		Yes		Italian		0–10		Yes

		Yes		Yes		No		No		None		$		No		No		Burger		0–10		No

		Yes		No		No		Yes		Some		$$		No		Yes		Thai		0–10		Yes

		Yes		Yes		Yes		No		Full		$		No		No		Burger		>60		No

		No		Yes		Yes		Yes		Full		$$$		Yes		Yes		Italian		10–30		No

		Yes		No		No		No		None		$		Yes		No		Thai		0–10		No

		No		Yes		Yes		Yes		Full		$		Yes		No		Burger		30–60		Yes

		Yes		Yes		Yes		No		Full		$$		No		No		Burger		>60		No

		No		Yes		Yes		Yes		Full		$		Yes		Yes		Italian		10–30		No

		Yes		No		No		No		None		$$		Yes		No		Thai		0–10		No

		No		Yes		Yes		Yes		Full		$$		Yes		No		Burger		30–60		Yes





reading content from D:\SD\SearchEngine_ver1\See\labeling_images.zip


crosses.bmp


diagonal.bmp


disks.bmp


letters.bmp


shapes.bmp


text_binary.bmp


reading content from D:\SD\SearchEngine_ver1\See\Laborator 8 FLT (ro).pdf


Laborator 8 

Interpretarea arborilor binari în Haskell/ML 

 

Laboratorul 8 constă în crearea unui analizor lexico-sintactic pentru procesarea arborilor 

binari de căutare în sintaxă Haskell și, comparativ, în sintaxă ML. Partea de ML va apărea pe 

fundal color (albastru), iar pentru implementare vom merge pe una dintre cele două sintaxe. Vom 

avea în vedere citirea arborilor și executarea unor operații pe arbori: insert (inserarea unui nod 

într-un arbore) și count (contorizarea nodurilor, diferite de frunzele vide Lf, dintr-un arbore). 

Exemple de input în Haskell: 

 

Exemple de input în ML: 

 

După cum se poate observa în exemple, sintaxa Haskell a unui arbore binar este 

următoarea:  

Iar sintaxa ML a unui arbore binar este: 

  

Node Lf 2 Lf 
> Node Lf 2 Lf 

Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf) 
> Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf) 

count (insert 16 (Node (Node Lf 2 Lf) 15 Lf)) 
> 3 

insert (count (Node Lf 17 (Node Lf 24 Lf))) (insert 12 (Node Lf 10 Lf)) 
> Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf) 

Node(2, Lf, Lf) 
> Node(2, Lf, Lf) 

Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf)) 
> Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf)) 

count(insert(16, Node(15, Node(2, Lf, Lf), Lf))) 
> 3 

insert(count(Node(17, Lf, Node(24, Lf, Lf))), insert(12, Node(10, Lf, Lf))) 
> Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf)) 

Node (Tree Int) Int (Tree Int) 

Node (int, int Tree, int Tree) 

 



Să luăm ca exemplu arborele binar din imaginea următoare: 

 

Reprezentarea arborelui în sintaxă Haskell este următoarea: 

 

Iar reprezentarea în sintaxă ML este: 

 

Pentru a reprezenta în memorie arborii binari de căutare, vom crea o structură cu trei 

câmpuri: unul pentru cheia nodului (de tip int) și două pentru fiii nodului (pointeri la subarborele 

stâng și la subarborele drept).  

 

Pe stiva de valori vor coexista două tipuri: int, pentru numerele citite din input și pentru 

cheile nodurilor, și o structură de tip arbore, pentru a reduce numerele din input la arbori în 

forma potrivită (reducând partea dreaptă a producțiilor la partea stângă). Astfel, yylval va fi un 

union cu două câmpuri: 

 

În ceea ce privește setul de producții, vom avea un set de reguli (expr) care descriu 
inputul. Putem separa instrucțiunile din input în două categorii, în funcție de tipul rezultatului. 
Citirile arborilor și comanda insert vor returna arbori, în vreme ce comanda count returnează un 

Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf) 

Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf)) 

typedef struct _node { 

int key; 

 struct _node *left, *right;  

} node; 

%union { 

 int ival; 

 struct _node *btree; 

} 



număr întreg. Astfel, reies alte două seturi de reguli, unul pentru situațiile din care rezultă un 
arbore (t_expr) și unul pentru cele din care rezultă numere întregi (i_expr). Cel mai important set 
de reguli este cel care descrie construirea unui arbore binar (tree), cu ajutorul celor doi 
constructori de date Haskell/ML pentru arbori binari: constructorul Node cu trei argumente și 
constructorul Lf cu zero argumente. 

 Setul de producții pentru sintaxă Haskell:

 

Setul de producții pentru sintaxă ML: 

 

  

expr : i_expr 

     | t_expr 

     ; 

i_expr : COUNT t_expr 

  |'(' i_expr ')' 

  | NUMBER 

  ; 

t_expr : INSERT i_expr t_expr 

       | '(' t_expr ')' 

       | tree 

       ; 

tree : NODE tree NUMBER tree 

     | '(' tree ')'    

     | LF    

     ; 

expr : i_expr 

     | t_expr 

     ; 

i_expr : COUNT '(' t_expr ')' 

  | NUMBER 

  ; 

t_expr : INSERT '(' i_expr ',' t_expr ')' 

       | tree 

       ; 

tree : NODE '(' NUMBER ',' tree ',' tree ')' 

     | LF    

     ; 



Exerciții propuse: 

1. Implementați o funcție pentru căutarea unui nod într-un arbore.  

Exemple în Haskell: 

find 12 (Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf)) 
> true 
find 17 (Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf)) 
> false 

Exemple în ML: 

 

2. Implementați o funcție pentru ștergerea unui nod dintr-un arbore. Verificați întâi dacă 

nodul căutat există în arbore.  

Exemplu în Haskell: 

delete 12 (Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf)) 
> Node (Node Lf 2 Lf) 10 Lf 

Exemplu în ML: 

 
 

3. Creați o funcție pentru a verifica dacă un arbore binar este echilibrat.  

Exemple în Haskell: 

balanced (Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf)) 
> true 
balanced (Node (Node Lf 2 Lf) 10 Lf) 
> false 

Exemple în ML: 

 

find(12, Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf))) 
> true 
find(17, Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf))) 
> false 

 

delete(12, Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf))) 
> Node(10, Node(2, Lf, Lf), Lf) 

balanced(Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf))) 
> true 
balanced(Node(10, Node(2, Lf, Lf), Lf)) 
> false 



reading content from D:\SD\SearchEngine_ver1\See\Letter of Intent.pdf


Letter of Intent 

For Participation in the MHP Internship 

I, Braica Patricia Maria, am a third-year student at the Faculty of Automation and Computers, within the 

Technical University of Cluj-Napoca, specializing in Computer Science and Information Technology in 

English. I wish to apply for the MHP internship in Cluj-Napoca. 

I would like to bring to your attention the reasons why I believe I am a strong candidate for this project. 

Firstly, I aim to bring innovation and contribute to improving the results of MHP. I feel well-prepared to 

engage in the complex field of Java programming. My qualifications are supported by the excellent 

results I have achieved in relevant subjects throughout my three years of study. 

Secondly, I want to develop my practical skills in the technical field, particularly in software solutions 

implementation. I believe this project will provide me with the opportunity to learn from professionals 

and apply theoretical knowledge in practice. I am highly motivated by the chance to work in an 

interdisciplinary team and contribute to the development of a real-world project. 

It is essential to mention that I have already worked with this type of technology in Web Development 

during the “Software Engineering” course, where I developed a project on restaurant recommendation 

systems using Google Location and Weather APIs, implemented with Java Spring Boot. 

Additionally, I have completed the "Object-Oriented Programming (OOP) in Java and C++" course, where 

I worked on a mandatory project that strengthened my knowledge of OOP-based application 

development. 

The "SQL Programming" course provided me with fundamental skills in database management, which 

are crucial for any project involving data storage and manipulation. 

Throughout my studies, I have taken relevant courses that have equipped me with essential skills in 

computer science and applied technologies. For example, through the "Fundamental Algorithms and 

Data Structures in C" course, I learned efficient programming techniques for developing high-

performance solutions. 

During the "AI Technologies in Python" course, my teammates and I implemented complex AI solutions 

such as theorem proving and the DPLL algorithm. 

My objectives are to expand my experience in advanced technologies, particularly in web development, 

while remaining open to exploring other IT specializations. Through this project, I wish to gain insight 

into different fields where I can contribute and discover what best suits my skills and interests. My goal 

is to acquire valuable knowledge and experiment with various types of projects to eventually become an 

expert in a specific domain or position, based on the skills and passions I develop along the way. 

If you consider that my motivation and expertise make me a suitable candidate for this project, I am 

available for an interview with the selection committee. Thank you for your time and consideration. 

Sincerely, 

Braica Patricia Maria 



reading content from D:\SD\SearchEngine_ver1\See\Letter of IntentEng.docx

Letter of Intent
For Participation in the MHP Internship
I, Braica Patricia Maria, am a third-year student at the Faculty of Automation and Computers, within the Technical University of Cluj-Napoca, specializing in Computer Science and Information Technology in English. I wish to apply for the MHP internship in Cluj-Napoca.
I would like to bring to your attention the reasons why I believe I am a strong candidate for this project.
Firstly, I aim to bring innovation and contribute to improving the results of MHP. I feel well-prepared to engage in the complex field of Java programming. My qualifications are supported by the excellent results I have achieved in relevant subjects throughout my three years of study.
Secondly, I want to develop my practical skills in the technical field, particularly in software solutions implementation. I believe this project will provide me with the opportunity to learn from professionals and apply theoretical knowledge in practice. I am highly motivated by the chance to work in an interdisciplinary team and contribute to the development of a real-world project.
It is essential to mention that I have already worked with this type of technology in Web Development during the “Software Engineering” course, where I developed a project on restaurant recommendation systems using Google Location and Weather APIs, implemented with Java Spring Boot.
Additionally, I have completed the "Object-Oriented Programming (OOP) in Java and C++" course, where I worked on a mandatory project that strengthened my knowledge of OOP-based application development.
The "SQL Programming" course provided me with fundamental skills in database management, which are crucial for any project involving data storage and manipulation.
Throughout my studies, I have taken relevant courses that have equipped me with essential skills in computer science and applied technologies. For example, through the "Fundamental Algorithms and Data Structures in C" course, I learned efficient programming techniques for developing high-performance solutions.
During the "AI Technologies in Python" course, my teammates and I implemented complex AI solutions such as theorem proving and the DPLL algorithm.
My objectives are to expand my experience in advanced technologies, particularly in web development, while remaining open to exploring other IT specializations. Through this project, I wish to gain insight into different fields where I can contribute and discover what best suits my skills and interests. My goal is to acquire valuable knowledge and experiment with various types of projects to eventually become an expert in a specific domain or position, based on the skills and passions I develop along the way.
If you consider that my motivation and expertise make me a suitable candidate for this project, I am available for an interview with the selection committee. Thank you for your time and consideration.
Sincerely,
Braica Patricia Maria

reading content from D:\SD\SearchEngine_ver1\See\lisp.l

/* lisp.l - Analizor lexical pentru microinterpretorul Lisp */
%{
#include "y.tab.h"
%}

%%
\s+                 ; /* Ignoră spațiile albe */
\(                  return '(';
\)                  return ')';
CONS                return CONS;
CAR                 return CAR;
CDR                 return CDR;
APPEND              return APPEND;
[0-9]+              { yylval.ival = atoi(yytext); return NUMBER; }
\'\([0-9 ]+\)      { yylval.sval = strdup(yytext); return LIST; }
.                   ;
%%

int yywrap() { return 1; }



reading content from D:\SD\SearchEngine_ver1\See\lisp.y

/* lisp.y - Analizor sintactic pentru microinterpretorul Lisp */
%{
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

typedef struct list {
    int value;
    struct list *next;
} list;

list *cons(int val, list *lst) {
    list *node = (list *)malloc(sizeof(list));
    node->value = val;
    node->next = lst;
    return node;
}

int car(list *lst) { return lst ? lst->value : 0; }
list *cdr(list *lst) { return lst ? lst->next : NULL; }
list *append(list *l1, list *l2) {
    if (!l1) return l2;
    list *head = l1;
    while (l1->next) l1 = l1->next;
    l1->next = l2;
    return head;
}

void print_list(list *lst) {
    printf("(");
    while (lst) {
        printf("%d ", lst->value);
        lst = lst->next;
    }
    printf(")\n");
}
%}

%union {
    int ival;
    list *lst;
}

%token <ival> NUMBER
%token CONS CAR CDR APPEND
%type <lst> form i_form l_form enum

%%
form: i_form  { $$ = $1; print_list($$); }
    | l_form  { $$ = $1; print_list($$); }
    ;

i_form: '(' i_command ')' { $$ = $2; }
      | NUMBER { $$ = cons($1, NULL); }
      ;

l_form: '(' l_command ')' { $$ = $2; }
      | enum ')' { $$ = $1; }
      ;

i_command: CAR l_form { $$ = cons(car($2), NULL); }
         | '+' form i_form { $$ = cons(car($2) + car($3), NULL); }
         ;

l_command: CDR l_form { $$ = cdr($2); }
         | CONS i_form l_form { $$ = cons(car($2), $3); }
         | APPEND l_form l_form { $$ = append($2, $3); }
         ;

enum: NUMBER enum { $$ = cons($1, $2); }
     | NUMBER { $$ = cons($1, NULL); }
     ;

file: file form '\n' | file '\n' | /* empty */ ;
%%

int main() {
    yyparse();
    return 0;
}

void yyerror(const char *msg) {
    fprintf(stderr, "Error: %s\n", msg);
}


reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (1).pdf


 

 
Abstract—Music has always been an integral part of human’s 

daily lives. But, for the most people, reading musical score and turning 
it into melody is not easy. This study aims to develop an Automatic 
music score recognition system using digital image processing, which 
can be used to read and analyze musical score images automatically. 
The technical approaches included: (1) staff region segmentation; (2) 
image preprocessing; (3) note recognition; and (4) accidental and rest 
recognition. Digital image processing techniques (e.g., horizontal 
/vertical projections, connected component labeling, morphological 
processing, template matching, etc.) were applied according to 
musical notes, accidents, and rests in staff notations. Preliminary 
results showed that our system could achieve detection and 
recognition rates of 96.3% and 91.7%, respectively. In conclusion, we 
presented an effective automated musical score recognition system 
that could be integrated in a system with a media player to play 
music/songs given input images of musical score. Ultimately, this 
system could also be incorporated in applications for mobile devices as 
a learning tool, such that a music player could learn to play 
music/songs. 
 

Keywords—Connected component labeling, image processing, 
morphological processing, optical musical recognition.  

I. INTRODUCTION 

ITH the advance of image processing and computer 
vision techniques in recent years, the techniques have 

been integrated in human’s daily lives. Typical image 
processing and computer vision applications include document 
processing, smartphone applications, video surveillance 
systems, multimedia systems, and/or video games, etc.  

In image processing techniques, the Optical Character 
Recognition (OCR) is an important technique that has been 
widely used in handwriting inputs, license plate recognition, 
and augmented reality applications. The objective of the OCR 
technique is to allow the computer to analyze the text images, 
and then convert to texts (typically the ASCII codes) which 
computer can handle. For example, [1] proposed a method to 
calculate the appropriate threshold for converting gray-level 
images to binary images automatically. Casey and Lecolinet [2] 
proposed a character segmentation system based on connected 
component analysis and feature extraction, which were used to 
segment and recognize each character from document images. 

 
Yuan-Hsiang Chang, Ph.D. is with the Information and Computer 

Engineering Department, Chung-Yuan Christian University, Chung Li, Taiwan, 
R.O.C. (phone: 886-3-265-4713; fax: 886-3-265-4799; e-mail: author@ 
boulder.nist.gov).  

Zhong-Xian Peng, is a graduate student with the. Information and Computer 
Engineering Department, Chung-Yuan Christian University, Chung Li, Tawian, 
R.O.C 

Li-Der Jeng is with the Electronic Engineering Department, Chung-Yuan 
Christian University, Chung Li, Taiwan 

Liu et al. [3] proposed a handwritten character strings 
recognition system for address reading, in which characters 
were segmented using the connected component analysis. Each 
character was then recognized using a beam search algorithm 
and a character classifier. 

In addition to the OCR technique, pattern recognition 
techniques are also drawing attention of many researchers. 
Patterns (or symbols) are commonly seen in documents and/or 
other scenarios in which text information is not used for the 
representation (such as music notes, traffic signs, gestures, etc.). 
However, recognition of such patterns (or symbols) may 
require expertise to achieve effective representation and/or 
communication (e.g., music notes in a music score, etc.). 

Musical score is a form to record music by symbols which 
may include the pitch and tempo information about the music 
and/or songs. With the development of pattern recognition 
techniques, musical score recognition has also become a 
research topic lately. For example, [4] proposed a method to 
detect and remove staff lines using derivation and connected 
component analysis. Chen et al. [5] proposed a conventional 
architecture of Optical Music Recognition (OMR) using the 
staff-lines detection as the key stage. They explored two 
methods, namely the Hough transform and Mathematical 
Morphology, for detecting all staff-lines of an image. Dutta et 
al. [6] proposed a different method to detect and remove staff 
lines from musical documents. The methodology considered a 
staff line segment as a horizontal linkage of vertical black runs 
with uniform height. They also used the neighboring properties 
of a staff line segment to validate it as a true segment. Yoo et al. 
[7] proposed a system to recognize musical scores in low 
resolution images captured by the digital camera of a mobile 
phone. They presented a mask based approach to cope with 
incomplete information in the low resolution images. Toyama 
et al. [8] proposed a score recognition method which could be 
applicable to the complex music scores. Symbol candidates 
were detected by template matching, and then selected by 
considering the relative positions and mutual connections. 
Rossant and Bloch [9] proposed an optical music recognition 
system based on a fuzzy modeling of symbol classes and music 
writing rules. The objective was to disambiguate the 
recognition hypotheses output by the individual symbol 
analysis, followed by the fuzzy modeling to account for 
imprecision in symbol detection. Parker [10] implemented a 
complete optical music recognition system, called Lemon. 
Their system included the techniques, i.e., staff line detection, 
text segmentation, line detection, symbol recognition, note 
head recognition, and semantic interpretation. 

Automatic Music Score Recognition System Using 
Digital Image Processing 
Yuan-Hsiang Chang, Zhong-Xian Peng, Li-Der Jeng. 

W 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1811International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

II.  METHOD 

In this study, we present an “Automatic Music Score 
Recognition System Using Digital Image Processing”, which 
was aimed to automatically recognize musical scores.  

Several system hypotheses can be described as follows: 
 The musical score is a printed document (i.e., black 

musical notes or symbols in white background). 
 The musical score is a scanned document in an upright 

position, therefore no perspective distortions are observed. 
 The image is with sufficient resolution and in good quality. 

Fig. 1 shows the flow chart of our system. The processes 
include: Image Analysis and Segmentation, Image 
Preprocessing, Note recognition, and Accidental and Rest 
Recognition. 

 

Note Recognition

Stem Filtering

Size Filtering

Shape Filtering

Pitch And Beat Analysis

Output

Staff Region Segmentation

Binary Transform

Horizontal Projection

Region Segmentation

Image Preprocessing

Accidental and Rest Recognition

Note Removal

Template ImageTemplate Matching

Source
Image

Staff Line Filtering

Morphological Processing

Connected Component Labeling

 

Fig. 1 System flow chart of the Automatic Music Score Recognition 
System Using Digital Image Processing  

A. Staff Region Segmentation 

A page of musical score consist of number of row stave, with 
a top-down order when playing. A staff consists of five staff 
lines, while notes are recorded on staff lines with respect to the 
height of each line to determine its pitch. Therefore, the first 
step of our system was to segment sub-regions for each staff. 
The processes included: Binary Transform, Horizontal 
Projection, and Region Segmentation. 

Binary Transform was simply used to convert the input 
image to a binary image. In this study, the Otsu’s algorithm was 

used to find the optimal threshold T that minimizes the 
within-class variances. As a result, given an input image I and 
the threshold T, a binary image IB can be acquired using: 
 

   


 


otherwise

TyxIif
yxI B ,0

,,255
,

                    (1) 

 
Horizontal Projection: The image projection is a method for 

projecting source data to selected area to reduce the dimension 
of the source data, such that the data could be easily processed. 
Image projections can be implemented in either the horizontal 
or vertical directions, resulted in horizontal or vertical 
projections. Here, the horizontal projection was applied in our 
system to acquire the horizontally projection histogram as 
shown in Fig. 2. By projecting the musical score in Fig. 2 (a) 
horizontally, total number of pixels for each row could be 
determined in Fig. 2 (b). As shown, the five staff lines were 
associated with five obvious peak values in terms of number of 
pixels. 

 

 

(a) 
 

 

(b) 

Fig. 2 Binary musical score image and the corresponding horizontal 
projects 

 
Region Segmentation: The objective of the region 

segmentation was to identify and segment regions of stave from 
the original image such that each region of the staff could be 
processed independently.  

Based on the result given in Fig. 2, the staff line height HL, 
the staff line space SL, and the distribution of staff lines, could 
be obtained. An example is shown in Fig. 3. 

 

 

Fig. 3 An example of the staff line height HL and the staff line space SL. 
The height of the note head is approximately the same as the staff line 

space 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1812International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

According to the horizontal projections, the histogram 
represented the number of pixels for each row in the binary 
image. Because each staff contained exactly five horizontal 
staff lines, the peaks of the horizontal projections at the location 
of staff line represented the locations of the five staff lines. 
Therefore, the five staff lines could be obtained by 
back-projections of the five peaks in the histogram, such that 
the resulting image contains only the staff lines without any 
note heads (or other symbols). 

B. Image Preprocessing 

In image preprocessing, our objective was to extract or 
isolate the musical symbols to be independent regions from the 
staff by removing the staff lines in the image. However, during 
staff line removal processes, several musical notes (or other 
symbols) may be damaged if they are associated with weak 
structures (shapes). Therefore, our system incorporated the 
image preprocessing processes to retain the musical notes (or 
symbols), while removing the staff lines for further processes. 

Staff Line Filtering: In the musical score, musical symbols 
are recorded on the staff. As a result, musical symbols are 
connected with the staff lines in images. In this step, our 
objective was to retain the music notes (or symbols) in images, 
while removing the staff lines. After acquiring the Staff line 
space and height by horizontal projections, our system removed 
all the black pixels at each rows of staff lines. Because this 
process may damage the structure (shapes) of musical notes (or 
symbols), additional criterion was included. The staff line 
height HL was selected as the threshold and black pixels were 
removed only if the observed height was smaller than the staff 
line height. An example is shown in Fig. 4 (a). 

Morphological Processing: Although the aforementioned 
process was able to remove staff lines effectively, the structure 
(shapes) of the musical notes (or symbols) could be affected. 
The process of Morphological processing was used to retain the 
complete structure (shapes) of each musical note (or symbol). 

 

 

(a) 
 

 

(b) 

Fig. 4 An example of the image preprocessing: (a) result of staff line 
filtering; (b) result of morphological processing 

 
Closing processing is a technology of morphological 

processing that can be used to link the small gaps of structure 
and to improve the connectivity for regions in images. The 
morphological closing is defined by: 

 

EEIEI Θ)(                                 (2) 
 
where I is the input image and is E the structuring element. The 
image is first dilated (  is the dilation operation) and then 

eroded (Θ  is the erosion operation) with the structuring 
element. In our system, the morphological closing was applied, 
an example is shown in Fig. 4 (b). 

Connected Component Labeling: A region of connected 
pixels with an identical label was referred as a connected 
component. The objective of the connected component labeling 
was to assign a unique label to each connected component. An 
example is shown in Fig. 5. 

 

 

Fig. 5 An example of the connected component labeling is shown. 
After labeling, each connected component (region) is assigned a 

unique label 
 

Given a binary images with binary-1s (black pixels) and 
binary-0s (white pixels), we applied the connected component 
labeling to extract each connected component. Therefore, each 
musical notes (or symbols) could be identified and labeled. The 
seed filling algorithm for the connected component labeling is 
given by: 
1) Search each pixel in the image until the value of the current 

pixel P with the binary-1 value and has not been labeled 
yet; 

2) Select P as the seed pixel and assign a label L to P, then 
check each pixel that is adjacent to the seed pixel; 

3) If there is a pixel Q with the binary-1 value that is adjacent 
to the seed pixel, return to step 2 until there is no pixels 
with the binary-1 is found; 

4) Update the label and return to step 1 until all pixels in the 
image have been checked. 

C. Note Recognition 

Once the connected regions for the musical notes (or 
symbols) were identified and labeled, the final step was to 
recognize them. In our system, the processes were divided into 
two major recognition phases: (1) Note recognition; and (2) 
Accidental and rest recognition. 

In staff notations, a musical note can be split into three parts 
according to its structure: head, stem and tail, as shown in Fig. 6. 
The head (e.g., solid or not) is mainly used to determine the 
pitch by its position with respect to the staff lines; the tails is 
mainly used to determine the beat; the stem is used to connect 
both the head and the tail. Our system was designed to detect 
the note heads first, followed by the detection of stems and tails.  

Stem Filtering: A stem is used to connect the head and the 
tail in a musical note. With the different position of a musical 
note, the stem is either extended upward or downward form the 
head. In addition, a whole note has no stems. Because of the 
variety in structures (shapes), recognition of musical note could 
be difficult. To simplify the task, the Stem filtering was 
designed to remove stems for the musical notes, while retaining 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1813International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

the structure of the note heads. 
 

 

Fig. 6 An example of a typical musical note (i.e., eighth note): The 
structure consists of head, stem and tail 

 
In this step, vertical projections were applied and the 

histogram was acquired to determine the approximated location 
of each musical note. During vertical projections, peaks in the 
histogram were related to the location of the stems, despite 
there are different types of musical notes (e.g., 4th or 8th notes, 
etc.). Therefore, stems of each musical notes could be filtered 
(removed). 

Size Filtering: Although there are differences in 
representing musical notes by different publishers, the height of 
the note heads is generally the same as the staff line space. 
Therefore, the staff line space SL was used as the threshold to 
determine if a connected region actually represents the head of 
a musical note. 

Shape Filtering: The head of a musical note is generally an 
oval shape which is symmetrical with respect to its center. Here, 
we detected note heads by calculating the rate of symmetric for 
each connected component. 

In a symmetric connected component L, for any point P∈L, 
there exists a point PS ∈	L	such	that	P - PC = PC - PS, where PC 

is the center of the connected component L, as defined by: 
 

SCCS PPPPPLP  :!,                   (3) 

 
According to the equation, the rate of symmetry R can be 

obtained for each connected component, as given by (4) 
 

A

S

Sum

Sum
R                                       (4) 

 
where Sums is the total number of the symmetric pixels and 
SumA is the total number of all the pixels in the connected 
component. Using the rate of symmetry, we could therefore 
remove all the regions that were not likely to be the heads of 
musical notes. An example is shown in Fig. 7. 

 

 

Fig. 7 An example of the note recognition, in which all the heads of the 
musical notes are marked  

 
Pitch and Beat Analysis: The pitch of the musical note is 

defined by its position with respect to the staff lines. The 
difference of pitches among musical notes is based on the scale 
as a basic unit, and the distance of each scale is with half height 
of the staff line space. Hence, we defined the pitch of each note 
by calculating the distance between musical notes and the 
datum line. The datum line was defined as the position of the 
keynote, i.e., the position of middle C. 

 

Whole/Half  Note ?

Have Stem?

How Many Tails?

Yes

No

Whole Note

Half Note

Quarter Note

Eighth Note

Sixteenth Note

No

Yes

0

1

2

Input

 
Fig. 8 The classifier for the beat of a musical note: Each musical note can thus be classified based on the properties if the stem/tails exist 

 
The beat of a musical note represents the length of the note 

being played, and each note has its own beat. The beat of a 
musical note is represented by three parts: (1) The note is solid 

or not; (2) The note has a stem or not; and (3) How many tails 
do the note have. Based on these properties, our system 
incorporated a classifier for the beat of a musical note, as shown 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1814International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

in Fig. 8. Furthermore, a dot is often used to adjust the beat for 
the musical notes. The dot is meant to increase the beat of the 
musical note by half of its original beat. For example, a note 
with two beats will become three beats. The symbol of a dot in a 
music score is a round black spot, and is generally marked at 
the right side of the note head. The size of dots is smaller than 
the half size of heads and is disconnected with other symbols. 
Based on the dot property as described, our system was 
designed to incorporate additional process for the process of 
recognizing the dot associated with a note head. 

D.  Accidental and Rest Recognition 

Accidentals are the musical symbols used to modify the pitch 
of a musical note. The most common accidentals can be 
described as follow: (1) the sharp is used to raise the pitch of a 
musical note by a semitone; (2) the flat is used to reduce the 
pitch of a musical notes by a semitone; and (3) the natural is 
used to recover the pitch of a musical note to its natural key. 
The accidentals are typically recorded in two ways: (1) marked 
at the start of a staff represent a key signature; and (2) marked at 
the left of a note to adjust the pitch of the musical note.  

Rests are the musical symbols used to represent the pauses in 
music/song. Unlike musical notes, rests have no pitches so that 
the height of rests in a score is fixed. However, shapes of rests 
with different beats are relatively irregular than musical notes. 

To identify the accidentals and/or rests, the technique of 
template matching is used in our system. The technique was 
used to compare an unknown symbol with respect to known 
template images (i.e., template images for possible accidentals 
and/or rests) in the database to recognize the symbol. In our 
system, once a region (sub-image) containing a symbol was 
detected, the region (sub-image) was then normalized to the 
same size with the template image and the logical XOR 
operation was applied: 
 

     


 


otherwise

yxIyxIif
yxI CT

XOR ,255

,,,0
,           (5) 

 
where IT represent the template image, IC represent the 
sub-image containing a symbol, and IXOR represent the result 
image after the exclusive-OR operation. An example is shown 
in Fig. 9. 

 

 

(a) 

 

(b) 

 

(c) 

Fig. 9 An example of the template matching for the rest recognition: 
(a) sub-image of an unknown symbol; (b) template image of the 

crotchet rest; (c) resulting image after the exclusion-OR operation 
 
Fig. 10 shows an example for the recognition of accidentals 

and rests in a musical score. Using the template matching, our 
system was able to identify the accidentals and rests. However, 

our system failed to detect the sharp symbol which is connected 
with the tail of a musical note. 

 

 

(a) 
 

 

(b) 

Fig. 10 An example of the accidental and rest recognition: (a) input 
image; (b) result of the recognition. There is a sharp that is connected 
with the tail of a musical note, resulting in a recognition failure in our 

system  

III. RESULTS 

In this section, we present the research environment and 
recognition results using our system in several musical score 
images. 

A. Research Environment 

The system development was based on a personal computer: 
Pentium(R) Dual-Core E5200 2.5GHz with 2GB memory, and 
Microsoft Windows 7 operating system. The system software 
was developed using the Microsoft Visual Studio C/C++ 2010 
and the Intel Open Source Computer Vision Library (OpenCV) 
Version 2.4.8.  

To evaluate our system performance, a set of digital images 
with musical scores of various complexities were collected 
from the Internet.  

B. Result of Musical Score Recognition 

Table I summarizes the results of musical symbol detection 
and recognition of our system using five images of musical 
scores. The detection rate was evaluated with the probability 
when musical notes or symbols (including accidentals and rests) 
were correctly detected. Then, based on the detected notes or 
symbols, the recognition rate was evaluated with the 
probability when the musical notes or symbols were correctly 
recognized. 

 
TABLE I 

THE RESULTS OF MUSICAL SYMBOL DETECTION AND RECOGNITION 

 Detection Recognition 

 Detected / Total Rate Recognized / Detected Rate 

Image 1 42 / 42 100% 42 / 42 100(%) 

Image 2 62 / 62 100% 62 / 62 100(%) 

Image 3 74(1) / 74 97.3% 64 / 74 86.4(%) 

Image 4 85(4) / 88 87.5% 65 / 85 76.5(%) 

Image 5 89(1) / 92 96.7% 85 / 89 95.5(%) 

Total 382(6) / 388 96.3% 318 / 382 91.7(%) 

 
Recognition results of our system are shown in the following. 

Fig. 11 shows the recognition results for the musical score 
Twinkle, Twinkle, Little Star. All the musical notes, including 
the pitches and beats, were successfully detected and 
recognized. The detected musical notes are marked 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1815International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

accordingly. 
 

 

Fig. 11 Recognition results of the musical score Twinkle, Twinkle, 
Little Star 

 
Fig. 12 shows the recognition results for the musical score 

The Swallow. Although the musical score was more 
complicated, all the musical notes, including the pitches and 
beats, were successfully detected and recognized.  

 

 

Fig. 12 Recognition results of the musical score The Swallow 
 

Fig. 13 shows the recognition results for the musical score I 
Will Sing You. The original image was in JPEG compressed 
format. All the musical notes, accidentals, and rests were 
successfully detected and recognized, despite there was a few 
errors in the recognition of the pitches. 

 

 

Fig. 13 Recognition results of the musical score I Will Sing You 

Fig. 14 shows the recognition results for the musical score At 
This Moment. The quality was relatively poor mainly because 
of compression distortion. The recognition results were 
relatively worse than previous scores. 

 

 

Fig. 14 Recognition results of the musical score At This Moment 
 

Fig. 15 shows the recognition results for the musical score 
My Herd. The quality was also relatively poor mainly because 
of compression distortion. The recognition results were 
relatively worse than previous scores especially in beat 
recognition (most recognition failure occurred at dots).  

 

 

Fig. 15 Recognition results of the musical score My Herd 

IV. CONCLUSION 

In this study, we proposed an Automatic Music Score 
Recognition System Using Digital Image Processing. The 
technical approaches included: staff region segmentation, 
image preprocessing, note recognition and accidental and rest 
recognition. Our system was developed to automatically detect 
and recognize musical notes, accidentals and rests in printed 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1816International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

musical scores.  
The results showed that the detection and the recognition 

rates of our system were 96.3% and 91.7%, respectively. While 
the results were limited and could be affected by image quality, 
our system was shown to achieve effective detection and 
recognition for musical symbols, such as notes, accidentals, and 
rests. Ultimately, our system could be incorporated with a 
media player that could play music/songs with inputs of 
musical scores.  

While our system has been demonstrated with success for 
different types of musical scores, our system was still limited 
with respect to the complexities of some musical scores (e.g., 
chords or other complex symbols). Improvement of our 
systems is still required for such musical scores. 

At present, our system was evaluated using personal 
computers with inputs of digital images. The system could be 
further integrated in applications for smart-phones or other 
mobile devices with built-in digital cameras. In addition, this 
system could be also used as a learning tool for players (e.g., 
piano players, guitar players, etc.) to play the music/songs even 
though they may not be familiar with the music/songs. 

REFERENCES  
[1] N. Otsu, “A Threshold Selection Method form Gray-Level Histograms,” 

IEEE Transactions on Systems, pp. 62-66, 1979. 
[2] R.G. Casey and E. Lecolinet, “A Survey of Methods and Strategies in 

Character Segmentation,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, pp. 690-706, 1996. 

[3] Cheng-Lin Liu, M. Koga and H. Fujisawa, “Lexicon-Driven 
Segmentation and Recognition of Handwritten Character Strings for 
Japanese Address Reading,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, pp. 1425-1437, 2002. 

[4] M. Sotoodeh and F. Tajeripour, “Staff Detection and Removal Using 
Derivation and Connected Component Analysis,” IEEE 16th CSI 
International Symposium on Artificial Intelligence and Signal Processing 
(AISP), pp. 54-57, 2012. 

[5] Chen Genfang, Zhang Liyin, Zhang Wenjun and Wang Qiuqiu, 
“Detecting the Staff-lines of Musical Score with Hough Transform and 
Mathematical Morphology,” IEEE International Conference on 
Multimedia Technology (ICMT) , pp. 1-4, 2010. 

[6] A. Dutta, U. Pal, A. Fornes and J. Llados, “An Efficient Staff Removal 
Approach from Printed Musical Documents,” IEEE International 
Conference on Pattern Recognition (ICPR), pp.1965-1968, 2010. 

[7] JaeMyeong Yoo, GiHong Kim and Gueesang Lee, “Mask Matching for 
Low Resolution Musical Note Recognition,” IEEE International 
Symposium on Signal Processing and Information Technology, pp. 
223-226, 2008. 

[8] F.Toyama, K. Shioji and J. Miyamichi, “Symbol Recognition of Printed 
Piano Scores with Touching Symbols,” Pattern Recognition, ICPR 18th 

International Conference, pp. 480-483, 2006. 
[9] F.Rossant and I. Bloch, “Optical Music Recognition Based on a Fuzzy 

Modeling of Symbol Classes and Music Writing Rules,” Pattern 
Recognition Letters, vol.23, pp. 1129-1141, 2002. 

[10] K.T. Reed and J.R.Parker, “Automatic Computer Recognition of Printed 
Music,” in Proceedings of the ICPR, pp.803-807, 1996. 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1817International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (2).pdf


 

 
Abstract—Music has always been an integral part of human’s 

daily lives. But, for the most people, reading musical score and turning 
it into melody is not easy. This study aims to develop an Automatic 
music score recognition system using digital image processing, which 
can be used to read and analyze musical score images automatically. 
The technical approaches included: (1) staff region segmentation; (2) 
image preprocessing; (3) note recognition; and (4) accidental and rest 
recognition. Digital image processing techniques (e.g., horizontal 
/vertical projections, connected component labeling, morphological 
processing, template matching, etc.) were applied according to 
musical notes, accidents, and rests in staff notations. Preliminary 
results showed that our system could achieve detection and 
recognition rates of 96.3% and 91.7%, respectively. In conclusion, we 
presented an effective automated musical score recognition system 
that could be integrated in a system with a media player to play 
music/songs given input images of musical score. Ultimately, this 
system could also be incorporated in applications for mobile devices as 
a learning tool, such that a music player could learn to play 
music/songs. 
 

Keywords—Connected component labeling, image processing, 
morphological processing, optical musical recognition.  

I. INTRODUCTION 

ITH the advance of image processing and computer 
vision techniques in recent years, the techniques have 

been integrated in human’s daily lives. Typical image 
processing and computer vision applications include document 
processing, smartphone applications, video surveillance 
systems, multimedia systems, and/or video games, etc.  

In image processing techniques, the Optical Character 
Recognition (OCR) is an important technique that has been 
widely used in handwriting inputs, license plate recognition, 
and augmented reality applications. The objective of the OCR 
technique is to allow the computer to analyze the text images, 
and then convert to texts (typically the ASCII codes) which 
computer can handle. For example, [1] proposed a method to 
calculate the appropriate threshold for converting gray-level 
images to binary images automatically. Casey and Lecolinet [2] 
proposed a character segmentation system based on connected 
component analysis and feature extraction, which were used to 
segment and recognize each character from document images. 

 
Yuan-Hsiang Chang, Ph.D. is with the Information and Computer 

Engineering Department, Chung-Yuan Christian University, Chung Li, Taiwan, 
R.O.C. (phone: 886-3-265-4713; fax: 886-3-265-4799; e-mail: author@ 
boulder.nist.gov).  

Zhong-Xian Peng, is a graduate student with the. Information and Computer 
Engineering Department, Chung-Yuan Christian University, Chung Li, Tawian, 
R.O.C 

Li-Der Jeng is with the Electronic Engineering Department, Chung-Yuan 
Christian University, Chung Li, Taiwan 

Liu et al. [3] proposed a handwritten character strings 
recognition system for address reading, in which characters 
were segmented using the connected component analysis. Each 
character was then recognized using a beam search algorithm 
and a character classifier. 

In addition to the OCR technique, pattern recognition 
techniques are also drawing attention of many researchers. 
Patterns (or symbols) are commonly seen in documents and/or 
other scenarios in which text information is not used for the 
representation (such as music notes, traffic signs, gestures, etc.). 
However, recognition of such patterns (or symbols) may 
require expertise to achieve effective representation and/or 
communication (e.g., music notes in a music score, etc.). 

Musical score is a form to record music by symbols which 
may include the pitch and tempo information about the music 
and/or songs. With the development of pattern recognition 
techniques, musical score recognition has also become a 
research topic lately. For example, [4] proposed a method to 
detect and remove staff lines using derivation and connected 
component analysis. Chen et al. [5] proposed a conventional 
architecture of Optical Music Recognition (OMR) using the 
staff-lines detection as the key stage. They explored two 
methods, namely the Hough transform and Mathematical 
Morphology, for detecting all staff-lines of an image. Dutta et 
al. [6] proposed a different method to detect and remove staff 
lines from musical documents. The methodology considered a 
staff line segment as a horizontal linkage of vertical black runs 
with uniform height. They also used the neighboring properties 
of a staff line segment to validate it as a true segment. Yoo et al. 
[7] proposed a system to recognize musical scores in low 
resolution images captured by the digital camera of a mobile 
phone. They presented a mask based approach to cope with 
incomplete information in the low resolution images. Toyama 
et al. [8] proposed a score recognition method which could be 
applicable to the complex music scores. Symbol candidates 
were detected by template matching, and then selected by 
considering the relative positions and mutual connections. 
Rossant and Bloch [9] proposed an optical music recognition 
system based on a fuzzy modeling of symbol classes and music 
writing rules. The objective was to disambiguate the 
recognition hypotheses output by the individual symbol 
analysis, followed by the fuzzy modeling to account for 
imprecision in symbol detection. Parker [10] implemented a 
complete optical music recognition system, called Lemon. 
Their system included the techniques, i.e., staff line detection, 
text segmentation, line detection, symbol recognition, note 
head recognition, and semantic interpretation. 

Automatic Music Score Recognition System Using 
Digital Image Processing 
Yuan-Hsiang Chang, Zhong-Xian Peng, Li-Der Jeng. 

W 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1811International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

II.  METHOD 

In this study, we present an “Automatic Music Score 
Recognition System Using Digital Image Processing”, which 
was aimed to automatically recognize musical scores.  

Several system hypotheses can be described as follows: 
 The musical score is a printed document (i.e., black 

musical notes or symbols in white background). 
 The musical score is a scanned document in an upright 

position, therefore no perspective distortions are observed. 
 The image is with sufficient resolution and in good quality. 

Fig. 1 shows the flow chart of our system. The processes 
include: Image Analysis and Segmentation, Image 
Preprocessing, Note recognition, and Accidental and Rest 
Recognition. 

 

Note Recognition

Stem Filtering

Size Filtering

Shape Filtering

Pitch And Beat Analysis

Output

Staff Region Segmentation

Binary Transform

Horizontal Projection

Region Segmentation

Image Preprocessing

Accidental and Rest Recognition

Note Removal

Template ImageTemplate Matching

Source
Image

Staff Line Filtering

Morphological Processing

Connected Component Labeling

 

Fig. 1 System flow chart of the Automatic Music Score Recognition 
System Using Digital Image Processing  

A. Staff Region Segmentation 

A page of musical score consist of number of row stave, with 
a top-down order when playing. A staff consists of five staff 
lines, while notes are recorded on staff lines with respect to the 
height of each line to determine its pitch. Therefore, the first 
step of our system was to segment sub-regions for each staff. 
The processes included: Binary Transform, Horizontal 
Projection, and Region Segmentation. 

Binary Transform was simply used to convert the input 
image to a binary image. In this study, the Otsu’s algorithm was 

used to find the optimal threshold T that minimizes the 
within-class variances. As a result, given an input image I and 
the threshold T, a binary image IB can be acquired using: 
 

   


 


otherwise

TyxIif
yxI B ,0

,,255
,

                    (1) 

 
Horizontal Projection: The image projection is a method for 

projecting source data to selected area to reduce the dimension 
of the source data, such that the data could be easily processed. 
Image projections can be implemented in either the horizontal 
or vertical directions, resulted in horizontal or vertical 
projections. Here, the horizontal projection was applied in our 
system to acquire the horizontally projection histogram as 
shown in Fig. 2. By projecting the musical score in Fig. 2 (a) 
horizontally, total number of pixels for each row could be 
determined in Fig. 2 (b). As shown, the five staff lines were 
associated with five obvious peak values in terms of number of 
pixels. 

 

 

(a) 
 

 

(b) 

Fig. 2 Binary musical score image and the corresponding horizontal 
projects 

 
Region Segmentation: The objective of the region 

segmentation was to identify and segment regions of stave from 
the original image such that each region of the staff could be 
processed independently.  

Based on the result given in Fig. 2, the staff line height HL, 
the staff line space SL, and the distribution of staff lines, could 
be obtained. An example is shown in Fig. 3. 

 

 

Fig. 3 An example of the staff line height HL and the staff line space SL. 
The height of the note head is approximately the same as the staff line 

space 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1812International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

According to the horizontal projections, the histogram 
represented the number of pixels for each row in the binary 
image. Because each staff contained exactly five horizontal 
staff lines, the peaks of the horizontal projections at the location 
of staff line represented the locations of the five staff lines. 
Therefore, the five staff lines could be obtained by 
back-projections of the five peaks in the histogram, such that 
the resulting image contains only the staff lines without any 
note heads (or other symbols). 

B. Image Preprocessing 

In image preprocessing, our objective was to extract or 
isolate the musical symbols to be independent regions from the 
staff by removing the staff lines in the image. However, during 
staff line removal processes, several musical notes (or other 
symbols) may be damaged if they are associated with weak 
structures (shapes). Therefore, our system incorporated the 
image preprocessing processes to retain the musical notes (or 
symbols), while removing the staff lines for further processes. 

Staff Line Filtering: In the musical score, musical symbols 
are recorded on the staff. As a result, musical symbols are 
connected with the staff lines in images. In this step, our 
objective was to retain the music notes (or symbols) in images, 
while removing the staff lines. After acquiring the Staff line 
space and height by horizontal projections, our system removed 
all the black pixels at each rows of staff lines. Because this 
process may damage the structure (shapes) of musical notes (or 
symbols), additional criterion was included. The staff line 
height HL was selected as the threshold and black pixels were 
removed only if the observed height was smaller than the staff 
line height. An example is shown in Fig. 4 (a). 

Morphological Processing: Although the aforementioned 
process was able to remove staff lines effectively, the structure 
(shapes) of the musical notes (or symbols) could be affected. 
The process of Morphological processing was used to retain the 
complete structure (shapes) of each musical note (or symbol). 

 

 

(a) 
 

 

(b) 

Fig. 4 An example of the image preprocessing: (a) result of staff line 
filtering; (b) result of morphological processing 

 
Closing processing is a technology of morphological 

processing that can be used to link the small gaps of structure 
and to improve the connectivity for regions in images. The 
morphological closing is defined by: 

 

EEIEI Θ)(                                 (2) 
 
where I is the input image and is E the structuring element. The 
image is first dilated (  is the dilation operation) and then 

eroded (Θ  is the erosion operation) with the structuring 
element. In our system, the morphological closing was applied, 
an example is shown in Fig. 4 (b). 

Connected Component Labeling: A region of connected 
pixels with an identical label was referred as a connected 
component. The objective of the connected component labeling 
was to assign a unique label to each connected component. An 
example is shown in Fig. 5. 

 

 

Fig. 5 An example of the connected component labeling is shown. 
After labeling, each connected component (region) is assigned a 

unique label 
 

Given a binary images with binary-1s (black pixels) and 
binary-0s (white pixels), we applied the connected component 
labeling to extract each connected component. Therefore, each 
musical notes (or symbols) could be identified and labeled. The 
seed filling algorithm for the connected component labeling is 
given by: 
1) Search each pixel in the image until the value of the current 

pixel P with the binary-1 value and has not been labeled 
yet; 

2) Select P as the seed pixel and assign a label L to P, then 
check each pixel that is adjacent to the seed pixel; 

3) If there is a pixel Q with the binary-1 value that is adjacent 
to the seed pixel, return to step 2 until there is no pixels 
with the binary-1 is found; 

4) Update the label and return to step 1 until all pixels in the 
image have been checked. 

C. Note Recognition 

Once the connected regions for the musical notes (or 
symbols) were identified and labeled, the final step was to 
recognize them. In our system, the processes were divided into 
two major recognition phases: (1) Note recognition; and (2) 
Accidental and rest recognition. 

In staff notations, a musical note can be split into three parts 
according to its structure: head, stem and tail, as shown in Fig. 6. 
The head (e.g., solid or not) is mainly used to determine the 
pitch by its position with respect to the staff lines; the tails is 
mainly used to determine the beat; the stem is used to connect 
both the head and the tail. Our system was designed to detect 
the note heads first, followed by the detection of stems and tails.  

Stem Filtering: A stem is used to connect the head and the 
tail in a musical note. With the different position of a musical 
note, the stem is either extended upward or downward form the 
head. In addition, a whole note has no stems. Because of the 
variety in structures (shapes), recognition of musical note could 
be difficult. To simplify the task, the Stem filtering was 
designed to remove stems for the musical notes, while retaining 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1813International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

the structure of the note heads. 
 

 

Fig. 6 An example of a typical musical note (i.e., eighth note): The 
structure consists of head, stem and tail 

 
In this step, vertical projections were applied and the 

histogram was acquired to determine the approximated location 
of each musical note. During vertical projections, peaks in the 
histogram were related to the location of the stems, despite 
there are different types of musical notes (e.g., 4th or 8th notes, 
etc.). Therefore, stems of each musical notes could be filtered 
(removed). 

Size Filtering: Although there are differences in 
representing musical notes by different publishers, the height of 
the note heads is generally the same as the staff line space. 
Therefore, the staff line space SL was used as the threshold to 
determine if a connected region actually represents the head of 
a musical note. 

Shape Filtering: The head of a musical note is generally an 
oval shape which is symmetrical with respect to its center. Here, 
we detected note heads by calculating the rate of symmetric for 
each connected component. 

In a symmetric connected component L, for any point P∈L, 
there exists a point PS ∈	L	such	that	P - PC = PC - PS, where PC 

is the center of the connected component L, as defined by: 
 

SCCS PPPPPLP  :!,                   (3) 

 
According to the equation, the rate of symmetry R can be 

obtained for each connected component, as given by (4) 
 

A

S

Sum

Sum
R                                       (4) 

 
where Sums is the total number of the symmetric pixels and 
SumA is the total number of all the pixels in the connected 
component. Using the rate of symmetry, we could therefore 
remove all the regions that were not likely to be the heads of 
musical notes. An example is shown in Fig. 7. 

 

 

Fig. 7 An example of the note recognition, in which all the heads of the 
musical notes are marked  

 
Pitch and Beat Analysis: The pitch of the musical note is 

defined by its position with respect to the staff lines. The 
difference of pitches among musical notes is based on the scale 
as a basic unit, and the distance of each scale is with half height 
of the staff line space. Hence, we defined the pitch of each note 
by calculating the distance between musical notes and the 
datum line. The datum line was defined as the position of the 
keynote, i.e., the position of middle C. 

 

Whole/Half  Note ?

Have Stem?

How Many Tails?

Yes

No

Whole Note

Half Note

Quarter Note

Eighth Note

Sixteenth Note

No

Yes

0

1

2

Input

 
Fig. 8 The classifier for the beat of a musical note: Each musical note can thus be classified based on the properties if the stem/tails exist 

 
The beat of a musical note represents the length of the note 

being played, and each note has its own beat. The beat of a 
musical note is represented by three parts: (1) The note is solid 

or not; (2) The note has a stem or not; and (3) How many tails 
do the note have. Based on these properties, our system 
incorporated a classifier for the beat of a musical note, as shown 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1814International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

in Fig. 8. Furthermore, a dot is often used to adjust the beat for 
the musical notes. The dot is meant to increase the beat of the 
musical note by half of its original beat. For example, a note 
with two beats will become three beats. The symbol of a dot in a 
music score is a round black spot, and is generally marked at 
the right side of the note head. The size of dots is smaller than 
the half size of heads and is disconnected with other symbols. 
Based on the dot property as described, our system was 
designed to incorporate additional process for the process of 
recognizing the dot associated with a note head. 

D.  Accidental and Rest Recognition 

Accidentals are the musical symbols used to modify the pitch 
of a musical note. The most common accidentals can be 
described as follow: (1) the sharp is used to raise the pitch of a 
musical note by a semitone; (2) the flat is used to reduce the 
pitch of a musical notes by a semitone; and (3) the natural is 
used to recover the pitch of a musical note to its natural key. 
The accidentals are typically recorded in two ways: (1) marked 
at the start of a staff represent a key signature; and (2) marked at 
the left of a note to adjust the pitch of the musical note.  

Rests are the musical symbols used to represent the pauses in 
music/song. Unlike musical notes, rests have no pitches so that 
the height of rests in a score is fixed. However, shapes of rests 
with different beats are relatively irregular than musical notes. 

To identify the accidentals and/or rests, the technique of 
template matching is used in our system. The technique was 
used to compare an unknown symbol with respect to known 
template images (i.e., template images for possible accidentals 
and/or rests) in the database to recognize the symbol. In our 
system, once a region (sub-image) containing a symbol was 
detected, the region (sub-image) was then normalized to the 
same size with the template image and the logical XOR 
operation was applied: 
 

     


 


otherwise

yxIyxIif
yxI CT

XOR ,255

,,,0
,           (5) 

 
where IT represent the template image, IC represent the 
sub-image containing a symbol, and IXOR represent the result 
image after the exclusive-OR operation. An example is shown 
in Fig. 9. 

 

 

(a) 

 

(b) 

 

(c) 

Fig. 9 An example of the template matching for the rest recognition: 
(a) sub-image of an unknown symbol; (b) template image of the 

crotchet rest; (c) resulting image after the exclusion-OR operation 
 
Fig. 10 shows an example for the recognition of accidentals 

and rests in a musical score. Using the template matching, our 
system was able to identify the accidentals and rests. However, 

our system failed to detect the sharp symbol which is connected 
with the tail of a musical note. 

 

 

(a) 
 

 

(b) 

Fig. 10 An example of the accidental and rest recognition: (a) input 
image; (b) result of the recognition. There is a sharp that is connected 
with the tail of a musical note, resulting in a recognition failure in our 

system  

III. RESULTS 

In this section, we present the research environment and 
recognition results using our system in several musical score 
images. 

A. Research Environment 

The system development was based on a personal computer: 
Pentium(R) Dual-Core E5200 2.5GHz with 2GB memory, and 
Microsoft Windows 7 operating system. The system software 
was developed using the Microsoft Visual Studio C/C++ 2010 
and the Intel Open Source Computer Vision Library (OpenCV) 
Version 2.4.8.  

To evaluate our system performance, a set of digital images 
with musical scores of various complexities were collected 
from the Internet.  

B. Result of Musical Score Recognition 

Table I summarizes the results of musical symbol detection 
and recognition of our system using five images of musical 
scores. The detection rate was evaluated with the probability 
when musical notes or symbols (including accidentals and rests) 
were correctly detected. Then, based on the detected notes or 
symbols, the recognition rate was evaluated with the 
probability when the musical notes or symbols were correctly 
recognized. 

 
TABLE I 

THE RESULTS OF MUSICAL SYMBOL DETECTION AND RECOGNITION 

 Detection Recognition 

 Detected / Total Rate Recognized / Detected Rate 

Image 1 42 / 42 100% 42 / 42 100(%) 

Image 2 62 / 62 100% 62 / 62 100(%) 

Image 3 74(1) / 74 97.3% 64 / 74 86.4(%) 

Image 4 85(4) / 88 87.5% 65 / 85 76.5(%) 

Image 5 89(1) / 92 96.7% 85 / 89 95.5(%) 

Total 382(6) / 388 96.3% 318 / 382 91.7(%) 

 
Recognition results of our system are shown in the following. 

Fig. 11 shows the recognition results for the musical score 
Twinkle, Twinkle, Little Star. All the musical notes, including 
the pitches and beats, were successfully detected and 
recognized. The detected musical notes are marked 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1815International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

accordingly. 
 

 

Fig. 11 Recognition results of the musical score Twinkle, Twinkle, 
Little Star 

 
Fig. 12 shows the recognition results for the musical score 

The Swallow. Although the musical score was more 
complicated, all the musical notes, including the pitches and 
beats, were successfully detected and recognized.  

 

 

Fig. 12 Recognition results of the musical score The Swallow 
 

Fig. 13 shows the recognition results for the musical score I 
Will Sing You. The original image was in JPEG compressed 
format. All the musical notes, accidentals, and rests were 
successfully detected and recognized, despite there was a few 
errors in the recognition of the pitches. 

 

 

Fig. 13 Recognition results of the musical score I Will Sing You 

Fig. 14 shows the recognition results for the musical score At 
This Moment. The quality was relatively poor mainly because 
of compression distortion. The recognition results were 
relatively worse than previous scores. 

 

 

Fig. 14 Recognition results of the musical score At This Moment 
 

Fig. 15 shows the recognition results for the musical score 
My Herd. The quality was also relatively poor mainly because 
of compression distortion. The recognition results were 
relatively worse than previous scores especially in beat 
recognition (most recognition failure occurred at dots).  

 

 

Fig. 15 Recognition results of the musical score My Herd 

IV. CONCLUSION 

In this study, we proposed an Automatic Music Score 
Recognition System Using Digital Image Processing. The 
technical approaches included: staff region segmentation, 
image preprocessing, note recognition and accidental and rest 
recognition. Our system was developed to automatically detect 
and recognize musical notes, accidentals and rests in printed 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1816International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

musical scores.  
The results showed that the detection and the recognition 

rates of our system were 96.3% and 91.7%, respectively. While 
the results were limited and could be affected by image quality, 
our system was shown to achieve effective detection and 
recognition for musical symbols, such as notes, accidentals, and 
rests. Ultimately, our system could be incorporated with a 
media player that could play music/songs with inputs of 
musical scores.  

While our system has been demonstrated with success for 
different types of musical scores, our system was still limited 
with respect to the complexities of some musical scores (e.g., 
chords or other complex symbols). Improvement of our 
systems is still required for such musical scores. 

At present, our system was evaluated using personal 
computers with inputs of digital images. The system could be 
further integrated in applications for smart-phones or other 
mobile devices with built-in digital cameras. In addition, this 
system could be also used as a learning tool for players (e.g., 
piano players, guitar players, etc.) to play the music/songs even 
though they may not be familiar with the music/songs. 

REFERENCES  
[1] N. Otsu, “A Threshold Selection Method form Gray-Level Histograms,” 

IEEE Transactions on Systems, pp. 62-66, 1979. 
[2] R.G. Casey and E. Lecolinet, “A Survey of Methods and Strategies in 

Character Segmentation,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, pp. 690-706, 1996. 

[3] Cheng-Lin Liu, M. Koga and H. Fujisawa, “Lexicon-Driven 
Segmentation and Recognition of Handwritten Character Strings for 
Japanese Address Reading,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, pp. 1425-1437, 2002. 

[4] M. Sotoodeh and F. Tajeripour, “Staff Detection and Removal Using 
Derivation and Connected Component Analysis,” IEEE 16th CSI 
International Symposium on Artificial Intelligence and Signal Processing 
(AISP), pp. 54-57, 2012. 

[5] Chen Genfang, Zhang Liyin, Zhang Wenjun and Wang Qiuqiu, 
“Detecting the Staff-lines of Musical Score with Hough Transform and 
Mathematical Morphology,” IEEE International Conference on 
Multimedia Technology (ICMT) , pp. 1-4, 2010. 

[6] A. Dutta, U. Pal, A. Fornes and J. Llados, “An Efficient Staff Removal 
Approach from Printed Musical Documents,” IEEE International 
Conference on Pattern Recognition (ICPR), pp.1965-1968, 2010. 

[7] JaeMyeong Yoo, GiHong Kim and Gueesang Lee, “Mask Matching for 
Low Resolution Musical Note Recognition,” IEEE International 
Symposium on Signal Processing and Information Technology, pp. 
223-226, 2008. 

[8] F.Toyama, K. Shioji and J. Miyamichi, “Symbol Recognition of Printed 
Piano Scores with Touching Symbols,” Pattern Recognition, ICPR 18th 

International Conference, pp. 480-483, 2006. 
[9] F.Rossant and I. Bloch, “Optical Music Recognition Based on a Fuzzy 

Modeling of Symbol Classes and Music Writing Rules,” Pattern 
Recognition Letters, vol.23, pp. 1129-1141, 2002. 

[10] K.T. Reed and J.R.Parker, “Automatic Computer Recognition of Printed 
Music,” in Proceedings of the ICPR, pp.803-807, 1996. 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1817International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


reading content from D:\SD\SearchEngine_ver1\Bee\10005799 (3).pdf


 

 
Abstract—Music has always been an integral part of human’s 

daily lives. But, for the most people, reading musical score and turning 
it into melody is not easy. This study aims to develop an Automatic 
music score recognition system using digital image processing, which 
can be used to read and analyze musical score images automatically. 
The technical approaches included: (1) staff region segmentation; (2) 
image preprocessing; (3) note recognition; and (4) accidental and rest 
recognition. Digital image processing techniques (e.g., horizontal 
/vertical projections, connected component labeling, morphological 
processing, template matching, etc.) were applied according to 
musical notes, accidents, and rests in staff notations. Preliminary 
results showed that our system could achieve detection and 
recognition rates of 96.3% and 91.7%, respectively. In conclusion, we 
presented an effective automated musical score recognition system 
that could be integrated in a system with a media player to play 
music/songs given input images of musical score. Ultimately, this 
system could also be incorporated in applications for mobile devices as 
a learning tool, such that a music player could learn to play 
music/songs. 
 

Keywords—Connected component labeling, image processing, 
morphological processing, optical musical recognition.  

I. INTRODUCTION 

ITH the advance of image processing and computer 
vision techniques in recent years, the techniques have 

been integrated in human’s daily lives. Typical image 
processing and computer vision applications include document 
processing, smartphone applications, video surveillance 
systems, multimedia systems, and/or video games, etc.  

In image processing techniques, the Optical Character 
Recognition (OCR) is an important technique that has been 
widely used in handwriting inputs, license plate recognition, 
and augmented reality applications. The objective of the OCR 
technique is to allow the computer to analyze the text images, 
and then convert to texts (typically the ASCII codes) which 
computer can handle. For example, [1] proposed a method to 
calculate the appropriate threshold for converting gray-level 
images to binary images automatically. Casey and Lecolinet [2] 
proposed a character segmentation system based on connected 
component analysis and feature extraction, which were used to 
segment and recognize each character from document images. 

 
Yuan-Hsiang Chang, Ph.D. is with the Information and Computer 

Engineering Department, Chung-Yuan Christian University, Chung Li, Taiwan, 
R.O.C. (phone: 886-3-265-4713; fax: 886-3-265-4799; e-mail: author@ 
boulder.nist.gov).  

Zhong-Xian Peng, is a graduate student with the. Information and Computer 
Engineering Department, Chung-Yuan Christian University, Chung Li, Tawian, 
R.O.C 

Li-Der Jeng is with the Electronic Engineering Department, Chung-Yuan 
Christian University, Chung Li, Taiwan 

Liu et al. [3] proposed a handwritten character strings 
recognition system for address reading, in which characters 
were segmented using the connected component analysis. Each 
character was then recognized using a beam search algorithm 
and a character classifier. 

In addition to the OCR technique, pattern recognition 
techniques are also drawing attention of many researchers. 
Patterns (or symbols) are commonly seen in documents and/or 
other scenarios in which text information is not used for the 
representation (such as music notes, traffic signs, gestures, etc.). 
However, recognition of such patterns (or symbols) may 
require expertise to achieve effective representation and/or 
communication (e.g., music notes in a music score, etc.). 

Musical score is a form to record music by symbols which 
may include the pitch and tempo information about the music 
and/or songs. With the development of pattern recognition 
techniques, musical score recognition has also become a 
research topic lately. For example, [4] proposed a method to 
detect and remove staff lines using derivation and connected 
component analysis. Chen et al. [5] proposed a conventional 
architecture of Optical Music Recognition (OMR) using the 
staff-lines detection as the key stage. They explored two 
methods, namely the Hough transform and Mathematical 
Morphology, for detecting all staff-lines of an image. Dutta et 
al. [6] proposed a different method to detect and remove staff 
lines from musical documents. The methodology considered a 
staff line segment as a horizontal linkage of vertical black runs 
with uniform height. They also used the neighboring properties 
of a staff line segment to validate it as a true segment. Yoo et al. 
[7] proposed a system to recognize musical scores in low 
resolution images captured by the digital camera of a mobile 
phone. They presented a mask based approach to cope with 
incomplete information in the low resolution images. Toyama 
et al. [8] proposed a score recognition method which could be 
applicable to the complex music scores. Symbol candidates 
were detected by template matching, and then selected by 
considering the relative positions and mutual connections. 
Rossant and Bloch [9] proposed an optical music recognition 
system based on a fuzzy modeling of symbol classes and music 
writing rules. The objective was to disambiguate the 
recognition hypotheses output by the individual symbol 
analysis, followed by the fuzzy modeling to account for 
imprecision in symbol detection. Parker [10] implemented a 
complete optical music recognition system, called Lemon. 
Their system included the techniques, i.e., staff line detection, 
text segmentation, line detection, symbol recognition, note 
head recognition, and semantic interpretation. 

Automatic Music Score Recognition System Using 
Digital Image Processing 
Yuan-Hsiang Chang, Zhong-Xian Peng, Li-Der Jeng. 

W 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1811International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

II.  METHOD 

In this study, we present an “Automatic Music Score 
Recognition System Using Digital Image Processing”, which 
was aimed to automatically recognize musical scores.  

Several system hypotheses can be described as follows: 
 The musical score is a printed document (i.e., black 

musical notes or symbols in white background). 
 The musical score is a scanned document in an upright 

position, therefore no perspective distortions are observed. 
 The image is with sufficient resolution and in good quality. 

Fig. 1 shows the flow chart of our system. The processes 
include: Image Analysis and Segmentation, Image 
Preprocessing, Note recognition, and Accidental and Rest 
Recognition. 

 

Note Recognition

Stem Filtering

Size Filtering

Shape Filtering

Pitch And Beat Analysis

Output

Staff Region Segmentation

Binary Transform

Horizontal Projection

Region Segmentation

Image Preprocessing

Accidental and Rest Recognition

Note Removal

Template ImageTemplate Matching

Source
Image

Staff Line Filtering

Morphological Processing

Connected Component Labeling

 

Fig. 1 System flow chart of the Automatic Music Score Recognition 
System Using Digital Image Processing  

A. Staff Region Segmentation 

A page of musical score consist of number of row stave, with 
a top-down order when playing. A staff consists of five staff 
lines, while notes are recorded on staff lines with respect to the 
height of each line to determine its pitch. Therefore, the first 
step of our system was to segment sub-regions for each staff. 
The processes included: Binary Transform, Horizontal 
Projection, and Region Segmentation. 

Binary Transform was simply used to convert the input 
image to a binary image. In this study, the Otsu’s algorithm was 

used to find the optimal threshold T that minimizes the 
within-class variances. As a result, given an input image I and 
the threshold T, a binary image IB can be acquired using: 
 

   


 


otherwise

TyxIif
yxI B ,0

,,255
,

                    (1) 

 
Horizontal Projection: The image projection is a method for 

projecting source data to selected area to reduce the dimension 
of the source data, such that the data could be easily processed. 
Image projections can be implemented in either the horizontal 
or vertical directions, resulted in horizontal or vertical 
projections. Here, the horizontal projection was applied in our 
system to acquire the horizontally projection histogram as 
shown in Fig. 2. By projecting the musical score in Fig. 2 (a) 
horizontally, total number of pixels for each row could be 
determined in Fig. 2 (b). As shown, the five staff lines were 
associated with five obvious peak values in terms of number of 
pixels. 

 

 

(a) 
 

 

(b) 

Fig. 2 Binary musical score image and the corresponding horizontal 
projects 

 
Region Segmentation: The objective of the region 

segmentation was to identify and segment regions of stave from 
the original image such that each region of the staff could be 
processed independently.  

Based on the result given in Fig. 2, the staff line height HL, 
the staff line space SL, and the distribution of staff lines, could 
be obtained. An example is shown in Fig. 3. 

 

 

Fig. 3 An example of the staff line height HL and the staff line space SL. 
The height of the note head is approximately the same as the staff line 

space 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1812International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

According to the horizontal projections, the histogram 
represented the number of pixels for each row in the binary 
image. Because each staff contained exactly five horizontal 
staff lines, the peaks of the horizontal projections at the location 
of staff line represented the locations of the five staff lines. 
Therefore, the five staff lines could be obtained by 
back-projections of the five peaks in the histogram, such that 
the resulting image contains only the staff lines without any 
note heads (or other symbols). 

B. Image Preprocessing 

In image preprocessing, our objective was to extract or 
isolate the musical symbols to be independent regions from the 
staff by removing the staff lines in the image. However, during 
staff line removal processes, several musical notes (or other 
symbols) may be damaged if they are associated with weak 
structures (shapes). Therefore, our system incorporated the 
image preprocessing processes to retain the musical notes (or 
symbols), while removing the staff lines for further processes. 

Staff Line Filtering: In the musical score, musical symbols 
are recorded on the staff. As a result, musical symbols are 
connected with the staff lines in images. In this step, our 
objective was to retain the music notes (or symbols) in images, 
while removing the staff lines. After acquiring the Staff line 
space and height by horizontal projections, our system removed 
all the black pixels at each rows of staff lines. Because this 
process may damage the structure (shapes) of musical notes (or 
symbols), additional criterion was included. The staff line 
height HL was selected as the threshold and black pixels were 
removed only if the observed height was smaller than the staff 
line height. An example is shown in Fig. 4 (a). 

Morphological Processing: Although the aforementioned 
process was able to remove staff lines effectively, the structure 
(shapes) of the musical notes (or symbols) could be affected. 
The process of Morphological processing was used to retain the 
complete structure (shapes) of each musical note (or symbol). 

 

 

(a) 
 

 

(b) 

Fig. 4 An example of the image preprocessing: (a) result of staff line 
filtering; (b) result of morphological processing 

 
Closing processing is a technology of morphological 

processing that can be used to link the small gaps of structure 
and to improve the connectivity for regions in images. The 
morphological closing is defined by: 

 

EEIEI Θ)(                                 (2) 
 
where I is the input image and is E the structuring element. The 
image is first dilated (  is the dilation operation) and then 

eroded (Θ  is the erosion operation) with the structuring 
element. In our system, the morphological closing was applied, 
an example is shown in Fig. 4 (b). 

Connected Component Labeling: A region of connected 
pixels with an identical label was referred as a connected 
component. The objective of the connected component labeling 
was to assign a unique label to each connected component. An 
example is shown in Fig. 5. 

 

 

Fig. 5 An example of the connected component labeling is shown. 
After labeling, each connected component (region) is assigned a 

unique label 
 

Given a binary images with binary-1s (black pixels) and 
binary-0s (white pixels), we applied the connected component 
labeling to extract each connected component. Therefore, each 
musical notes (or symbols) could be identified and labeled. The 
seed filling algorithm for the connected component labeling is 
given by: 
1) Search each pixel in the image until the value of the current 

pixel P with the binary-1 value and has not been labeled 
yet; 

2) Select P as the seed pixel and assign a label L to P, then 
check each pixel that is adjacent to the seed pixel; 

3) If there is a pixel Q with the binary-1 value that is adjacent 
to the seed pixel, return to step 2 until there is no pixels 
with the binary-1 is found; 

4) Update the label and return to step 1 until all pixels in the 
image have been checked. 

C. Note Recognition 

Once the connected regions for the musical notes (or 
symbols) were identified and labeled, the final step was to 
recognize them. In our system, the processes were divided into 
two major recognition phases: (1) Note recognition; and (2) 
Accidental and rest recognition. 

In staff notations, a musical note can be split into three parts 
according to its structure: head, stem and tail, as shown in Fig. 6. 
The head (e.g., solid or not) is mainly used to determine the 
pitch by its position with respect to the staff lines; the tails is 
mainly used to determine the beat; the stem is used to connect 
both the head and the tail. Our system was designed to detect 
the note heads first, followed by the detection of stems and tails.  

Stem Filtering: A stem is used to connect the head and the 
tail in a musical note. With the different position of a musical 
note, the stem is either extended upward or downward form the 
head. In addition, a whole note has no stems. Because of the 
variety in structures (shapes), recognition of musical note could 
be difficult. To simplify the task, the Stem filtering was 
designed to remove stems for the musical notes, while retaining 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1813International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

the structure of the note heads. 
 

 

Fig. 6 An example of a typical musical note (i.e., eighth note): The 
structure consists of head, stem and tail 

 
In this step, vertical projections were applied and the 

histogram was acquired to determine the approximated location 
of each musical note. During vertical projections, peaks in the 
histogram were related to the location of the stems, despite 
there are different types of musical notes (e.g., 4th or 8th notes, 
etc.). Therefore, stems of each musical notes could be filtered 
(removed). 

Size Filtering: Although there are differences in 
representing musical notes by different publishers, the height of 
the note heads is generally the same as the staff line space. 
Therefore, the staff line space SL was used as the threshold to 
determine if a connected region actually represents the head of 
a musical note. 

Shape Filtering: The head of a musical note is generally an 
oval shape which is symmetrical with respect to its center. Here, 
we detected note heads by calculating the rate of symmetric for 
each connected component. 

In a symmetric connected component L, for any point P∈L, 
there exists a point PS ∈	L	such	that	P - PC = PC - PS, where PC 

is the center of the connected component L, as defined by: 
 

SCCS PPPPPLP  :!,                   (3) 

 
According to the equation, the rate of symmetry R can be 

obtained for each connected component, as given by (4) 
 

A

S

Sum

Sum
R                                       (4) 

 
where Sums is the total number of the symmetric pixels and 
SumA is the total number of all the pixels in the connected 
component. Using the rate of symmetry, we could therefore 
remove all the regions that were not likely to be the heads of 
musical notes. An example is shown in Fig. 7. 

 

 

Fig. 7 An example of the note recognition, in which all the heads of the 
musical notes are marked  

 
Pitch and Beat Analysis: The pitch of the musical note is 

defined by its position with respect to the staff lines. The 
difference of pitches among musical notes is based on the scale 
as a basic unit, and the distance of each scale is with half height 
of the staff line space. Hence, we defined the pitch of each note 
by calculating the distance between musical notes and the 
datum line. The datum line was defined as the position of the 
keynote, i.e., the position of middle C. 

 

Whole/Half  Note ?

Have Stem?

How Many Tails?

Yes

No

Whole Note

Half Note

Quarter Note

Eighth Note

Sixteenth Note

No

Yes

0

1

2

Input

 
Fig. 8 The classifier for the beat of a musical note: Each musical note can thus be classified based on the properties if the stem/tails exist 

 
The beat of a musical note represents the length of the note 

being played, and each note has its own beat. The beat of a 
musical note is represented by three parts: (1) The note is solid 

or not; (2) The note has a stem or not; and (3) How many tails 
do the note have. Based on these properties, our system 
incorporated a classifier for the beat of a musical note, as shown 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1814International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

in Fig. 8. Furthermore, a dot is often used to adjust the beat for 
the musical notes. The dot is meant to increase the beat of the 
musical note by half of its original beat. For example, a note 
with two beats will become three beats. The symbol of a dot in a 
music score is a round black spot, and is generally marked at 
the right side of the note head. The size of dots is smaller than 
the half size of heads and is disconnected with other symbols. 
Based on the dot property as described, our system was 
designed to incorporate additional process for the process of 
recognizing the dot associated with a note head. 

D.  Accidental and Rest Recognition 

Accidentals are the musical symbols used to modify the pitch 
of a musical note. The most common accidentals can be 
described as follow: (1) the sharp is used to raise the pitch of a 
musical note by a semitone; (2) the flat is used to reduce the 
pitch of a musical notes by a semitone; and (3) the natural is 
used to recover the pitch of a musical note to its natural key. 
The accidentals are typically recorded in two ways: (1) marked 
at the start of a staff represent a key signature; and (2) marked at 
the left of a note to adjust the pitch of the musical note.  

Rests are the musical symbols used to represent the pauses in 
music/song. Unlike musical notes, rests have no pitches so that 
the height of rests in a score is fixed. However, shapes of rests 
with different beats are relatively irregular than musical notes. 

To identify the accidentals and/or rests, the technique of 
template matching is used in our system. The technique was 
used to compare an unknown symbol with respect to known 
template images (i.e., template images for possible accidentals 
and/or rests) in the database to recognize the symbol. In our 
system, once a region (sub-image) containing a symbol was 
detected, the region (sub-image) was then normalized to the 
same size with the template image and the logical XOR 
operation was applied: 
 

     


 


otherwise

yxIyxIif
yxI CT

XOR ,255

,,,0
,           (5) 

 
where IT represent the template image, IC represent the 
sub-image containing a symbol, and IXOR represent the result 
image after the exclusive-OR operation. An example is shown 
in Fig. 9. 

 

 

(a) 

 

(b) 

 

(c) 

Fig. 9 An example of the template matching for the rest recognition: 
(a) sub-image of an unknown symbol; (b) template image of the 

crotchet rest; (c) resulting image after the exclusion-OR operation 
 
Fig. 10 shows an example for the recognition of accidentals 

and rests in a musical score. Using the template matching, our 
system was able to identify the accidentals and rests. However, 

our system failed to detect the sharp symbol which is connected 
with the tail of a musical note. 

 

 

(a) 
 

 

(b) 

Fig. 10 An example of the accidental and rest recognition: (a) input 
image; (b) result of the recognition. There is a sharp that is connected 
with the tail of a musical note, resulting in a recognition failure in our 

system  

III. RESULTS 

In this section, we present the research environment and 
recognition results using our system in several musical score 
images. 

A. Research Environment 

The system development was based on a personal computer: 
Pentium(R) Dual-Core E5200 2.5GHz with 2GB memory, and 
Microsoft Windows 7 operating system. The system software 
was developed using the Microsoft Visual Studio C/C++ 2010 
and the Intel Open Source Computer Vision Library (OpenCV) 
Version 2.4.8.  

To evaluate our system performance, a set of digital images 
with musical scores of various complexities were collected 
from the Internet.  

B. Result of Musical Score Recognition 

Table I summarizes the results of musical symbol detection 
and recognition of our system using five images of musical 
scores. The detection rate was evaluated with the probability 
when musical notes or symbols (including accidentals and rests) 
were correctly detected. Then, based on the detected notes or 
symbols, the recognition rate was evaluated with the 
probability when the musical notes or symbols were correctly 
recognized. 

 
TABLE I 

THE RESULTS OF MUSICAL SYMBOL DETECTION AND RECOGNITION 

 Detection Recognition 

 Detected / Total Rate Recognized / Detected Rate 

Image 1 42 / 42 100% 42 / 42 100(%) 

Image 2 62 / 62 100% 62 / 62 100(%) 

Image 3 74(1) / 74 97.3% 64 / 74 86.4(%) 

Image 4 85(4) / 88 87.5% 65 / 85 76.5(%) 

Image 5 89(1) / 92 96.7% 85 / 89 95.5(%) 

Total 382(6) / 388 96.3% 318 / 382 91.7(%) 

 
Recognition results of our system are shown in the following. 

Fig. 11 shows the recognition results for the musical score 
Twinkle, Twinkle, Little Star. All the musical notes, including 
the pitches and beats, were successfully detected and 
recognized. The detected musical notes are marked 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1815International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

accordingly. 
 

 

Fig. 11 Recognition results of the musical score Twinkle, Twinkle, 
Little Star 

 
Fig. 12 shows the recognition results for the musical score 

The Swallow. Although the musical score was more 
complicated, all the musical notes, including the pitches and 
beats, were successfully detected and recognized.  

 

 

Fig. 12 Recognition results of the musical score The Swallow 
 

Fig. 13 shows the recognition results for the musical score I 
Will Sing You. The original image was in JPEG compressed 
format. All the musical notes, accidentals, and rests were 
successfully detected and recognized, despite there was a few 
errors in the recognition of the pitches. 

 

 

Fig. 13 Recognition results of the musical score I Will Sing You 

Fig. 14 shows the recognition results for the musical score At 
This Moment. The quality was relatively poor mainly because 
of compression distortion. The recognition results were 
relatively worse than previous scores. 

 

 

Fig. 14 Recognition results of the musical score At This Moment 
 

Fig. 15 shows the recognition results for the musical score 
My Herd. The quality was also relatively poor mainly because 
of compression distortion. The recognition results were 
relatively worse than previous scores especially in beat 
recognition (most recognition failure occurred at dots).  

 

 

Fig. 15 Recognition results of the musical score My Herd 

IV. CONCLUSION 

In this study, we proposed an Automatic Music Score 
Recognition System Using Digital Image Processing. The 
technical approaches included: staff region segmentation, 
image preprocessing, note recognition and accidental and rest 
recognition. Our system was developed to automatically detect 
and recognize musical notes, accidentals and rests in printed 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1816International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

musical scores.  
The results showed that the detection and the recognition 

rates of our system were 96.3% and 91.7%, respectively. While 
the results were limited and could be affected by image quality, 
our system was shown to achieve effective detection and 
recognition for musical symbols, such as notes, accidentals, and 
rests. Ultimately, our system could be incorporated with a 
media player that could play music/songs with inputs of 
musical scores.  

While our system has been demonstrated with success for 
different types of musical scores, our system was still limited 
with respect to the complexities of some musical scores (e.g., 
chords or other complex symbols). Improvement of our 
systems is still required for such musical scores. 

At present, our system was evaluated using personal 
computers with inputs of digital images. The system could be 
further integrated in applications for smart-phones or other 
mobile devices with built-in digital cameras. In addition, this 
system could be also used as a learning tool for players (e.g., 
piano players, guitar players, etc.) to play the music/songs even 
though they may not be familiar with the music/songs. 

REFERENCES  
[1] N. Otsu, “A Threshold Selection Method form Gray-Level Histograms,” 

IEEE Transactions on Systems, pp. 62-66, 1979. 
[2] R.G. Casey and E. Lecolinet, “A Survey of Methods and Strategies in 

Character Segmentation,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, pp. 690-706, 1996. 

[3] Cheng-Lin Liu, M. Koga and H. Fujisawa, “Lexicon-Driven 
Segmentation and Recognition of Handwritten Character Strings for 
Japanese Address Reading,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, pp. 1425-1437, 2002. 

[4] M. Sotoodeh and F. Tajeripour, “Staff Detection and Removal Using 
Derivation and Connected Component Analysis,” IEEE 16th CSI 
International Symposium on Artificial Intelligence and Signal Processing 
(AISP), pp. 54-57, 2012. 

[5] Chen Genfang, Zhang Liyin, Zhang Wenjun and Wang Qiuqiu, 
“Detecting the Staff-lines of Musical Score with Hough Transform and 
Mathematical Morphology,” IEEE International Conference on 
Multimedia Technology (ICMT) , pp. 1-4, 2010. 

[6] A. Dutta, U. Pal, A. Fornes and J. Llados, “An Efficient Staff Removal 
Approach from Printed Musical Documents,” IEEE International 
Conference on Pattern Recognition (ICPR), pp.1965-1968, 2010. 

[7] JaeMyeong Yoo, GiHong Kim and Gueesang Lee, “Mask Matching for 
Low Resolution Musical Note Recognition,” IEEE International 
Symposium on Signal Processing and Information Technology, pp. 
223-226, 2008. 

[8] F.Toyama, K. Shioji and J. Miyamichi, “Symbol Recognition of Printed 
Piano Scores with Touching Symbols,” Pattern Recognition, ICPR 18th 

International Conference, pp. 480-483, 2006. 
[9] F.Rossant and I. Bloch, “Optical Music Recognition Based on a Fuzzy 

Modeling of Symbol Classes and Music Writing Rules,” Pattern 
Recognition Letters, vol.23, pp. 1129-1141, 2002. 

[10] K.T. Reed and J.R.Parker, “Automatic Computer Recognition of Printed 
Music,” in Proceedings of the ICPR, pp.803-807, 1996. 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1817International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


reading content from D:\SD\SearchEngine_ver1\Bee\10005799.pdf


 

 
Abstract—Music has always been an integral part of human’s 

daily lives. But, for the most people, reading musical score and turning 
it into melody is not easy. This study aims to develop an Automatic 
music score recognition system using digital image processing, which 
can be used to read and analyze musical score images automatically. 
The technical approaches included: (1) staff region segmentation; (2) 
image preprocessing; (3) note recognition; and (4) accidental and rest 
recognition. Digital image processing techniques (e.g., horizontal 
/vertical projections, connected component labeling, morphological 
processing, template matching, etc.) were applied according to 
musical notes, accidents, and rests in staff notations. Preliminary 
results showed that our system could achieve detection and 
recognition rates of 96.3% and 91.7%, respectively. In conclusion, we 
presented an effective automated musical score recognition system 
that could be integrated in a system with a media player to play 
music/songs given input images of musical score. Ultimately, this 
system could also be incorporated in applications for mobile devices as 
a learning tool, such that a music player could learn to play 
music/songs. 
 

Keywords—Connected component labeling, image processing, 
morphological processing, optical musical recognition.  

I. INTRODUCTION 

ITH the advance of image processing and computer 
vision techniques in recent years, the techniques have 

been integrated in human’s daily lives. Typical image 
processing and computer vision applications include document 
processing, smartphone applications, video surveillance 
systems, multimedia systems, and/or video games, etc.  

In image processing techniques, the Optical Character 
Recognition (OCR) is an important technique that has been 
widely used in handwriting inputs, license plate recognition, 
and augmented reality applications. The objective of the OCR 
technique is to allow the computer to analyze the text images, 
and then convert to texts (typically the ASCII codes) which 
computer can handle. For example, [1] proposed a method to 
calculate the appropriate threshold for converting gray-level 
images to binary images automatically. Casey and Lecolinet [2] 
proposed a character segmentation system based on connected 
component analysis and feature extraction, which were used to 
segment and recognize each character from document images. 

 
Yuan-Hsiang Chang, Ph.D. is with the Information and Computer 

Engineering Department, Chung-Yuan Christian University, Chung Li, Taiwan, 
R.O.C. (phone: 886-3-265-4713; fax: 886-3-265-4799; e-mail: author@ 
boulder.nist.gov).  

Zhong-Xian Peng, is a graduate student with the. Information and Computer 
Engineering Department, Chung-Yuan Christian University, Chung Li, Tawian, 
R.O.C 

Li-Der Jeng is with the Electronic Engineering Department, Chung-Yuan 
Christian University, Chung Li, Taiwan 

Liu et al. [3] proposed a handwritten character strings 
recognition system for address reading, in which characters 
were segmented using the connected component analysis. Each 
character was then recognized using a beam search algorithm 
and a character classifier. 

In addition to the OCR technique, pattern recognition 
techniques are also drawing attention of many researchers. 
Patterns (or symbols) are commonly seen in documents and/or 
other scenarios in which text information is not used for the 
representation (such as music notes, traffic signs, gestures, etc.). 
However, recognition of such patterns (or symbols) may 
require expertise to achieve effective representation and/or 
communication (e.g., music notes in a music score, etc.). 

Musical score is a form to record music by symbols which 
may include the pitch and tempo information about the music 
and/or songs. With the development of pattern recognition 
techniques, musical score recognition has also become a 
research topic lately. For example, [4] proposed a method to 
detect and remove staff lines using derivation and connected 
component analysis. Chen et al. [5] proposed a conventional 
architecture of Optical Music Recognition (OMR) using the 
staff-lines detection as the key stage. They explored two 
methods, namely the Hough transform and Mathematical 
Morphology, for detecting all staff-lines of an image. Dutta et 
al. [6] proposed a different method to detect and remove staff 
lines from musical documents. The methodology considered a 
staff line segment as a horizontal linkage of vertical black runs 
with uniform height. They also used the neighboring properties 
of a staff line segment to validate it as a true segment. Yoo et al. 
[7] proposed a system to recognize musical scores in low 
resolution images captured by the digital camera of a mobile 
phone. They presented a mask based approach to cope with 
incomplete information in the low resolution images. Toyama 
et al. [8] proposed a score recognition method which could be 
applicable to the complex music scores. Symbol candidates 
were detected by template matching, and then selected by 
considering the relative positions and mutual connections. 
Rossant and Bloch [9] proposed an optical music recognition 
system based on a fuzzy modeling of symbol classes and music 
writing rules. The objective was to disambiguate the 
recognition hypotheses output by the individual symbol 
analysis, followed by the fuzzy modeling to account for 
imprecision in symbol detection. Parker [10] implemented a 
complete optical music recognition system, called Lemon. 
Their system included the techniques, i.e., staff line detection, 
text segmentation, line detection, symbol recognition, note 
head recognition, and semantic interpretation. 

Automatic Music Score Recognition System Using 
Digital Image Processing 
Yuan-Hsiang Chang, Zhong-Xian Peng, Li-Der Jeng. 

W 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1811International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799
Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight



 

II.  METHOD 

In this study, we present an “Automatic Music Score 
Recognition System Using Digital Image Processing”, which 
was aimed to automatically recognize musical scores.  

Several system hypotheses can be described as follows: 
 The musical score is a printed document (i.e., black 

musical notes or symbols in white background). 
 The musical score is a scanned document in an upright 

position, therefore no perspective distortions are observed. 
 The image is with sufficient resolution and in good quality. 

Fig. 1 shows the flow chart of our system. The processes 
include: Image Analysis and Segmentation, Image 
Preprocessing, Note recognition, and Accidental and Rest 
Recognition. 

 

Note Recognition

Stem Filtering

Size Filtering

Shape Filtering

Pitch And Beat Analysis

Output

Staff Region Segmentation

Binary Transform

Horizontal Projection

Region Segmentation

Image Preprocessing

Accidental and Rest Recognition

Note Removal

Template ImageTemplate Matching

Source
Image

Staff Line Filtering

Morphological Processing

Connected Component Labeling

 

Fig. 1 System flow chart of the Automatic Music Score Recognition 
System Using Digital Image Processing  

A. Staff Region Segmentation 

A page of musical score consist of number of row stave, with 
a top-down order when playing. A staff consists of five staff 
lines, while notes are recorded on staff lines with respect to the 
height of each line to determine its pitch. Therefore, the first 
step of our system was to segment sub-regions for each staff. 
The processes included: Binary Transform, Horizontal 
Projection, and Region Segmentation. 

Binary Transform was simply used to convert the input 
image to a binary image. In this study, the Otsu’s algorithm was 

used to find the optimal threshold T that minimizes the 
within-class variances. As a result, given an input image I and 
the threshold T, a binary image IB can be acquired using: 
 

   


 


otherwise

TyxIif
yxI B ,0

,,255
,

                    (1) 

 
Horizontal Projection: The image projection is a method for 

projecting source data to selected area to reduce the dimension 
of the source data, such that the data could be easily processed. 
Image projections can be implemented in either the horizontal 
or vertical directions, resulted in horizontal or vertical 
projections. Here, the horizontal projection was applied in our 
system to acquire the horizontally projection histogram as 
shown in Fig. 2. By projecting the musical score in Fig. 2 (a) 
horizontally, total number of pixels for each row could be 
determined in Fig. 2 (b). As shown, the five staff lines were 
associated with five obvious peak values in terms of number of 
pixels. 

 

 

(a) 
 

 

(b) 

Fig. 2 Binary musical score image and the corresponding horizontal 
projects 

 
Region Segmentation: The objective of the region 

segmentation was to identify and segment regions of stave from 
the original image such that each region of the staff could be 
processed independently.  

Based on the result given in Fig. 2, the staff line height HL, 
the staff line space SL, and the distribution of staff lines, could 
be obtained. An example is shown in Fig. 3. 

 

 

Fig. 3 An example of the staff line height HL and the staff line space SL. 
The height of the note head is approximately the same as the staff line 

space 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1812International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799
Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight

Asus
Highlight



 

According to the horizontal projections, the histogram 
represented the number of pixels for each row in the binary 
image. Because each staff contained exactly five horizontal 
staff lines, the peaks of the horizontal projections at the location 
of staff line represented the locations of the five staff lines. 
Therefore, the five staff lines could be obtained by 
back-projections of the five peaks in the histogram, such that 
the resulting image contains only the staff lines without any 
note heads (or other symbols). 

B. Image Preprocessing 

In image preprocessing, our objective was to extract or 
isolate the musical symbols to be independent regions from the 
staff by removing the staff lines in the image. However, during 
staff line removal processes, several musical notes (or other 
symbols) may be damaged if they are associated with weak 
structures (shapes). Therefore, our system incorporated the 
image preprocessing processes to retain the musical notes (or 
symbols), while removing the staff lines for further processes. 

Staff Line Filtering: In the musical score, musical symbols 
are recorded on the staff. As a result, musical symbols are 
connected with the staff lines in images. In this step, our 
objective was to retain the music notes (or symbols) in images, 
while removing the staff lines. After acquiring the Staff line 
space and height by horizontal projections, our system removed 
all the black pixels at each rows of staff lines. Because this 
process may damage the structure (shapes) of musical notes (or 
symbols), additional criterion was included. The staff line 
height HL was selected as the threshold and black pixels were 
removed only if the observed height was smaller than the staff 
line height. An example is shown in Fig. 4 (a). 

Morphological Processing: Although the aforementioned 
process was able to remove staff lines effectively, the structure 
(shapes) of the musical notes (or symbols) could be affected. 
The process of Morphological processing was used to retain the 
complete structure (shapes) of each musical note (or symbol). 

 

 

(a) 
 

 

(b) 

Fig. 4 An example of the image preprocessing: (a) result of staff line 
filtering; (b) result of morphological processing 

 
Closing processing is a technology of morphological 

processing that can be used to link the small gaps of structure 
and to improve the connectivity for regions in images. The 
morphological closing is defined by: 

 

EEIEI Θ)(                                 (2) 
 
where I is the input image and is E the structuring element. The 
image is first dilated (  is the dilation operation) and then 

eroded (Θ  is the erosion operation) with the structuring 
element. In our system, the morphological closing was applied, 
an example is shown in Fig. 4 (b). 

Connected Component Labeling: A region of connected 
pixels with an identical label was referred as a connected 
component. The objective of the connected component labeling 
was to assign a unique label to each connected component. An 
example is shown in Fig. 5. 

 

 

Fig. 5 An example of the connected component labeling is shown. 
After labeling, each connected component (region) is assigned a 

unique label 
 

Given a binary images with binary-1s (black pixels) and 
binary-0s (white pixels), we applied the connected component 
labeling to extract each connected component. Therefore, each 
musical notes (or symbols) could be identified and labeled. The 
seed filling algorithm for the connected component labeling is 
given by: 
1) Search each pixel in the image until the value of the current 

pixel P with the binary-1 value and has not been labeled 
yet; 

2) Select P as the seed pixel and assign a label L to P, then 
check each pixel that is adjacent to the seed pixel; 

3) If there is a pixel Q with the binary-1 value that is adjacent 
to the seed pixel, return to step 2 until there is no pixels 
with the binary-1 is found; 

4) Update the label and return to step 1 until all pixels in the 
image have been checked. 

C. Note Recognition 

Once the connected regions for the musical notes (or 
symbols) were identified and labeled, the final step was to 
recognize them. In our system, the processes were divided into 
two major recognition phases: (1) Note recognition; and (2) 
Accidental and rest recognition. 

In staff notations, a musical note can be split into three parts 
according to its structure: head, stem and tail, as shown in Fig. 6. 
The head (e.g., solid or not) is mainly used to determine the 
pitch by its position with respect to the staff lines; the tails is 
mainly used to determine the beat; the stem is used to connect 
both the head and the tail. Our system was designed to detect 
the note heads first, followed by the detection of stems and tails.  

Stem Filtering: A stem is used to connect the head and the 
tail in a musical note. With the different position of a musical 
note, the stem is either extended upward or downward form the 
head. In addition, a whole note has no stems. Because of the 
variety in structures (shapes), recognition of musical note could 
be difficult. To simplify the task, the Stem filtering was 
designed to remove stems for the musical notes, while retaining 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1813International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

the structure of the note heads. 
 

 

Fig. 6 An example of a typical musical note (i.e., eighth note): The 
structure consists of head, stem and tail 

 
In this step, vertical projections were applied and the 

histogram was acquired to determine the approximated location 
of each musical note. During vertical projections, peaks in the 
histogram were related to the location of the stems, despite 
there are different types of musical notes (e.g., 4th or 8th notes, 
etc.). Therefore, stems of each musical notes could be filtered 
(removed). 

Size Filtering: Although there are differences in 
representing musical notes by different publishers, the height of 
the note heads is generally the same as the staff line space. 
Therefore, the staff line space SL was used as the threshold to 
determine if a connected region actually represents the head of 
a musical note. 

Shape Filtering: The head of a musical note is generally an 
oval shape which is symmetrical with respect to its center. Here, 
we detected note heads by calculating the rate of symmetric for 
each connected component. 

In a symmetric connected component L, for any point P∈L, 
there exists a point PS ∈	L	such	that	P - PC = PC - PS, where PC 

is the center of the connected component L, as defined by: 
 

SCCS PPPPPLP  :!,                   (3) 

 
According to the equation, the rate of symmetry R can be 

obtained for each connected component, as given by (4) 
 

A

S

Sum

Sum
R                                       (4) 

 
where Sums is the total number of the symmetric pixels and 
SumA is the total number of all the pixels in the connected 
component. Using the rate of symmetry, we could therefore 
remove all the regions that were not likely to be the heads of 
musical notes. An example is shown in Fig. 7. 

 

 

Fig. 7 An example of the note recognition, in which all the heads of the 
musical notes are marked  

 
Pitch and Beat Analysis: The pitch of the musical note is 

defined by its position with respect to the staff lines. The 
difference of pitches among musical notes is based on the scale 
as a basic unit, and the distance of each scale is with half height 
of the staff line space. Hence, we defined the pitch of each note 
by calculating the distance between musical notes and the 
datum line. The datum line was defined as the position of the 
keynote, i.e., the position of middle C. 

 

Whole/Half  Note ?

Have Stem?

How Many Tails?

Yes

No

Whole Note

Half Note

Quarter Note

Eighth Note

Sixteenth Note

No

Yes

0

1

2

Input

 
Fig. 8 The classifier for the beat of a musical note: Each musical note can thus be classified based on the properties if the stem/tails exist 

 
The beat of a musical note represents the length of the note 

being played, and each note has its own beat. The beat of a 
musical note is represented by three parts: (1) The note is solid 

or not; (2) The note has a stem or not; and (3) How many tails 
do the note have. Based on these properties, our system 
incorporated a classifier for the beat of a musical note, as shown 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1814International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

in Fig. 8. Furthermore, a dot is often used to adjust the beat for 
the musical notes. The dot is meant to increase the beat of the 
musical note by half of its original beat. For example, a note 
with two beats will become three beats. The symbol of a dot in a 
music score is a round black spot, and is generally marked at 
the right side of the note head. The size of dots is smaller than 
the half size of heads and is disconnected with other symbols. 
Based on the dot property as described, our system was 
designed to incorporate additional process for the process of 
recognizing the dot associated with a note head. 

D.  Accidental and Rest Recognition 

Accidentals are the musical symbols used to modify the pitch 
of a musical note. The most common accidentals can be 
described as follow: (1) the sharp is used to raise the pitch of a 
musical note by a semitone; (2) the flat is used to reduce the 
pitch of a musical notes by a semitone; and (3) the natural is 
used to recover the pitch of a musical note to its natural key. 
The accidentals are typically recorded in two ways: (1) marked 
at the start of a staff represent a key signature; and (2) marked at 
the left of a note to adjust the pitch of the musical note.  

Rests are the musical symbols used to represent the pauses in 
music/song. Unlike musical notes, rests have no pitches so that 
the height of rests in a score is fixed. However, shapes of rests 
with different beats are relatively irregular than musical notes. 

To identify the accidentals and/or rests, the technique of 
template matching is used in our system. The technique was 
used to compare an unknown symbol with respect to known 
template images (i.e., template images for possible accidentals 
and/or rests) in the database to recognize the symbol. In our 
system, once a region (sub-image) containing a symbol was 
detected, the region (sub-image) was then normalized to the 
same size with the template image and the logical XOR 
operation was applied: 
 

     


 


otherwise

yxIyxIif
yxI CT

XOR ,255

,,,0
,           (5) 

 
where IT represent the template image, IC represent the 
sub-image containing a symbol, and IXOR represent the result 
image after the exclusive-OR operation. An example is shown 
in Fig. 9. 

 

 

(a) 

 

(b) 

 

(c) 

Fig. 9 An example of the template matching for the rest recognition: 
(a) sub-image of an unknown symbol; (b) template image of the 

crotchet rest; (c) resulting image after the exclusion-OR operation 
 
Fig. 10 shows an example for the recognition of accidentals 

and rests in a musical score. Using the template matching, our 
system was able to identify the accidentals and rests. However, 

our system failed to detect the sharp symbol which is connected 
with the tail of a musical note. 

 

 

(a) 
 

 

(b) 

Fig. 10 An example of the accidental and rest recognition: (a) input 
image; (b) result of the recognition. There is a sharp that is connected 
with the tail of a musical note, resulting in a recognition failure in our 

system  

III. RESULTS 

In this section, we present the research environment and 
recognition results using our system in several musical score 
images. 

A. Research Environment 

The system development was based on a personal computer: 
Pentium(R) Dual-Core E5200 2.5GHz with 2GB memory, and 
Microsoft Windows 7 operating system. The system software 
was developed using the Microsoft Visual Studio C/C++ 2010 
and the Intel Open Source Computer Vision Library (OpenCV) 
Version 2.4.8.  

To evaluate our system performance, a set of digital images 
with musical scores of various complexities were collected 
from the Internet.  

B. Result of Musical Score Recognition 

Table I summarizes the results of musical symbol detection 
and recognition of our system using five images of musical 
scores. The detection rate was evaluated with the probability 
when musical notes or symbols (including accidentals and rests) 
were correctly detected. Then, based on the detected notes or 
symbols, the recognition rate was evaluated with the 
probability when the musical notes or symbols were correctly 
recognized. 

 
TABLE I 

THE RESULTS OF MUSICAL SYMBOL DETECTION AND RECOGNITION 

 Detection Recognition 

 Detected / Total Rate Recognized / Detected Rate 

Image 1 42 / 42 100% 42 / 42 100(%) 

Image 2 62 / 62 100% 62 / 62 100(%) 

Image 3 74(1) / 74 97.3% 64 / 74 86.4(%) 

Image 4 85(4) / 88 87.5% 65 / 85 76.5(%) 

Image 5 89(1) / 92 96.7% 85 / 89 95.5(%) 

Total 382(6) / 388 96.3% 318 / 382 91.7(%) 

 
Recognition results of our system are shown in the following. 

Fig. 11 shows the recognition results for the musical score 
Twinkle, Twinkle, Little Star. All the musical notes, including 
the pitches and beats, were successfully detected and 
recognized. The detected musical notes are marked 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1815International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

accordingly. 
 

 

Fig. 11 Recognition results of the musical score Twinkle, Twinkle, 
Little Star 

 
Fig. 12 shows the recognition results for the musical score 

The Swallow. Although the musical score was more 
complicated, all the musical notes, including the pitches and 
beats, were successfully detected and recognized.  

 

 

Fig. 12 Recognition results of the musical score The Swallow 
 

Fig. 13 shows the recognition results for the musical score I 
Will Sing You. The original image was in JPEG compressed 
format. All the musical notes, accidentals, and rests were 
successfully detected and recognized, despite there was a few 
errors in the recognition of the pitches. 

 

 

Fig. 13 Recognition results of the musical score I Will Sing You 

Fig. 14 shows the recognition results for the musical score At 
This Moment. The quality was relatively poor mainly because 
of compression distortion. The recognition results were 
relatively worse than previous scores. 

 

 

Fig. 14 Recognition results of the musical score At This Moment 
 

Fig. 15 shows the recognition results for the musical score 
My Herd. The quality was also relatively poor mainly because 
of compression distortion. The recognition results were 
relatively worse than previous scores especially in beat 
recognition (most recognition failure occurred at dots).  

 

 

Fig. 15 Recognition results of the musical score My Herd 

IV. CONCLUSION 

In this study, we proposed an Automatic Music Score 
Recognition System Using Digital Image Processing. The 
technical approaches included: staff region segmentation, 
image preprocessing, note recognition and accidental and rest 
recognition. Our system was developed to automatically detect 
and recognize musical notes, accidentals and rests in printed 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1816International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


 

musical scores.  
The results showed that the detection and the recognition 

rates of our system were 96.3% and 91.7%, respectively. While 
the results were limited and could be affected by image quality, 
our system was shown to achieve effective detection and 
recognition for musical symbols, such as notes, accidentals, and 
rests. Ultimately, our system could be incorporated with a 
media player that could play music/songs with inputs of 
musical scores.  

While our system has been demonstrated with success for 
different types of musical scores, our system was still limited 
with respect to the complexities of some musical scores (e.g., 
chords or other complex symbols). Improvement of our 
systems is still required for such musical scores. 

At present, our system was evaluated using personal 
computers with inputs of digital images. The system could be 
further integrated in applications for smart-phones or other 
mobile devices with built-in digital cameras. In addition, this 
system could be also used as a learning tool for players (e.g., 
piano players, guitar players, etc.) to play the music/songs even 
though they may not be familiar with the music/songs. 

REFERENCES  
[1] N. Otsu, “A Threshold Selection Method form Gray-Level Histograms,” 

IEEE Transactions on Systems, pp. 62-66, 1979. 
[2] R.G. Casey and E. Lecolinet, “A Survey of Methods and Strategies in 

Character Segmentation,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, pp. 690-706, 1996. 

[3] Cheng-Lin Liu, M. Koga and H. Fujisawa, “Lexicon-Driven 
Segmentation and Recognition of Handwritten Character Strings for 
Japanese Address Reading,” IEEE Transactions on Pattern Analysis and 
Machine Intelligence, pp. 1425-1437, 2002. 

[4] M. Sotoodeh and F. Tajeripour, “Staff Detection and Removal Using 
Derivation and Connected Component Analysis,” IEEE 16th CSI 
International Symposium on Artificial Intelligence and Signal Processing 
(AISP), pp. 54-57, 2012. 

[5] Chen Genfang, Zhang Liyin, Zhang Wenjun and Wang Qiuqiu, 
“Detecting the Staff-lines of Musical Score with Hough Transform and 
Mathematical Morphology,” IEEE International Conference on 
Multimedia Technology (ICMT) , pp. 1-4, 2010. 

[6] A. Dutta, U. Pal, A. Fornes and J. Llados, “An Efficient Staff Removal 
Approach from Printed Musical Documents,” IEEE International 
Conference on Pattern Recognition (ICPR), pp.1965-1968, 2010. 

[7] JaeMyeong Yoo, GiHong Kim and Gueesang Lee, “Mask Matching for 
Low Resolution Musical Note Recognition,” IEEE International 
Symposium on Signal Processing and Information Technology, pp. 
223-226, 2008. 

[8] F.Toyama, K. Shioji and J. Miyamichi, “Symbol Recognition of Printed 
Piano Scores with Touching Symbols,” Pattern Recognition, ICPR 18th 

International Conference, pp. 480-483, 2006. 
[9] F.Rossant and I. Bloch, “Optical Music Recognition Based on a Fuzzy 

Modeling of Symbol Classes and Music Writing Rules,” Pattern 
Recognition Letters, vol.23, pp. 1129-1141, 2002. 

[10] K.T. Reed and J.R.Parker, “Automatic Computer Recognition of Printed 
Music,” in Proceedings of the ICPR, pp.803-807, 1996. 

World Academy of Science, Engineering and Technology
International Journal of Computer and Information Engineering

 Vol:9, No:7, 2015 

1817International Scholarly and Scientific Research & Innovation 9(7) 2015 scholar.waset.org/1307-6892/10005799

In
te

rn
at

io
na

l S
ci

en
ce

 I
nd

ex
, C

om
pu

te
r 

an
d 

In
fo

rm
at

io
n 

E
ng

in
ee

ri
ng

 V
ol

:9
, N

o:
7,

 2
01

5 
w

as
et

.o
rg

/P
ub

lic
at

io
n/

10
00

57
99

http://waset.org/publication/Automatic-Music-Score-Recognition-System-Using-Digital-Image-Processing/10005799
http://scholar.waset.org/1307-6892/10005799


reading content from D:\SD\SearchEngine_ver1\Bee\CN3a_2022.doc

COMPUTER NETWORKS
OPTICAL FIBRES AND COMPONENTS

LABORATORY WORK NO. 3a
OPTICAL FIBERS AND COMPONENTS

1. Objectives
The objective of this work is gaining knowledge on optical fibers and components, link performance analysis and the optical power budget calculus.
2. Theoretical considerations 

2.1 Optical fibers and components
The current laboratory work continues the focus on the Physical layer of the ISO/OSI stack by providing knowledge on optical fibers and components. Furthermore, on part 3b, the main network devices and elements of structured cabling are presented.
Once the drop in the price of optical fibers, and appropriate communications equipment, this has become the environment of choice for new high-speed connections (exterior and interior). 
To transmit data, optical fibers send light signals along glass or plastic cores (of the order tens of microns (μ), which constitutes a wavelength guide for light, obtained from a combination of silicon dioxide and other elements). 

An optical fiber strand is the basic element of an optical fiber cable (a cable contains several strands). A strand has three layers: core, cladding and coating. A fiber optic cable consists of several components: fiber strand(s), buffer, protective materials, outer jacket.

The core is wrapped by material made of silicon dioxide having a refractive index lower than the core called cladding. In order to protect the cladding, this is wrapped in a plastic material. This is called buffer and is wrapped in a material, usually Kevlar, which confers resistance of fiber at the time of installation. Optical fiber buffers are of two categories: tight (a protective covering is applied over the coating of each fiber strand) or  loose-tube (several strands inside a tube filled with a protective gel). For outdoor, long-distance installation, loose-tube fiber is preferred. The last wrapper is the jacket which protects the fiber against abrasive materials, solvents and other factors. The color enclosure in the case of multimode optical fiber is usually orange and in the case of single-mode optical fiber is usually yellow. Each fiber optics cable is composed of two fibers wrapped separately, a fiber being used for transmission and another for the reception, ensuring in this way a full-duplex connection. A cable of optical fiber may contain from two up to hundred separate fiber strands (usually in LANs, up to 24). Figure 2.1 presents the layer of an optical fiber and an optical fiber transversal section.

	 

	Figure 2.1 a. Optical fiber layers               b. Optical fiber transversal section


For the signal to be reflected without loss, the following two conditions need to be met:

· Optical-fiber must have a refractive index higher than the material surrounding it;

· The angle of incidence of light signal must be greater than the critical angle of fiber and of the material surrounding it. The angle of incidence of light signal can be controlled by using the next two factors:

· Numerical aperture of the fiber is the range of angles of the light signal for which the reflection is complete;

· The modes are the ways that the signal light can follow.

Unlike copper-based transmission media, optical fiber is not susceptible to, and it does not generate electromagnetic or crosstalk interference.

Two main optical fibers are commonly used in LANs and WANs: single-mode and multimode. Single-mode optical fiber is used for long distance links and for vertical cabling in buildings (building’s backbone). Multimode optical fiber is commonly used in horizontal and vertical cabling. Multimode fiber has a larger core diameter compared to single-mode. Thus, multimode does not require the same precision as single-mode, resulting in less expensive connectors, transmitters etc.

For the single-mode fiber the core diameter is small enough as to permit only one mode (one way) light signal, being sent in a straight line through the middle of the core. Single-mode optical fiber cables use cores with diameter between 8μ and 10μ. The most used single-mode optical fibers have 9μ diameter and cladding with a diameter of 125μ. They are usually referred as 9/125μ optical fibers. Light source used is the infrared laser. It is recommended caution when using lasers as source of light since it may affect the eyes. Single-mode fibers may transmit data at distances over 100km. The loss on km of single-mode optical fiber is specified by the manufacturer. In the case of single-mode fiber, the refractive index of glass stays constant. This type of glass is called step index glass. 

The core of multimode fiber has a sufficiently large diameter as to permit several modes (several ways) for light signal. Standard multimode optical fiber cables have a core diameter of 62, 5μ or 50μ and cladding with a diameter of 125μ. They are usually referred as optical fibers of 62.5/125μ or 50/125μ. Usually, the light sources used with multimode fibers are Infrared Light Emitting Diode (LED) or Vertical Cavity Surface Emitting Lasers (VCSEL). LED-s are cheaper and require less safety measures than lasers. The disadvantage of LED is that may not transmit light signals at distances as large as lasers. Multimode fibers of 62.5/125 may transmit data at distances of up to 2000m. The loss of multimode optical fiber is specified by the manufacturer. In the case of multimode fiber, the refractive index of glass may be constant (multimode step index glass) or may also decreases from the center to the exterior  (variable or graded-index glass and allows various illuminating modes to reach the receiver at the same time). 
In optical fiber, beside propagation, the light is subjected to two main phenomena: attenuation and dispersion. Attenuation or absorption is essentially due to the presence of hydroxyl ions -OH and of the various metal ions. Light may also be spread by micro crystals, lower than the wavelength, which form at the cooling of the glass. Attenuation limits the length of optical fiber to be used. The dispersion or impulse width widening is mainly due in multimode fibers to the different length of the modes. The chromatic dispersion appears due to the variation of the refraction index function of the light colour or wavelength. The dispersion limits the use of optical fiber in the frequency or in bandwidth. The two limitations multiplied characterize most accurate an optical fiber. 20MHz-km values are obtained for fiber with step index, 1GHz-km for the variable index and 1000GHz-km for the single-mode in which there is no modal dispersion. 

Optical fiber transmitters convert electrical signals in equivalent luminous pulses. There are two types of light source used by transmitters for optical-fiber:
· The LED which produces infra-red light having a wavelength of 850nm or 1310nm. They are used with multimode fibers. Coupling to optical fiber can be improved by using a spherical lens;
· LASER semiconductor diode containing which produces infra-red light having a wavelength of 1310nm or 1550nm. They are used with multimode or single-mode fibers.
There are two types of basic design for LEDs: with surface emission and with edge emission. At surface emission led, the emission of light is perpendicular to the plane of junction through a thin transparent layer. They emit in a geometric radial spectrum. At edge emission led the light is emitted in a plane parallel to the junction at semiconductor edge. The materials used are often compounds III V as GaAs or Al×GA1-XAs for wavelengths of 0.8-0.9 μm and Ga×In1-XPYAs1-y for wavelengths of 1.3-1.6 μm. Emission spectrum of a LED is between 25 to 40 μm for small wavelengths and 50-100 μm for larger wavelengths.
LASER semiconductor diodes, laser diodes (LD), are obtained by introducing a led into an optical resonant cavity. The effect of laser only appears at the existence of a direct current high enough to achieve an inversion of the population of the electrons and holes from the two energy strips of conduction and valence. The current value from which this effect appears is called limit current. Under this current the device acts as an ordinary led. Since the light emitted by a laser is much more coherent than issued by a LED, the efficiency of the optical fiber coupling is higher. Optical power also captured by laser is greater than that emitted by the LED.
An analysis compared between the two types of transmitters is clearly in favour of LD because the possibility to use higher frequencies, narrower spectrum and in favour of the LED due to price and power stability in relation to temperature.
The life expectancy of both devices is equal and is of the order of 10 million hours.
The fiber optics receivers convert luminous pulses into equivalent electrical signals. Semiconductor devices normally used for optical fiber are classified in two types: simple and with internal gain. The first may be called PIN photodiode by type of doping (p intrinsic and n) and the second category is called APD (Avalanche Photo- Diodes). These devices are sensible at 850, 1310 and 1550nm wavelengths, wavelengths used by transmitters for optical fiber. As semiconductor materials are used Si for wavelengths of 800-900 nm and Ge or InGaAsP for 1300 and 1500 nm. Si has optimum sensitivity only within a reduced frequencies range but Ge has an appreciable darkness current and is more sensitive to noise. For this reason last possibility is the best but requires a more sophisticated manufacturing technology and therefore has a higher price. 

In order to connect multiple fibers or for achieving a longer fiber, splices (junctions) may be used. Splices are of two types: mechanical and fusion. Attenuations introduced are lower than 0.5dB (ANSI/TIA-568-C.3 specifies that mechanical or fusions splices shall not exceed a maximum optical insertion loss of 0.3dB). At mechanical splices the two ends of the fiber, carefully cut, cleaned and polished are caught in a rigid mechanical holder that they fix to each other in an fixed ensemble. Fusion splices shall be carried out by heating close to the melting point. At this moment the two fibers are pressed against one another and cooled. These operations shall be preceded by cutting operations and finishing their ends and prior alignment of the two ends which will be connected. Fusion splices also remake draw/bursting resistance of the fiber at approximate 90% of the original value. To protect the splices, splice enclosures are used.
Connectors in the optical fiber allow the connection to ports. The common used connectors are SC (Subscriber Connector) - snap on type, ST (Straight Tip) - twist on type, FC (Ferrule Connector) - screw on type, LC (Lucent Connector) - snap on type and MTP/MPO - push/pull type, for multimode optical fibers and for single-mode optical fibers. Attenuation introduced by an optical connector, even of superior quality is greater than that introduced by a splice, having values of approximately 1 dB. Connectors are high precision mechanical equipment and usually one end of the fiber is in the connector and one is free. In this case attaching a connector shall be reduced to the execution of a splice. Such a solution is usually more advantageous than mounting a connector directly to the end of the fiber because prefabricated connectors ensure the accuracy of mounting much higher. If the optical fiber is ended into an optical fiber terminator for redistribution this end connector is also called pig-tail and is prefabricated type. A special category of connectors is optical cords for distribution or connection. These are special optical fibers with connectors at both ends allowing small fiber curvature radii of approximately 2,5-5 cm. Their color is yellow for single-mode fiber and orange for multimode fiber
Repeaters are optical amplifiers receiving light signals attenuated as a result of the distance traveled through optical fiber, remake the form, power and time parameters of these signals and send them away.

Patch panels for optical fiber are similar with copper cable patch panels, increasing flexibility of the optical networks. For connecting different equipment, an optical fiber patch cord is used (also known as a zip cord - two flexible optical fibers with connectors at each end).
Additionally, several other active or passive devices are used with optical fibers (e.q.: optical couplers - combines or splits optical signals; optical attenuators - reduce the power level of an optical signal; optical isolators; fiber-optic switches; optical multiplexers, etc.).

The ISO/IEC 11801-1 specifies the  requirements for coaxial, twisted-pair copper and optical fiber. The ISO/IEC 11801 (Europe) and ANSI/TIA-568-C (USA and Canada) standards define 7 classes of optical fibers (single-mode and multimode) as shown in table 2.1, together with several important parameters (optical fiber requirements, the cable transmission performance and the physical cable requirements):
Table 2.1 Optical fiber characteristics
	
	Multimode
	Single-mode

	Type
	OM1
62,5/125 μm
	OM2
50/125 μm
	OM3
50/125 μm
	OM4
50/125 μm
	OM5
50/125 μm
	OS1
9/125 μm
	OS2
9/125 μm

	Wavelength
	850, 1300nm
	850, 1300nm
	850, 1300nm
	850, 1300nm
	850, 1300nm
	1300nm, 1550nm
(1383nm)
	1300nm, 1550nm

	Max. attenuation (db/km) 
	2.6 / 
2.4
	3.56 / 2.3
	2.6 / 
1.9
	2.9 / 
1.5
	2.9 / 
1.5
	1
	0.4

	Light source
	LED (Light-Emitting Diode) / 
VCSEL (Vertical Cavity Surface-Emitting Lasers Light Source) 
	LASER (Light Amplification by Stimulated Emission of Radiation)

	Distance/ data rate
	1 Gbps
	275m
	550m
	-
	-
	-
	5-120km

	
	10Gbps
	33m
	82m
	300m
	400m
	400m
	10-80km

	
	40-100 Gbps
	-
	-
	100m
	150m
	150m
	2-80km

	Color
	orange/ slate
	orange
	aqua
	violet/ aqua
	green/ lime
	yellow
	yellow



Incorrect installation of optical fiber has as result the increase in attenuation for the optical signal. The scope or exaggerated than optical fiber may cause cracks in the heart to disperse the signal light. Exaggerated stretching or bending of the optical fiber may cause small cracks of the core which will scatter the light signal. Exaggerated bending of the optical fiber may have as a result the drop in incident angle of the light signal under critical angle of total reflection. For the connector installation the heads must be cut off and finished. After installation, the heads of the optical fibbers, the fiber connectors and ports must be kept clean so that no attenuation will be introduced. Before use of optical fiber cables, their attenuation must be tested. At the design of an optical-fiber links, loss of power signal that can be tolerated must be calculated. This is called the budget of loss of optical link. Loss of power is measured in decibels (dB).
For optical fiber link testing there are several methods: continuity testing, visual fault locator, measurement of optical power output, OTDR and BER test error rate.

Continuity testers are used to test the continuity in an optical fiber. A visual fault locator (VFL) tool allows a technician to identify breaks, macrobends (refers to the minimum bending radius) or poor fusion splices.

The measurement of optical power output determines the loss of power through the optical link by measuring the output power at a known input power. The unit of measurement for optical power is the miliwatt (mW) but for practical reasons shall be used other unit of measure which measure the gain (G) or loss (L) in a system, namely decibel (DB).
The procedure OTDR Optical Time Domain Reflectometer is the procedure by which the attenuation characteristics of an optical fiber and its length may be visualized. This procedure is the only through which can be detected positions such breaks in optical fibre. OTDR displays a graphic having as X axis the fibre length and as Y axis the attenuation. From this graphic, the fiber attenuation and the splices and connectors quality can be deduced. Also can be determined the braking position in the cable if externally the cable is not affected.

The BER test (Bit Error Rate) is the final test for a data link through optical fiber. This test or criterion shows at how many bits transmitted through the fibre an error due fibre will be produced. The BER test must meet the requirements imposed by the producers of the DTE equipment that are coupled to the optical fibre. For computer networks they ask to be less than 1 bit of error at 109/1012 bits transmitted or BER < 10-9/10-12. For the testing is required a generator of random bit sequence and an interface to optical fibre if a loop is tested or two if a single fibre is tested. In order to have significant results, the test must be carried out over a period long enough so as to provide a sufficient number of bits. The test period of one day or two are common if it is working at a large bit rate in the use of optical fibre link and small BER. A counter may automatically count the number of errors detected.

Calculation of optical power budget shall be made according to the following table.
Table 2.2 Optical power budget

	Crt. 
	Optical loss or power
	DB 

	1. 
	The km loss in Optical Fibre db/km X _____km fibre
	_____dB 

	2. 
	The loss in Splices ___dB/splice X _____splices
	_____dB 

	3. 
	The loss in Connectors __dB/connector X ___ connectors
	_____dB 

	4. 
	Losses on other components
	_____dB 

	5. 
	Margin of error
	_____dB 

	6. 
	Total loss on the Link (1+2+3+4+5)
	_____dB 

	7. 
	The power of average emission of the transmitter
	_____dB 

	8. 
	Average power received by the receiver (7-6) 
	_____dB 

	9. 
	The dynamic of the receiver _____dB at _____dB
	 

	10. 
	Receiver sensitivity at a rate of errors given by BER
	_____dB 

	11. 
	Available Remaining Power  (8-10)
	_____dB 


Remarks 

For item 3. the transmitter connection losses to the optical will not be taken into account, these being already included. The amount calculated in item 8. must be within the range of item 9. for the receiver to operate correctly. The amount calculated in item 11 must be positive in order to have a functional optical data link. 
The error margin is due to take into account the average values for all link components. The dispersion of these values around the mean value is known and may take a margin of error large enough to cover deviations from an average with a probability of 99.9% or more. As the number of items is greater and as it is desirable a larger cover probability than a larger error margin will be taken.
Optical emission power of the transmitter is a catalogue data and includes the loss of connection at one end of the optical fiber in the case in which the connection is made in accordance with recommendations. The power is greater at the LASER diodes and smaller at the LED. In the case of LASER usage for relatively short distances an attenuator is necessary so that the receiver will not be destroyed.
Receiver dynamics represents the power range which a receiver can transform in electrical signal without loss of information.
It is also needed a minimum optical power necessary for fulfilling the tolerated error rate condition which for computer networks is situated at the value of 1 bit erroneous at one billion bits transmitted.
Calculus example of the optical power budget 
Optical fiber diameter: Core 62.5μm/Cladding 125μm.
Numerical aperture of the fiber NA: 0.275.
The wavelength of the optical equipment: 1310μm. 

Table 2.3 Calculus example
	Crt. 
	Optical loss or power
	DB 

	1. 
	The km loss in Optical Fiber 1,8db/km X 3,5km fiber
	6,3dB 

	2. 
	The loss in Splices 0,5dB/splice X 2 splices
	1,0dB 

	3. 
	The loss in Connectors 1,0dB/connector X 2 connectors
	2,0dB 

	4. 
	Losses on other components
	0,0dB 

	5. 
	Margin of error
	2,0dB 

	6. 
	Total loss on the Link (1+2+3+4+5)
	11,3dB 

	7. 
	The power of average emission of the transmitter
	-10,0dB 

	8. 
	Average power received by the receiver (7-6) 
	-21,3dB 

	9. 
	The dynamic of the receiver _____dB at _____dB
	

	10. 
	Receiver sensitivity at a rate of errors given by BER
	-26,0dB 

	11. 
	Available Remaining Power  (8-10)
	+4,7dB 


The power at the receiver is in the dynamic of the receiver, which makes possible its function, and the remaining available power is positive, ensuring a viable connection.

There should be taken into account the fact that during the life of the link, aging phenomena may occur, leading to increase the power loss, as well as the fact that optical fiber may be broken accidentally and needs to be spliced. 

A calculation made to the limit endangers the length of service of a link through optical fiber.

3. Lab activity
3.1 The characteristics of various types of optical fibers, components and aspects related to the cabling of computer networks using this transmission environment should be discussed.
3.2 Explore the fiber optic infrastructure deployed in the oceans available at https://www.submarinecablemap.com/
3.3 A 9/125μ single-mode optical fiber having the length of 2,5km and the loss equal to 0,5dB/km, which connects two DTE equipments is considered. The attenuation introduced by splices and connectors is equal to 0,5 and 1dB respectively. The error margin taken into consideration is 3dB. The power of average emission of the transmitter is -15dB, the receiver sensitivity at a rate of errors given by BER 10-9 is -25dB and dynamic of the receiver is in the range -10 ÷ -30dB. Calculate the optical power budget.

Notes

6
7


reading content from D:\SD\SearchEngine_ver1\Bee\CN4.docx

LABORATORY WORK NO. 4
Network Layer – IPv4 Fundamentals

1. Objectives

At the end of the lab, students will be able: to explain the characteristics of the network layer, to describe the operation of the IPv4 protocol, to divide the networks into subnets, to explain the network address translation process, and to implement basic IPv4 network configurations.

2. Theoretical considerations

2.1 Network layer

The OSI Network layer corresponds to the TCP/IP Internet layer. It provides addressing, routing and traffic control services to allow devices to exchange data across networks and contains different types of protocols:
· IP version 4 (IPv4) and IP version 6 (IPv6) routed protocols;
· routing protocols such as Open Shortest Path First (OSPF) or Border Gateway Protocol (BGP);
· messaging protocols such as Internet Control Message Protocol (ICMP).
The network layer performs four basic operations:
· Addressing
· Encapsulation
· Routing
· De-encapsulation





IP protocols have the following characteristics:

· Connectionless
· no connection established between source and destination before data packets transmission;
· no control information (synchronizations, acknowledgments, etc.).

· Best Effort
· unreliable, packet delivery is not guaranteed;
· no mechanism to resend data that is not received, reduced overhead.

· Media Independent
· does not concern itself with the type of frame required at the data link layer or the media type at the physical layer;
· can be sent over any media type: copper, fiber, or wireless.

2.2 IPv4

The packet header is presented below:

	Octet
	0
	1
	2
	3

	Bit
	0
	1
	2
	3
	4
	5
	6
	7
	8
	9
	10
	11
	12
	13
	14
	15
	16
	17
	18
	19
	20
	21
	22
	23
	24
	25
	26
	27
	28
	29
	30
	31

	0
	Version
	IHL
	DSCP
	ECN
	Total Length

	32
	Identification
	Flags
	Fragment Offset

	64
	Time To Live
	Protocol
	Header Checksum

	96
	Source IP Address

	128
	Destination IP Address

	160
	Options



· Version - version field, equal to 4;
· Internet Header Length (IHL) - the size of the IPv4 header;
· Differentiated Services Code Point (DSCP) - originally defined as the type of service (ToS), specifies differentiated services (DiffServ);
· Explicit Congestion Notification (ECN) - allows end-to-end notification of network congestion without dropping packets, optional feature;
· Total Length - defines the entire packet size in bytes, including header and data;
· Identification- identification field, primarily used for uniquely identifying the group of fragments of a single IP datagram;
· Flags - used to control or identify fragments;
· bit 0 – Reserved, must be zero;
· bit 1 – Don't Fragment (DF)
· bit 2 – More Fragments (MF)
· Fragment offset –specifies the offset of a fragment relative to the beginning of the original unfragmented IP datagram;
· Time to live (TTL) – limits a datagram's lifetime;
· in practice, is used as a hop count;
· when the datagram arrives at a router, the router decrements the TTL field by one;
· when the TTL field hits zero, the router discards the packet and sends an ICMP time exceeded message to the sender.
· Protocol –defines the protocol used in the data portion of the IP datagram;
· Header checksum – used for error-checking of the header;
· Source address – the IPv4 address of the sender of the packet;
· Destination address – the IPv4 address of the receiver of the packet;
· Options – rarely used, if IHL is greater than 5, the options field is present.

The addresses can be assigned statically or dynamically.
The address is hierarchical, being composed of two parts: the network part and host part.

	Network ID
	Host ID



The number of bits assigned to the network and host depends on the class to which the address belongs:

	Class
	1st Octet Decimal Range
	1st Octet High Order Bits
	Network/Host ID (N=Network, H=Host)
	Default Subnet Mask

	A
	1 – 126*
	0
	N.H.H.H
	255.0.0.0

	B
	128 – 191
	10
	N.N.H.H
	255.255.0.0

	C
	192 – 223
	110
	N.N.N.H
	255.255.255.0

	D
	224 – 239
	1110
	Reserved for Multicasting

	E
	240 – 255**
	1111
	Experimental; used for research


Note:	* Class A addresses 127.0.0.0 to 127.255.255.255 cannot be used and is reserved for loopback and diagnostic functions.
** 255.255.255.255 is reserved as the IPv4 Broadcast address.
The IPv4 subnet mask is used to differentiate the network portion from the host portion of an IPv4 address. It is, like the IPv4 address, a 32 bits structure. The bits corresponding to the network portion are set to 1 and the bits corresponding to the host portion are set to 0.

	Network ID
	Host ID

	11………..1
	00…………………………………………………..0



The network masks corresponding to the classes are presented below:

Class A: 255.0.0.0 or /8 (11111111.00000000.00000000.00000000)
Class B: 255.255.0.0 or /16 (11111111.11111111.00000000.00000000)
Class C: 255.255.255.0 or /24 (11111111.11111111.11111111.00000000)

Public IPv4 addresses are uniquely assigned addresses and are are globally routed between internet service provider (ISP) routers. There are also blocks of addresses, called private addresses, that are used by most organizations to assign IPv4 addresses to internal hosts. These addresses are not uniquely assigned addresses and are are not globally routed between ISP routers. These blocks of private addresses are presented below.
Class A: 10.0.0.0 - 10.255.255.255		/8
Class B: 172.16.0.0 - 172.31.255.255		/12
Class C: 192.168.0.0 - 192.168.255.255	/16

To allow a device with a private IPv4 address to access devices and resources outside of the local network, the private address must be translated to a public address. This process is called network address translation (NAT) and provides the translation of private addresses to public addresses. A NAT router typically operates at the border of a network. When a device inside the network wants to communicate with a device outside of its network, the packet is forwarded to the border router which performs the NAT process, translating the internal private address of the device to a public, outside, routable address.






The network address has all the host bits set to 0 and the broadcast address has all the bits set to 1. These addresses cannot be assigned to a host. All the other addresses are valid host addresses.

Exercise
Consider the following address: 192.168.1.10/24. Calculate the network and broadcast address, the valid host range, the total number of host bits and the total number of hosts.
IP:	11000000.10101000.00000001.00001010
NM:	11111111.11111111.11111111.00000000
IP logic AND with the NM:
11000000.10101000.00000001.00001010
11111111.11111111.11111111.00000000
--------------------------------------------------
11000000.10101000.00000001.00000000 – Network address (all host bits are set to 0)
192.168.1.0 – Network address
11000000.10101000.00000001.11111111 – Broadcast address (all host bits are set to 1)
192.168.1.255 – Broadcast address
11000000.10101000.00000001.00000001 – First valid host address
192.168.1.1 – First valid host address
11000000.10101000.00000001.11111110 – Last valid host address
192.168.1.254 – Last valid host address
192.168.1.1-192.168.1.254 – Valid host range
Total number of host bits is 8.
Total number of hosts is 28-2=254.

2.3 Subnetting

To create subnets, bits are borrowed from the host ID. A new network mask is created to show the new structure. In the network mask, the bits corresponding to the subnetwork portion are set to 1.


	Network ID
	Host ID

	11………..1
	00…………………………………………………..0

	Network ID
	Subnetwork ID
	Host ID

	11………..1
	11……………………..1
	00……………………0



Exercise
Consider the following address: 192.168.1.0/24. Divide this address in 4 subnets and further divide the fourth subnet into a maximum number of subnets. Specify for the subnets: netmask, network address, broadcast address, the number of host bits, the number of hosts and their address range.

We will borrow 2 bits to obtain 4 subnets. In order to further divide the fourth subnet into a maximum number of subnets, we will reserve for the host portion 2 bits, the minimum possible number.





First /26 subnet:
	Network Subnetwork Host
	

	11000000.10101000.00000001.00000000
	192.168.1.0/26 - Network Address

	11000000.10101000.00000001.00000001
	192.168.1.1/26 - First Host Address

	…
	…

	11000000.10101000.00000001.00111110
	192.168.1.62/26 - Last Host Address

	11000000.10101000.00000001.00111111
	192.168.1.63/26 - Broadcast Address


Netmask: /26 (255.255.255.192)
Network address: 192.168.1.0/26
Broadcast address: 192.168.1.63/26
Number of host bits: 6
Number of hosts: 26-2=62
Hosts address range: 192.168.1.1/26-192.168.1.62/26

First /30 subnet:
	Network Subnetwork Host
	

	11000000.10101000.00000001.11000000
	192.168.1.192/30 - Network Address

	11000000.10101000.00000001.11000001
	192.168.1.193/30 - First Host Address

	11000000.10101000.00000001.11000010
	192.168.1.194/30 - Last Host Address

	11000000.10101000.00000001.11000011
	192.168.1.195/30 - Broadcast Address


Netmask: /30 (255.255.255.252)
Network address: 192.168.1.192/30
Broadcast address: 192.168.1.195/30
Number of host bits: 2
Number of hosts: 22-2=2
Hosts address range: 192.168.1.193/30-192.168.1.194/30

3. Lab activity

3.1 Discuss the theoretical aspects.
3.2 Solve the following problems:
A. Determine the network and broadcast addresses and number of host bits and hosts for the given IPv4 addresses and prefixes:
	IPv4 
Address/Prefix
	Network Address
	Broadcast Address 
	Total Number 
of Host Bits 
	Total Number 
of Hosts

	172.16.104.99/27
	
	
	
	

	198.133.219.250/24
	
	
	
	

	10.1.113.75/19
	
	
	
	



B. Having the following information, compute subnets with the following constrains:
· A number of 62 subnets
· Host IP Address: 172.16.0.0
· Original Subnet Mask 255.255.0.0

C. Having the following information, compute subnets with the following constrains:
· A maximum number of 29 hosts/subnet
· Host IP Address: 192.168.200.0 
· Original Subnet Mask 255.255.255.0

D. Having the following information, compute subnets with the following constrains:
· A number of 250 subnets
· Host IP Address: 10.0.0.0
· Original Subnet Mask 255.0.0.0

3.3 Test the following commands (using Command Prompt on Windows OS or Terminal in Linux OS):

· Command: ipconfig /all (on Windows OS) and ifconfig (on Linux OS)
· Role: displays all network configuration values for your network interface cards

· Command: ipconfig /release and ipconfig /renew (on Windows OS) and dhclient (on Linux OS)
· Role: refreshes DHCP and DNS values

· Command: ping
· Role: troubleshoots network connectivity; verifies IP connections, using ICMP packets

· Command: tracert (traceroute on Linux)
· Role: troubleshoots network connectivity; resolves the path to an IP destination, using ICMP packets

· Command: nslookup
· Role: performs DNS queries

· Command: route print 
· Role: displays the routing table of the host device

· Command: netstat
· Role: network statistics tool

· Command: arp -a 
· Role: displays the ARP cache (mapping of IP address to a physical addresses)

Hint: you can use online operating systems to test various commands (e.g. https://bellard.org/jslinux/ for Alpine Linux or Windows 2000)

3.4 Using Wireshark, capture different types of IP packets and analyze their headers. For example:
· capture ping traffic by filtering the ICMP protocol filter 
· capture nsloookup traffic by filtering the DNS protocol filter
· etc.

3.5 Configure and test the following network using Packet Tracer:






Considering IP address 172.16.0.0 /16, compute 2 subnets and assign the correct IP address to the routers’ interfaces and to the host computers (PC0 and PC1).

Step 0: In order  to show the interface name and numbers, go to Options -> Preferences and check “Always Show Port Labels in Logical Workspace”



Step 1: Create the two subnets

Step 2: Before configuring the network devices, assign a unique IP address and he corresponding subnet mask to each network port:

	Device
	Interface
	IP Address
	Subnet mask

	PC0
	 Fa0
	172 . ___ . ___ . ___
	___ . ___ . ___ . ___

	Router0
	Gig0/0
	___ . ___ . ___ . ___
	___ . ___ . ___ . ___

	Router0
	Gig0/1
	___ . ___ . ___ . ___
	___ . ___ . ___ . ___

	PC1
	Fa0
	___ . ___ . ___ . ___
	___ . ___ . ___ . ___



Step 3: Configure the router using the commands provided in steps 3.x below. The commands provide sample interface names and IP addresses. You must use the interface names and the IP addresses filled in the previous table:

Example on configuring the depicted topology

COMPUTER NETWORKS
Network Layer – IPv4 Fundamentals






Step 3.1: Enter configuration mode on the router
Router>enable
Router#configure terminal 
Router(config)# 

Step 3.2: Assign static IPv4 address to the router interfaces

Router(config)#interface fastethernet 0/0
Router(config-if)#ip address 192.168.0.1 255.255.255.0 
Router(config-if)#no shutdown
Router(config-if)#exit

Configure the other router interface with the corresponding IP address the same for the other router interface
Router(config)# interface ___
Router(config-if)#ip address ___________ ___________
Router(config-if)#no shutdown 

Step 3.3: Display information about the router configuration

Router#show ip interface brief
Description: Display IP information about router’s interfaces

Router#show ip route
Description: Display IP routing table

Step 4: Configure IP addresses on the PCs using the following screenshots






Test the connectivity.
a. check IP addresses oh hosts computers: PC -> Desktop -> IP Configuration
b. Check connectivity between computers using the ping <target IP> command: PC -> Desktop -> Command prompt



Notes



image5.png

image7.png

image8.png

image4.png

image9.png

image3.png

image11.png

image10.png

image6.png

image2.png

image1.png


reading content from D:\SD\SearchEngine_ver1\Bee\CN6.docx


COMPUTER NETWORKS
Network Layer – IPv6
LABORATORY WORK NO. 7
Network Layer – IPv6

1. Objectives

At the end of the lab, students will be able: to explain the characteristics of the IPv6 protocol, to describe the dynamic IPv6 configuration, to explain the routing process, and to implement basic IPv6 network configurations.

2. Theoretical considerations

2.1 IPv6

IPv6 was developed by the Internet Engineering Task Force (IETF) to overcome the limitations of IPv4.
The main limitation of IPv4 is the exhaustion of addresses because the address request is larger than the address space provided by the 32 bits of the address. The solution for the IPv4 address depletion is private addressing and NAT. This solution in turn creates several drawbacks such as lack of end-to-end connectivity and increased network complexity.
IPv6 provides the following improvements:
· Increased address space based on 128 bit address;
· Improved packet handling due to the simplified header with fewer fields;
· Eliminates the need for NAT by eliminating the need for private addresses.

The packet header is presented below:



· Version - version field, equal to 6;
· Traffic class - equivalent to DiffServ – DS field;
· Payload length – indicates the length of the payload of the IPv6 packet;
· Next header – defines the next level protocol;
· Hop limit – replaces the Time to live field in IPv4;
· Source address – the IPv4 address of the sender of the packet;
· Destination address – the IPv4 address of the receiver of the packet;

IPv6 packet may contain extension headers, placed between IPv6 header and the payload, providing optional network layer information. Routers do not fragment IPv6 packets.

IPv6 addresses are 128 bits in length. The preferred format for writing an IPv6 address is x:x:x:x:x:x:x:x, with each “x” consisting of four hexadecimal values, 4 bits being represented by a hexadecimal digit. Hextet is an unofficial term, it refers to a segment of 16 bits (4 values in hexadecimal). Example of an IPv6 addresses in the preferred format:

	Type
	Format

	Preferred
	2001:0b20:0000:00d7:0000:0000:0000:0012



There are two rules to reduce or compress IPv6 representation. The first rule is to omit the zeros that are at the beginning of each hextet - leading 0s (zeros).

	Type
	Format

	Preferred
	2001:0b20:0000:00d7:0000:0000:0000:0012

	No leading 0s
	2001:b20:0:d7:0:0:0:12



The second rule is to omit the segments (hextets) that contain all the bits 0 and replace them with "double colon" (::). This replacement can be done only once

	Type
	Format

	Preferred
	2001:0b20:0000:00d7:0000:0000:0000:0012

	No leading 0s
	2001:b20:0:d7:0:0:0:12

	Compressed
	2001:b20:0:d7::12

	or
	

	Compressed
	2001:b20::d7:0:0:0:12



Types of IPv6 addresses:
· Unicast
· Uniquely identifies an interface
· The source address must be unicast
· Multicast
· It is used to send a single IPv6 packet to multiple destinations
· IPv6 does not have a broadcast address, but there is a multicast address that provides the same result
· Well-Known Multicast Addresses
· ff02 :: 1: All IPv6 devices
· ff02 :: 2: All IPv6 routers
· ff02 :: 5: All OSPFv3 routers
· ff02 :: a: All EIGRP (IPv6) routers
· Anycast
· Any unicast address that can be assigned to multiple devices
· A packet sent to anycast address is routed to the nearest device with that address

IPv6 prefix length indicates the network portion of an IPv6 address. It is represented in slash notation and can range from 0 to 128. The recommended IPv6 prefix length for LANs is /64. Example of an IPv6 address and prefix length: 2001:b20:0:d7::12/64

	Prefix (64 bits)
	Interface ID (64 bits)

	2001:0b20:0000:00d7
	0000:0000:0000:0012



Types of unicast addresses:
· Global Unicast Address (GUA)
· Globally unique
· Routable on the Internet
· Similar to a public IPv4 address
· Link-local Address (LLA)
· Required for every IPv6-enabled device
· Created even if the device has not been assigned a global unicast address
· For communication with other devices from the same local link
· Allow devices to communicate only on the same link
· Unique only in the local link
· Not routable on the Internet
· They are in the range FE80::/10
· The router's link-local address is usually used as the default gateway
· Unique Local Address (ULA)
· Local addressing within a site or between a limited number of sites



Structure of the Global Unicast Addresses (GUA)
· Global routing prefix
· Network
· Portion of the address assigned by the provider
· Typical /48
· Subnet ID
· For subnetting in an organization
· Usually, 16 bits
· Interface ID
· The equivalent of the host portion of an IPv4 address
· Usually, 64 bits
Example of an IPv6 global unicast address: 2001:b20:0:d7::12/64

	Global Routing Prefix
	Subnet ID
	Interface ID

	2001:0b20:0000
	00d7
	0000:0000:0000:0012



2.2 Host configuration

Methods:
· Static
· Manual configuration of the IPv6 address
· Dynamic
· Stateless Address Autoconfiguration (SLAAC)
· Stateful DHCPv6

A device obtains the IPv6 addressing information dynamically, through Internet Control Message Protocol version 6 (ICMPv6) messages. IPv6 routers periodically send out ICMPv6 Router Advertisement (RA) messages to all IPv6-enabled devices on the network. An RA message will also be sent in response to a host sending an ICMPv6 Router Solicitation (RS) message, which is a request for an RA message.
The ICMPv6 RA message is a suggestion to devices on how to obtain IPv6 addressing information. The ICMPv6 RA message includes the following:
· Network prefix and prefix length
· Default gateway address
· DNS addresses and domain name

There are three methods for RA messages:
· Method 1: SLAAC - prefix, prefix length, and default gateway address
· Method 2: SLAAC with a stateless DHCPv6 server – partial information, the rest of the information, such as DNS addresses, needs to be obtained from a stateless DHCPv6 server
· Method 3: Stateful DHCPv6 (no SLAAC) - default gateway address, the rest of the information, needs to be obtained from a stateful DHCPv6 server

The decision of how a client will obtain IPv6 addressing information depends on the settings within the RA message. An ICMPv6 RA message includes three flags to identify the dynamic options available to a host, as follows:
· A flag - Address Autoconfiguration flag. Use Stateless Address Autoconfiguration (SLAAC) to create an IPv6 GUA.
· O flag - Other Configuration flag. Other information is available from a stateless DHCPv6 server.
· M flag - Managed Address Configuration flag. Use a stateful DHCPv6 server to obtain an IPv6 GUA.

· Method 1 - SLAAC



· Method 2 - SLAAC with a stateless DHCPv6 server



· Method 3 - Stateful DHCPv6 (no SLAAC)



3. Lab activity

3.1 Discuss the theoretical aspects.

3.2 Consider the network topology below:



Step 1: Before configuring the network devices, discuss the IPv6 address assignment in the table below:

	Device
	Interface
	IPv6 Address

	Laptop 1
	Fa0
	DHCPv6

	Laptop 2
	Fa0
	DHCPv6

	R1
	Gig0/0
	2001:1:1:1::1/64
fe80::1 link-local 

	R1
	Gig0/1
	2001:1:1:2::1/64

	R2
	Gig0/1
	2001:1:1:2::2/64
fe80::2 link-local 

	R2
	Gig0/0
	2001:1:1:3::1/64


Note*: pay attention to the interface names of the router you are using, some routers may only have FastEthernet interfaces.

Step 2: Assign hostnames, enable IPv6 routing and assign static IPv6 addresses to router interfaces.

Example:
R1>enable 
R1#configure terminal 
Enter configuration commands, one per line.  End with CNTL/Z.
Router(config)#hostname R1
R1(config)#ipv6 unicast-routing 
R1(config)# interface gigabitEthernet 0/0
R1(config-if)#ipv6 address fe80::1 link-local 
R1(config-if)#ipv6 address 2001:1:1:1::1/64
R1(config-if)#no shutdown

Use the following command to display the IPv6 addresses configured on the router:
R1#show ipv6 interface brief

Step 3: Configure a static route on each router pointed to the IPv6 address of Gig0/1 on the other router. For R1 router specify the LLA address for the next hop and for the R2 router specify the GUA address the next hop. Discuss the differences!

R1(config)#ipv6 route 2001:1:1:3::/64 GigabitEthernet0/1 FE80::2

R2(config)# ipv6 route 2001:1:1:1::/64 2001:1:1:2::1

Use the following command to display the IPv6 routing table:
Router#show ipv6 route

Step 4: Verify SLAAC Address Assignment.





Step 5: Test the connectivity between end devices from opposite networks.
a. ping <target IP>
b. tracert <target IP>



Step 6: Replace the configured static routes with default routes and test the connectivity between end devices from opposite networks. In IPv6, the default route is ::/0.

R1(config)#no ipv6 route 2001:1:1:3::/64 GigabitEthernet0/1 FE80::2
R2(config)#no ipv6 route 2001:1:1:1::/64 2001:1:1:2::1

R1(config)#ipv6 route ::/0 ______________________________________
R2(config)#ipv6 route ::/0 ______________________________________

Step 7: Configure R1 to provide stateless DHCPv6 for Laptop 1.

R1(config)#ipv6 dhcp pool R1_NET1
R1(config-dhcpv6)#dns-server 2001:1:1:1::F
R1(config-dhcpv6)#domain-name NET1.com
R1(config-dhcpv6)#exit
R1(config)#interface gigabitEthernet 0/0
R1(config-if)#ipv6 nd other-config-flag 
R1(config-if)#ipv6 dhcp server R1_NET1

Step 8: Verify stateless DHCPv6 Address Assignment.







Step 9: Configure R2 to provide stateful DHCPv6 for Laptop 2.

R2(config)#ipv6 dhcp pool R2_NET3
R2(config-dhcpv6)# address prefix 2001:1:1:3::/64
R2(config-dhcpv6)#dns-server 2001:1:1:3::A
R2(config-dhcpv6)#domain-name NET3.com
R2(config-dhcpv6)#exit
R2(config)#interface gigabitEthernet 0/0
R2(config-if)#ipv6 nd managed-config-flag
R2(config-if)#ipv6 dhcp server R2_NET3

Step 10: Verify stateful DHCPv6 Address Assignment





Step 11: Test the connectivity between end devices from opposite networks.
a. ping <target IP>
b. tracert <target IP>




Notes



12

11

image3.png

image4.png

image5.png

image6.png

image7.png

image8.png

image9.png

image10.png

image11.png

image12.png

image13.png

image14.png

image1.png

image2.png


reading content from D:\SD\SearchEngine_ver1\Bee\CN7.docx

LABORATORY WORK 
Application Layer: Network programming with sockets


1. Objectives
Prerequisite: Use a working software environment for your preferred programming language (Java, C#, Python, C/C++, etc.) 
At the end of the activity, students will be able to write software for socket applications and debug network applications using Wireshark.

2. Theoretical considerations
The current practical work focuses on the Transport and Application layers of the ISO/OSI stack (Figure 8.1).

Figure 8.1 Network stack models and PDU naming in each level. The arrows indicate the addressed layers in the current activity
This practical activity addresses the programming side of software engineering and communication offered through the use of network sockets in a desktop environment. Socket programming is available in any high level programming language and sockets are transmitting information at the Application Layer. Sockets are used in different types of applications, such as: Client-Server, peer-2-peer systems, inter-process communication (on the same machine).
Network sockets can be constructed to use both IPv4 and IPv6 addresses. A socket is the combination of an IP address and a port number for use in a network application. A network application provides connectivity between different network devices. It is not possible to bind a socket to a port that is already in use by any other application, however the same port may be used concurrently by TCP and UDP transport layer protocols. The IP addresses identify the network device, but the port number uniquely identifies each running application on the current network device.
The operations that an application can perform on a socket are the following:
· Create - Creation of a socket object 
· Bind - Configure the socket object to use a local pair of IP address and port number to accept connections
· Listen - Program the socket to wait for incoming connections
· Accept - Accept the incoming connection
· Connect - This operation is used by a client that wants to connect to a server
· Send - Used to send data over the socket to the remote destination
· Receive - Used to receive data which is sent from a remote location
· Close - close the connection between the two sockets
2.1. Working with sockets on the local machine
· In order to simulate a network on the local machine, the entire available loopback range: 127.0.0.0 - 127.255.255.255 can be used. The loopback network interface is available only on the local host and is mainly used for diagnostics and standalone network applications. Therefore, a simulated local network can use these IP addresses for communication. In order to test and confirm that this range can be used, a ping command can be run from the local terminal to verify connectivity to said IP addresses (Figure 8.2):

Figure 8.2 Loopback addresses testing
· It is also possible to assign multiple valid IP addresses on the local interface, but this has to be done manually by statically allocating IP addresses to the interface. In this case, running the ipconfig command would show all the IP addresses assigned to the same interface. See an example below (Figure 8.3):

Figure 8.3 IP configuration view - CLI
· After having assigned the IP addresses, sockets can now be created to use these IP addresses.

2.2. TCP Sockets
· TCP (Transmission Control Protocol) sockets are connection oriented and represent a reliable data transmission mechanism that allows data to be received and processed in the same order it was transmitted.
· The Figure 8.4 shows a Wireshark traffic capture on the “Adaptor for loopback traffic capture”. The screenshot shows a client-server communication via sockets using the loopback addresses. The applied filter is tcp.port == 1234. The server is bound to the 127.0.0.1 address and awaits connections on port number 1234 while the client binds on the 127.0.0.2 address sending a payload of 14 bytes to the server.

Figure 8.4 Wireshark capture of TCP socket communication
· The screenshot highlights the TCP mechanism represented by acknowledgement (ACK) packets. The first three packet exchanges (Figure 8.4) represent the 3-way handshake which is needed to establish the connection for any TCP connection (Figure 8.5) and following that the packet sending the payload is visible. This handshake assures that both hosts want to communicate and acknowledge the other host’s intention to communicate.

Figure 8.5 TCP 3-way handshake
· The Wireshark image shows a socket communication which remains open.
· Answer the following question while working on the practical activity: If the socket connection is closed, what are the TCP flags that are set in order to close the connection?
2.3. UDP Sockets
· In contrast with the TCP sockets, UDP (User Datagram Protocol) sockets are not connection oriented and they do not provide reliable communication. This means they do not guarantee that network packets are delivered to the destination. The Figure 8.6 represents a Wireshark capture (again on the “Adaptor for loopback traffic capture”) of a UDP communication between two hosts. The applied filter is udp.port == 1234. As can be seen, there is no handshake performed and there aren’t any ACK packets being transmitted.

Figure 8.6 Wireshark capture of UDP socket communication
TCP and UDP socket communications are presented in Figure 8.7 a and b.
	
	


	1. TCP socket communication
	1. UDP socket communication


Figure 8.7 Socket communications

1. Implementation template
· A network device can function in 3 modes:
· Server: Receiving device
· Client: Sending device
· Relay: Acting as an intermediary node in a communication and acts as both sending and receiving device. This type of network node can be encountered in Wireless Sensor Networks (WSN) where not all sensor nodes are in the wireless range of the collector device, therefore some nodes need to forward the information to the sink node (the collector node).
· This chapter provides a template for implementing the relay communication node using OOP concepts (the template is written in pseudocode, not in a particular programming language). This is not the only possibility to organize the code, students can choose any software design methodology they are comfortable with.
	Relay node implementation template

	class RelayNode {
public:
    RelayNode(IPAddress, serverPortNr) {
        m_server.listen(IPAddress, serverPortNr);
        m_client.bind(IPAddress);

        m_server.onReceive() => {
            ByteArray receivedData = m_server.readData();
            m_client.connectToHost(m_nextHopIpAddress, m_nextHopPortNr);
            m_client.sendData(receivedData);
            m_client.close();
        }
    }
    void setNextHopInformation(nextHopIPAddress, nextHopServerPortNr) {
        m_nextHopIpAddress = nextHopIPAddress;
        m_nextHopPortNr= nextHopServerPortNr;
    }

private:
    Server m_server; // server instance accepting connections
    Client m_client; // client instance sending data to the next hop
    IPAddress m_nextHopIpAddress; // next hop address used by the client instance
    int m_nextHopPortNr; // next hop port nr used by the client instance
}

void main() {
    RelayNode relay(127.0.0.1, 1234);
    relay.setNextHopInformation(127.0.0.2, 2345)
    …
    // run application event loop
}


3. Practical activity
· Each student will be assigned one of the topologies below and the simulation scenario has to be implemented in software.
· Besides the constraints imposed by each simulation scenario, the common tasks for each implementation are the following:
· Use a programming language of choice to implement the network simulation
· Use the loopback address range for addressing: 127.0.0.0 – 127.255.255.255
· Test the implementation using Wireshark
· Deliver the implementation (source code or link to online code versioning repository)
· Provide a Wireshark capture to prove the communication between different IP addresses
· Inspect the ratio between total delivered payload against the relevant application layer traffic / the ratio between the total packet length (headers and data) compared to the length of data sent (use Wireshark statistics or manual packet inspection)
· Depending on the implemented simulation, research the headers for TCP and/or UDP protocols. Using Wireshark, identify the header elements in the captured traffic

3.1 Ring communication
· Three computers are communicating in a single direction creating a loop (Figure 8.8)
· One of the computers initiates the communication sending the value ‘1’
· Upon receipt, each network device increments the received value and sends it to the next device
· The communication ends when the delivered payload reaches the value ‘100’
· Implementation hints:
· Implement a single class which is instantiated 3 times with different communication parameters (reuse the code and do not duplicate it for each instance)
· All communication uses TCP sockets (optional)

Figure 8.8 Ring communication network topology

3.2 Node selector
· There are three nodes in the topology: N1, N2, N3 (Figure 8.9)
· N1 increments a value 100 times and after every increment it sends the value to either N2 or N3 which are selected randomly for transmission
· When N2 receives an integer value which is a multiple of 3 it will send an ACK packet back to N1
· When N3 receives an integer value which is a multiple of 5 it will send an ACK packet back to N1
· Implementation hints:
· Implement a single class for N2 and N3 which is instantiated with different communication parameters (reuse the code and do not duplicate it for each instance)
· All communication uses UDP sockets (optional)

Figure 8.9 Node selector network topology

3.3 Relay nodes
· There are four nodes in the topology (Figure 8.10), Sender and three possible destinations (D1, D2, and D3)
· The Sender node is transmitting 100 packets containing an integer number randomly to one of the 3 possible destinations (D1, D2 or D3)
· After each packet transmission the integer number is incremented
· Every node can only send data to the next hop to which it is connected to, therefore a packet from the Sender to D3 must pass through D1 and D2


Figure 8.10 Relay nodes network topology
· Implementation hints:
· The data payload that is transmitted via the socket has to contain the target IP address, so the payload has the following format (Figure 8.11):
	Target IP address
	Value


Figure 8.11 Payload format
· Every time a node receives a packet it verifies whether the received payload’s target IP address is the same as the current node IP address. If it is identical, the communication stops here, otherwise the data is forwarded to the next hop.
· Implement a single class for D1, D2 and D3 which is instantiated with different communication parameters (reuse the code and do not duplicate it for each instance)

image6.png

image7.png

image8.png

image9.png

image10.png

image11.png

image1.png

image2.png

image3.png

image4.png

image5.png


reading content from D:\SD\SearchEngine_ver1\Bee\Comisii burse 2024-2025.pdf


     
                                            

                  FACULTATEA DE AUTOMATICĂ ȘI CALCULATOARE 
                          Str. G. Barițiu nr 26-28, Cluj Napoca, 400027, ROMÂNIA 
                                                   Telefon +40 264 401218 
                                                           https://ac.utcluj.ro/ 
 

 

 

 

 

DECIZIA nr. 11 din 19.09.2024 

- extras - 

 

În Consiliul Facultății din data de 19.09.2024, s-au aprobat componențele următoarelor 

comisii  pentru anul universitar 2024-2025: 

1. Comisiei de analiză, evaluare a dosarelor și atribuire a burselor  
Prodecan: prof.dr.ing. Mihaela DÎNȘOREANU 
Secretar șef: Luciana ABRUDANU 
Student: Cristian Mihai FILIP  - an IV Ca ro 
Student: Aurelia Georgiana DUȚULESCU - an III Au ro 
 

2. Comisia de specialiști pentru burse de performanță științifică: 
Prof.dr.ing. Gheorghe SEBESTYEN 
Conf.dr.ing. Mihai HULEA 
 

3. Comisia de contestații burse: 
Prodecan: conf.dr.mat. Daniela INOAN 
Dr. ec. Simona SABO-MARȚIȘ 
Student Natalia Georgiana BONCEA - an IV Ca ro 
Student Antonia Maria FILIMON - an IV Au ro 
 
 
 
 
 

DECAN, 

Prof. dr. ing. Vlad MUREȘAN 

 
 



reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-28-32.pdf


Image Processing - Laboratory 4: Geometrical features of binary objects 

 

 

27 

4. Geometrical features of binary objects 
 

4.1. Introduction 

 
This lab work presents some important geometric properties of binary images and the 

algorithms used for computing them. The properties described are the area, the center of mass, the 

elongation axis, the perimeter, the thinness ratio, the aspect ratio and the projections of the binary 

image.  

 

4.2. Theoretical considerations 
  

After applying segmentation and labeling algorithms, we obtain a new image where each object 

can be referred separately: 

 

𝐼𝑖(𝑟, 𝑐) = {
1,      if 𝐼(𝑟, 𝑐) ∈ object labeled 'i'
0,      otherwise 

 

 

where 𝑟 ∈ [0. . . 𝐻𝑒𝑖𝑔ℎ𝑡 − 1] and 𝑐 ∈ [0. . . 𝑊𝑖𝑑𝑡ℎ − 1]  
 

An object ‘i’ in the image is described by the function:  

The geometric properties of the objects can be classified into two categories:  

• position and orientation properties: the center of mass, the area, the perimeter, the 

elongation axis; 

• shape properties: aspect ratio, thinness ratio, Euler’s number, the projections, the Feret 

diameters of the objects. 

 

4.2.1. Area 

𝐴𝑖 = ∑ ∑ 𝐼𝑖(𝑟, 𝑐)

𝑊−1

𝑐=0

𝐻−1

𝑟=0

 

 

The area Ai is measured in pixels and it indicates the relative size of the object. 

 

4.2.2. The center of mass 
 

�̄�𝑖 =
1

𝐴𝑖
∑ ∑ 𝑟𝐼𝑖(𝑟, 𝑐)

𝑊−1

𝑐=0

𝐻−1

𝑟=0

 

�̄�𝑖 =
1

𝐴𝑖
∑ ∑ 𝑐𝐼𝑖(𝑟, 𝑐)

𝑊−1

𝑐=0

𝐻−1

𝑟=0

 

 

The equations above correspond to the row and column where the center of mass is located. 

This attribute helps us locate the object in a bi-dimensional image. 

 

4.2.3. The axis of elongation (the axis of least second order moment) 

 

𝑡𝑎𝑛( 2𝜑𝑖) =
2 ∑ ∑ (𝑟 − �̄�𝑖)(𝑐 − �̄�𝑖)𝐼𝑖(𝑟, 𝑐)𝑊−1

𝑐=0
𝐻−1
𝑟=0

∑ ∑ (𝑐 − �̄�𝑖)2𝐼𝑖(𝑟, 𝑐) − ∑ ∑ (𝑟 − �̄�𝑖)2𝑊−1
𝑐=0 𝐼𝑖(𝑟, 𝑐)𝐻−1

𝑟=0
𝑊−1
𝑐=0

𝐻−1
𝑟=0

 



Technical University of Cluj-Napoca, Computer Science Department 

 

 

28 

If both the nominator and the denominator of the above equation are equal to zero, then the 

object has a circular symmetry, and any line that passes through the center of mass is a symmetry 

axis. 

For finding the direction of the line (the angle) one must apply the arctangent function. The 

arctangent is defined on the interval (-∞, +∞) and it takes values in the interval  

(-π/2, π/2). The evaluation of the arctangent becomes unstable when the denominator of the fraction 

tends to zero.  

The signs of the numerator and of the denominator are important for determining the right 

quadrant in which the result lays. The arctangent function does not make the difference between 

directions that are opposed. For this reason, the usage of the function “atan2” is suggested. The 

“atan2” function has as arguments the numerator and the denominator of such fraction, and it returns 

a result in the interval (-π, π). 

The axis of elongation gives information about how the object is positioned in the field of 

view, more exactly, its orientation. The axis corresponds to the direction in which the object (seen as 

a plane surface of constant width) can rotate most easily (has a minimum kinetic moment).  

 After the i  angle is found, the correctness of the resulted value can be validated by drawing 

the axis of elongation. The axis of elongation will correspond to the line that passes through the center 

of mass and determines the i  angle with Ox axis.  

   

4.2.4. The perimeter  

 

 The perimeter of the object helps us determine the position of the object in space and it also 

gives information about the shape of the object. The perimeter can be computed by counting the 

number of pixels on the contour (pixels of value 1 and having at least one neighbor pixel of value 0). 

 A first approach to contour detection is the scanning of the image, line by line and counting 

the number of pixels in the object that satisfy the condition mentioned above. A main disadvantage 

of this method is that we cannot distinguish the exterior contour from the interior contours (if they 

exist, they are generated by the holes in the object). As the pixels of digital images represent 

distributions on a rectangular raster, the length of curves and oblique lines in the image cannot be 

correctly estimated by counting the pixels. A first correction is given by the multiplication by π/4 of 

the perimeter that resulted in the previous algorithm. There are other methods for length correction. 

These methods take into account the type of neighborhood used (4 neighbors, 8 neighbors etc.). 

 Another method for detecting the contour of an object involves the usage of an existing 

algorithm for edge detection, the thinning of the edges until they become 1 pixel thick and in the end 

the counting of the resulted edge pixels. 

 Methods of type “chain-codes” represent complex methods for contour detection and offer a 

high accuracy. 

 

4.2.5. The thinness ratio (circularity) 

 

 

 The function above has the maximum value equal to 1, and for this value we obtain a circle. 

The thinness ratio is used for determining how “round” an object is. If the value of T is close to 1, the 

object tends to be round. 









=

2
4

P

A
T 



Image Processing - Laboratory 4: Geometrical features of binary objects 

 

 

29 

 The value of the thinness ratio also offers information on how regular an object is. The objects 

that have a regular contour have a greater value of T than the objects of irregular contours. The value 

1/T is called irregularity factor of the object (or compactness factor). 

 

 

4.2.6. The aspect ratio 

 

 This property is found by scanning the image and keeping the minimum and maximum 

values of the lines and columns that form the rectangle circumscribed to the object. 

 

 

 

4.2.7. The projections of the binary object 

 

 The projections give information about the shape of the object. The horizontal projection 

equals the sum of pixels computed on each line of the image, and the vertical projection is given by 

the sum of the pixels on the columns.  

 

 

ℎ𝑖(𝑟) = ∑ 𝐼𝑖(𝑟, 𝑐)𝑊−1
𝑐=0       𝑣𝑖(𝑐) = ∑ 𝐼𝑖(𝑟, 𝑐)𝐻−1

𝑟=0  

 

 

 The projections are used in applications of text recognition in which the interest object can be 

normalized.  

 

4.3. Implementation details 
 

In order to distinguish between the various objects present in an image, we will suppose that 

each one of them is painted using a different color. These colors may be the result of a previous 

labeling step or may be generated manually (see Fig. 4.1). 

 

 
Fig. 4.1 Example of a labeled image on which the described algorithms could be tested 

1

1

minmax

minmax

+−

+−
=

rr

cc
R



Technical University of Cluj-Napoca, Computer Science Department 

 

 

30 

There are various approaches for implementing the geometrical properties extractors:  

 

4.3.1. Compute the geometrical features for all objects in an image at once 

 

For each object, the compound pixels are selected based on the object unique label (color) and 

the corresponding geometrical features are computed. This procedure is applied to each object from 

the input labeled image. 

 

4.3.2. Compute the geometrical features for a specific object selected with the mouse 

 

The user should position the mouse pointer over a pixel belonging to the desired object and 

click on it. In response to this action, the geometrical features of the desired object should be 

computed and displayed in the standard output. 

 

In order to add an event handler, we will use the setMouseCallback function from OpenCV, 

which has the role to set a handler for the mouse in a specific window.  

 
void setMouseCallback(const string& winname, MouseCallback onMouse, void* userdata=0) 

winname – window title, 

onMouse – callback function name that is called when a mouse event occurs on the winname 

window, 

userdata – optional parameter that may be passed to the callback function. 

 
The computation of the desired features will be implemented in onMouse function. 

 
void onMouse (int event, int x, int y, int flags, void* param) 

event – is the mouse event and can take the following values: 

- EVENT_MOUSEMOVE 

- EVENT_LBUTTONDOWN 

- EVENT_RBUTTONDOWN 

- EVENT_MBUTTONDOWN 

- EVENT_LBUTTONUP 

- EVENT_RBUTTONUP 

- EVENT_MBUTTONUP 

- EVENT_LBUTTONDBLCLK 

- EVENT_RBUTTONDBLCLK 

- EVENT_MBUTTONDBLCLK 

x, y – are the x and y coordinates where the event occurred, 

flags – specific condition whenever a mouse event occurs, 

param – corresponds to the userdata pointer passed through setMouseCallback function. 
 

In OpenCVApplication framework, an example of event handler is presented in the 

testMouseClick() function.  
 

In order to draw the elongation axis, use the line function from OpenCV to draw the line: 
  

void line( Mat img,  Point pStart, Point pEnd, Scalar color, int thickness ) 

 img – image where the line segment is drawn 

 pStart, pEnd – the two points that define the line segment 

 color – line color 

 thickness – line thickness 



Image Processing - Laboratory 4: Geometrical features of binary objects 

 

 

31 

4.4. Practical work 
 

1. For a specific object in a labeled image selected by a mouse click, compute the object’s area, 

center of mass, axis of elongation, perimeter, thinness ratio and aspect ratio.  

a. Display the results in the standard output 

b. In a separate image (source image clone): 

o Draw the contour points of the selected object 

o Display the center of mass of the selected object 

o Display the axis of elongation of the selected object by using the line function from 

OpenCV. 

c. Compute and display the projections of the selected object in a separate image (source 

image clone). 

2. Create a new processing function which takes as input a labeled image and keeps in the output 

image only the objects that: 

a. have their area < TH_area 

b. have a specific orientation phi, where phi_LOW < phi < phi_HIGH  

where TH_area, phi_LOW, phi_HIGH are given by the user.  

3. Save your work. Use the same application in the next laboratories. At the end of the image 

processing laboratory, you should present your own application with the implemented 

algorithms!!! 

 

4.5. Bibliography 
 

[1] Umbaugh Scot E., Computer Vision and Image Processing, Prentice Hall, NJ, 1998, ISBN 0-13-

264599-8.  


	Image processing
	4. Geometrical features of binary objects
	4.1. Introduction
	4.2. Theoretical considerations
	4.2.1. Area
	4.2.2. The center of mass
	4.2.3. The axis of elongation (the axis of least second order moment)
	4.2.4. The perimeter
	4.2.5. The thinness ratio (circularity)
	4.2.6. The aspect ratio
	4.2.7. The projections of the binary object

	4.3. Implementation details
	4.3.1. Compute the geometrical features for all objects in an image at once
	4.3.2. Compute the geometrical features for a specific object selected with the mouse

	4.4. Practical work
	4.5. Bibliography




reading content from D:\SD\SearchEngine_ver1\Bee\IP_labs.pdf#page=28-34-38.pdf


Image Processing - Laboratory 5: Connected-component labeling 

 

 

33 

5. Connected-component labeling 
 

5.1. Introduction 
 

 This laboratory work presents algorithms for labeling distinct objects from a black and white 

image. As a result, every object will be assigned a unique number. This number, or label, can be used 

to process the objects separately. 

 

5.2. Theoretical foundations 
 

 We will present several algorithms for labeling. The input for the algorithms is a binary image. 

The output is a label matrix which has the same dimensions as the input image. It should be capable 

of storing sufficiently large label values.  

 In the input binary image, the objects are represented as connected components of color black 

(0), the background is assigned the color white (255). To define what a connected component is, we 

need to introduce different neighborhood types. 

 The 4-neighborhood of a position (i,j) is defined to be the set of positions:  

N4(i,j)={(i-1,j), (i,j-1), (i+1,j), (i,j+1)}, 

i.e., the upper, left, lower and right neighbors.  

 The 8-neighborhood consists of all neighboring positions differing by at most 1: 
N8(i,j) = {(k,l) | |k-i|≤1, |l-j|≤1, (k,l)≠(i,j) }, 

so, it includes the 4-neighborhood and the neighbors situated diagonally. 

 When traversing the image in a particular direction we can define the previous neighbors with 

regard to this traversal. The previous neighbors for normal top-down, left-right traversal for a position 

(i,j) is:  

Np(i,j)={(i,j-1), (i-1,j-1), (i-1,j), (i-1,j+1)}. 

 

The presented definitions are illustrated below.  

 

           

 x    x    x  

           
             a) 4-neighborhood          b) 8-neighborhood     c) previous neighbors 

 

We will define a graph generated by a binary image. The set of vertices is formed by all object 

pixel positions. The neighboring object pixels determine the edges of the graph. Two positions are 

neighboring if one is part of the other's neighborhood. We will use N4 and N8, so the generated graph 

is undirected. In this setting a connected component is a set of vertices in which for each pair there is 

path from vertex 1 to vertex 2.  

 

5.2.1. Algorithm 1 - Breadth first traversal 

 

We start the description with a straightforward method for labeling, which relies on breadth 

first traversal of the graph defined on the image. The first step is to initialize the label matrix to zeroes 

which indicates that everything is unlabeled. Then algorithm searches for an unlabeled object pixel. 

If it finds one, it gives it a new label and propagates the label to its neighbors. We repeat this until all 

object pixels are given a label. In the following we present the steps of the algorithm:  



Technical University of Cluj-Napoca, Computer Science Department 

 

 

34 

label = 0    

labels = zeros(height, width) // height x width matrix with 0  

for i = 0:height-1 

 for j = 0:width-1 

  if img(i,j)==0 and labels(i,j)==0 

   label++ 

   Q = queue()  

   labels(i,j) = label 

   Q.push( (i,j) ) 

   while Q not empty 

    q = Q.pop()     

    for each neighbor in N8(q) 

     if img(neighbor)==0 and labels(neighbor)==0 

      labels(neighbor) = label 

      Q.push( neighbor ) 

Algorithm 1. Breadth first traversal for connected-component labeling 

 

The queue data structure maintains the list of points that need to be labeled. Since the queue 

uses a FIFO policy we obtain a breadth first traversal. We mark visited nodes by setting the label for 

their position. Changing the data structure to a stack would result in a depth first traversal of the image 

graph. 

 

5.2.2. Algorithm 2 - Two-pass with equivalence classes 

 

Labeling can be achieved by performing two linear passes over the image and some additional 

processing on a smaller graph. This approach uses less memory. In the previous algorithm we needed 

the store a list of points. If there is a large connected component, the size of the list is roughly the 

same as the size of the image.  

The current algorithm performs the first pass and labels all object pixels with initial labels. 

For each pixel we need to consider the previously visited and labeled pixels, so we use the Np 

neighborhood defined above. After inspecting the labels of the previous positions, we can have the 

following cases: 

• If no previous neighbor was labeled, we create a new label. 

• Otherwise, we take the smallest label, called x, from the neighbors. Afterwards, we mark each 

neighboring label y as equivalent to x. 

We assign the label found in the previous step to the current position and continue. After the 

first pas we have assigned initial labels to each position. However, several labels are equivalent, so 

we need to assign new ones to each equivalence class.  

The equivalence relations define an undirected graph on the labels. This graph is usually much 

smaller than the original graph defined on the whole image. It consists of nodes labeled from 1 to the 

maximum label value. The edges of the graph indicate the equivalence relations. We can apply 

Algorithm 1 on this smaller graph to obtain a new list of labels. All labels equivalent to label 1 get 

relabeled to 1. The next connected component not equivalent to 1 gets relabeled to 2, and so on. A 

new pass over the labels’ matrix is necessary to update the labels. 

  



Image Processing - Laboratory 5: Connected-component labeling 

 

 

35 

label = 0 

labels = zeros(height, width) 

vector<vector<int>> edges(1000) 

for i = 0:height-1 

 for j = 0:width-1 

  if img(i,j)==0 and labels(i,j)==0 

   L = vector() 

   for each neighbor in Np(i,j) 

    if labels(neighbor)>0 

     L.push_back(labels(neighbor)) 

   if L.size() == 0  // assign new label 

    label++ 

    labels(i,j) = label 

   else     // assign smallest neighbor 

    x = min(L) 

    labels(i,j) = x 

    for each y from L 

                    if (y <> x)  

     edges[x].push_back(y) 

     edges[y].push_back(x) 

 

newlabel = 0     

newlabels = zeros(label+1)   // an array of zeroes of length label+1 

for i = 1:label 

 if newlabels[i]==0 

  newlabel++ 

  Q = queue() 

  newlabels[i] = newlabel 

  Q.push( i ) 

  while Q not empty 

   x = Q.pop() 

   for each y in edges[x] 

    if newlabels[y] == 0 

     newlabels[y] = newlabel 

     Q.push( y ) 

           

for i = 0:height-1 

 for j = 0:width-1 

  labels(i,j) = newlabels[labels(i,j)]    

Algorithm 2. Two-pass connected-component labeling 

 

 

 

 

 
Fig. 5.1 Example of a case when the previous neighbors have different labels.  

Labels 1 and 2 are marked as equivalent at this step 

 



Technical University of Cluj-Napoca, Computer Science Department 

 

 

36 

5.3. Implementation details 
 

The following code illustrates how to visit the 4-neighborhood of a pixel. It can be easily 

modified to 8-neighborhood, or to only consider the upper and left neighbors of the pixel. 

 
int di[4] = {-1,0,1,0}; 

int dj[4] = {0,-1,0,1}; 

uchar neighbors[4]; 

for(int k=0; k<4; k++) 

neighbors[k] = img.at<uchar>(i+di[k], j+dj[k]); 

 

Pay attention to stay within the bounds of the image!  

 

Store the labels in a matrix capable of holding the maximum number of labels: 

 

28
 = 256 - uchar (CV_8UC1)  

216 = 65536 - short (CV_16SC1)  

232 ~ 2.1e9 - int (CV_32SC1)  

 

You can use the std∷stack and std∷queue container for storing points for Algorithm 1 

to obtain DFS and BFS traversal, respectively. The points can be instances of structure 

pair<int,int>. Sample code for initializing and performing operations on a queue: 

 
#include <queue> 

queue<pair<int,int>> Q; 

Q.push( pair<int,int>(i,j) ); // add as tail of the queue (newest) 

pair<int,int> p = Q.front();  // access the front element (oldest) 

Q.pop(); // remove the front element 

// access position of p 

i = p.first; j = p.second; 

 

The equivalence relations that define the edges of the smaller graph can be stored using 

adjacency lists in a vector<vector<uchar>>.  Sample code to initialize and insert edges: 

 
// ensure that edges has the proper size 

vector<vector<int>> edges(1000); 

// if u is equivalent to v 

edges[u].push_back(v); 

edges[v].push_back(u); 

 

To display the label matrix as a color image you need to generate a random color for each 

label. You should use the default random generator from the standard library. It is better than a call 

to rand()%256. 

 
#include <random> 

default_random_engine gen; 

uniform_int_distribution<int> d(0,255); 

uchar x = d(gen); 

  



Image Processing - Laboratory 5: Connected-component labeling 

 

 

37 

5.4. Labeling examples 
 

 
 

 
Fig. 5.2 Labeling examples 

 

5.5. Practical Work 
 

1. Implement the breadth first traversal component labeling algorithm (Algorithm 1). You should be 

able to easily switch between the neighborhood types of 4 and 8. 

2. Implement a function which generates a color image from a label matrix by assigning a random 

color to each label. Display the results. 

3. Implement the two-pass component labeling algorithm. Display the intermediate results you get 

after the first pass over the image. Compare this to the final results and to the previous algorithm. 

4. Optionally, visualize the process of labeling by showing intermediate results and pausing after 

each step to illustrate the order of traversal a selected algorithm. 

5. Optionally, change the queue to a stack to perform DFS traversal. 

6. Save your work. Use the same application in the next laboratories. At the end of the image 

processing laboratory, you should present your own application with the implemented 

algorithms!!! 

 

5.6. Bibliography 
 

[1] Umbaugh Scot E., Computer Vision and Image Processing, Prentice Hall, NJ, 1998, ISBN 0-13-

264599-8 

[2] Robert M. Haralick, Linda G. Shapiro, Computer and Robot Vision, Addison-Wesley Publishing 

Company, 1993. 

  


	Image processing
	5. Connected-component labeling
	5.1. Introduction
	5.2. Theoretical foundations
	5.2.1. Algorithm 1 - Breadth first traversal
	5.2.2. Algorithm 2 - Two-pass with equivalence classes

	5.3. Implementation details
	5.4. Labeling examples
	5.5. Practical Work
	5.6. Bibliography




reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 5 FLT (ro).pdf


Laborator 5 

Arbori dezechilibrați și interpretor de expresii postfix 

 
În laboratorul al treilea am aflat cum se stochează simbolurile pe stivă și cum se 

procesează și se propagă valorile semantice (cu ajutorul pseudo-variabilelor dolari) bottom-up în 

arborele sintactic (parse tree). În cazul expresiilor aritmetice, pe stiva de valori erau stocate doar 

valori de tip întreg, care în urma unei reduceri se substituiau tot cu o valoare întreagă. La o 

reducere, partea dreaptă a unei producții se înlocuia cu (se reducea la) partea stângă. 

În laboratorul al patrulea am lucrat și cu liste, fapt pentru care a fost nevoie să definim un 

%union cu un câmp pentru numere întregi și un câmp pentru liste. Pe stiva de valori ajung să 

coexiste și numere și liste, de aceea trebuie să facem stiva omogenă, cu elemente de același tip, 

și anume union. Acest union, în cazul de față, este un fel de wrapper, care conferă o formă 

comună numerelor și listelor. Deși la citirea unui token din input se pune pe stiva de valori doar 

câte un întreg, în urma unei reduceri (când se recunoaște în input o structură sintactică agregată), 

ajunge să se pună pe stiva de valori o valoare de tip agregat. În cazul de față, structura de date 

agregată este lista. 

Așadar, ne putem imagina cum arată arborele sintactic la citirea și crearea unei liste. La 

fiecare pas, pe stiva de valori se pune câte un element de tip întreg dintr-o listă. Când în stiva de 

valori există un întreg SAU un întreg și o listă, acestea vor fi reduse la o singură listă. În regula 

enum din setul de producții (din laboratorul 4) este descrisă compunerea unei liste intern, ca 

structură de date. Regula poate fi recursivă dreapta sau recursivă stânga. În primul caz, se 

introduce un element la începutul listei, iar arborele este dezechilibrat pe dreapta. În al doilea 

caz, se introduce un element la finalul listei, iar arborele este dezechilibrat pe stânga. 

Introducerea unui element la finalul unei liste este o metodă ineficientă, deoarece trebuie 

parcursă toată lista.  

Recursivitate dreapta:       Recursivitate stânga: 

       

 

enum -> NUMBER enum 

      | NUMBER  

 

enum -> enum NUMBER 

      | NUMBER  

 



În primul caz, pe stiva de valori se stochează la fiecare pas toate elementele citite până 

acum din listă. După stocarea ultimului element, începe extragerea de pe stivă și adăugarea 

efectivă în listă a elementelor, începând cu ultimul (cel mai din dreapta) și terminând cu primul 

(cel mai din stânga). Adică se adaugă elementele în lista finală în ordine, de la dreapta la stânga, 

printr-o simplă adăugare pas cu pas în capul unei liste parțiale. În al doilea caz, se păstrează în 

stiva de valori doar elementul care se introduce în listă la pasul curent.  

Să luăm ca exemplu compunerea listei ‘(1 2 3 4). În tabelul următor putem vedea cum 

evoluează stiva de valori la compunerea unei liste recursiv dreapta, respectiv recursiv stânga.  

Recursivitate dreapta Recursivitate stânga 

Stiva de valori: 
  1 
  1 2 
  1 2 3 
  1 2 3 4 
  1 2 3 
  1 2 
  1 

Stiva de valori: 
  1 
  2 
  3 
  4 

Compunerea listei: 
           4 
       3  4 
     2 3 4 
  1 2 3 4 

Compunerea listei: 
  1 
  1 2 
  1 2 3 
  1 2 3 4 

 Următoarea provocare este să creăm un analizor lexico-sintactic pentru a transforma 

expresii aritmetice din formă infix în formă postfix.  

 Exemple:  

 1 + 2 =>    1 2 + 

 (a – 5 + c) * 2 =>   a 5 – c + 2 * 

  a / 2 + – (a – 5 + c) * 2 ^ b =>     a 2 / a 5 – c + – 2 b ^ * + 

 Observăm că inputul poate să conțină variabile, pe lângă numere și operatori. Având în 

vedere că nu putem calcula expresiile, ci trebuie doar să le modificăm forma, le putem stoca sub 

formă de string-uri. În acest caz, canalul de comunicare semantică între analizorul lexical și 

parserul sintactic, yylval, trebuie să accepte string-uri, deci poate fi reprezentat ca un %union cu 

un câmp de string-uri.  

 În acest exercițiu sunt foarte importante prioritățile operațiilor, pentru a asigura o 

transpunere corectă a expresiilor. Ne amintim din laboratorul al treilea că prioritățile operațiilor 

sunt specificate în partea de declarații a fișierului .y, cu %left, %right sau %nonassoc. Ordinea în 

care sunt declarate indică importanța lor: prima are cea mai mică prioritate, iar ultima are cea 

mai mare prioritate. Dacă asociativitatea este pe stânga (%left), atunci o serie de operații cu 



aceleași priorități va fi tratată de la stânga spre dreapta. Dacă asociativitatea este pe dreapta 

(%right), atunci seria va fi tratată din dreapta spre stânga. Există situații în care este nevoie să 

definim priorități particulare. De exemplu, dacă tratăm numere negative, minusul lor (minus 

unar) nu are aceeași prioritate ca minusul de la scădere (minus binar) și nici nu este tratat la fel. 

Așa că vom defini o prioritate specială pentru minusul unar al numerelor negative.  

 

 În setul de producții trebuie să specificăm că minusul numerelor negative are prioritatea 

specială, definită de noi. Prin “%prec MINUSUNAR” se suprascrie precedența care ar fi fost dată 

implicit de ‘-‘. Știm deja că precedența unei reguli este importantă în conflictele shift-reduce, 

când se compară precedența regulii care s-ar reduce cu precedența simbolului care s-ar shifta. 

 

  

Exerciții propuse: 

1. Creați un analizor lexico-sintactic care să preia din input expresii aritmetice scrise în 

formă postfix și să le transforme în formă prefix. Exemplu:     1 2 +    =>    + 1 2 

2. Creați un analizor lexico-sintactic care să citească din input expresii aritmetice în 

formă postfix, fără variabile, doar cu numere, și să afișeze rezultatul calculului. 

Exemplu:   1  2  +    =>   3 

10  5  –  3  +  2  *   =>  16 

%left '+' '-' 

%left '*' '/' 

%left MINUSUNAR 

%right '^' 

expr : expr '+' expr  

     | expr '-' expr  

     | expr '*' expr  

     | expr '/' expr  

     | expr '^' expr  

     | '-' expr %prec MINUSUNAR 

     | '(' expr ')' 

     | NUMBER 

     | VAR 

     ; 



reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 6 și 7 FLT (ro).pdf


Laborator 6 și 7 

Prelucrarea matricilor 

 

Pe parcursul laboratoarelor 6 și 7 vom realiza un analizor lexico-sintactic pentru a prelucra 

matrici și operații pe matrici. Așadar, vom crea o nouă pereche de fișiere lex și yacc. 

Inputul poate fi o atribuire de matrice unei variabile sau o operație aritmetică între 

variabile de tip matrice. Exemple: 

A = 1 0 2 

       0 3 1 ; 

B = 6 11 16 

       0  1  2 ; 

C = 0 1 0 

       2 4 2 ; 

A + B + C ; 

> 7 12 18 

   2  8   5  

A + B – C ; 

> 7 10 18 

   -2  0  1 

 Scopul este să reținem matricile citite în variabile, pentru a putea aplica operații pe ele. 

Dacă variabilele sunt scrise în input cu majuscule, putem crea un vector de 26 de poziții în care 

să stocăm matricile atribuite variabilelor. Tradițional, în domeniul compilatoarelor, acest vector 

se numește tabelă de simboluri. Totuși, dintre simboluri (mai exact, dintre simbolurile 

terminale/tokeni), tabela de simboluri stochează doar identificatorii (variabile și nume de funcții) 

împreună cu informații legate de acestea: valoarea curentă păstrată într-o variabilă, respectiv un 

pointer spre începutul codului unei funcții. 

 

 Pentru a stoca o matrice, putem crea două structuri: una pentru a stoca o înșiruire de 

numere întregi compunând un rând dintr-o matrice, iar alta pentru a stoca o înșiruire de rânduri 

care formează o matrice. Fiecare dintre cele două structuri trebuie să conțină și numărul total de 

elemente dintr-un rând (care practic definește numărul total de coloane din matrice), respectiv 

numărul total de rânduri dintr-o matrice.  

 

matr *mem[26]; 

typedef struct _line{ 

 int elems[MAX]; 

 int no_columns_used; 

} line; 

 

typedef struct _matr { 

 line *rows[MAX]; 

 int no_rows_used; 

} matr; 

 



Având în vedere că pe stiva de valori pot să coexiste atât numere, cât și înșiruiri de numere 

sau înșiruiri de rânduri, înseamnă că yylval trebuie să fie declarat drept un %union cu trei câmpuri. 

 

Setul de producții este format dintr-un set de reguli care descriu inputul (stmt), un set de 

reguli care descriu operațiile aritmetice aplicate pe matrici (expr) și reguli pentru construcția 

rândurilor (row) și a matricilor (matrix).  

 

Tokenul (literalul) ‘;’ indică finalul unei instrucțiuni (statement – stmt), după care ar urma 

un ‘\n’. Tokenul ‘\n’ apare și ca un separator între rândurile dintr-o matrice. După ultimul rând 

dintr-o matrice nu urmează direct ‘\n’, ci urmează tokenul ‘;’ și abia apoi ‘\n’ după finalul 

instrucțiunii.  

Putem observa o comparație între gramatica matricilor și gramatica G1 de la curs: 

 

În gramatica G1, o expresie aritmetică E este definită recursiv ca o enumerare de termeni 

aritmetici T, separați prin tokenul ‘+’. Asemănător, în cazul matricilor, o matrice (matrix) este 

definită recursiv ca o enumerare de rânduri (row), separate între ele prin tokenul ‘\n’. Ca și aspect 

vizual, în G1 o expresie E este o sumă de termeni T (separați prin ‘+’) de la stânga la dreapta, iar 

o matrice (matrix) este o succesiune de rânduri (row) de sus în jos, efectul vertical fiind dat de 

‘\n’-urile dintre rânduri. 

În final, în secțiunea de user subroutines a fișierului .y vom defini funcțiile necesare pentru 

lucrul pe matrici.  

%union { 

  struct _matr *mat; 

  struct _line *lin; 

  int ival; 

} 

 

stmt : VAR '=' matrix ';' 

     | expr ';'  

     ; 

expr : expr '+' expr  

     | expr '-' expr  

     | VAR  

     ; 

matrix : matrix '\n' row  

       | row 

       ; 

row : row NUMBER  

    | NUMBER 

    ; 

E -> E + T 

   | T 

 



Exerciții propuse: 

1. Adăugați o funcție pentru calculul determinantului unei matrice. 

2. Adăugați o funcție pentru realizarea înmulțirii a două matrici. 



reading content from D:\SD\SearchEngine_ver1\Bee\Laborator 8 FLT (ro).pdf


Laborator 8 

Interpretarea arborilor binari în Haskell/ML 

 

Laboratorul 8 constă în crearea unui analizor lexico-sintactic pentru procesarea arborilor 

binari de căutare în sintaxă Haskell și, comparativ, în sintaxă ML. Partea de ML va apărea pe 

fundal color (albastru), iar pentru implementare vom merge pe una dintre cele două sintaxe. Vom 

avea în vedere citirea arborilor și executarea unor operații pe arbori: insert (inserarea unui nod 

într-un arbore) și count (contorizarea nodurilor, diferite de frunzele vide Lf, dintr-un arbore). 

Exemple de input în Haskell: 

 

Exemple de input în ML: 

 

După cum se poate observa în exemple, sintaxa Haskell a unui arbore binar este 

următoarea:  

Iar sintaxa ML a unui arbore binar este: 

  

Node Lf 2 Lf 
> Node Lf 2 Lf 

Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf) 
> Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf) 

count (insert 16 (Node (Node Lf 2 Lf) 15 Lf)) 
> 3 

insert (count (Node Lf 17 (Node Lf 24 Lf))) (insert 12 (Node Lf 10 Lf)) 
> Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf) 

Node(2, Lf, Lf) 
> Node(2, Lf, Lf) 

Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf)) 
> Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf)) 

count(insert(16, Node(15, Node(2, Lf, Lf), Lf))) 
> 3 

insert(count(Node(17, Lf, Node(24, Lf, Lf))), insert(12, Node(10, Lf, Lf))) 
> Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf)) 

Node (Tree Int) Int (Tree Int) 

Node (int, int Tree, int Tree) 

 



Să luăm ca exemplu arborele binar din imaginea următoare: 

 

Reprezentarea arborelui în sintaxă Haskell este următoarea: 

 

Iar reprezentarea în sintaxă ML este: 

 

Pentru a reprezenta în memorie arborii binari de căutare, vom crea o structură cu trei 

câmpuri: unul pentru cheia nodului (de tip int) și două pentru fiii nodului (pointeri la subarborele 

stâng și la subarborele drept).  

 

Pe stiva de valori vor coexista două tipuri: int, pentru numerele citite din input și pentru 

cheile nodurilor, și o structură de tip arbore, pentru a reduce numerele din input la arbori în 

forma potrivită (reducând partea dreaptă a producțiilor la partea stângă). Astfel, yylval va fi un 

union cu două câmpuri: 

 

În ceea ce privește setul de producții, vom avea un set de reguli (expr) care descriu 
inputul. Putem separa instrucțiunile din input în două categorii, în funcție de tipul rezultatului. 
Citirile arborilor și comanda insert vor returna arbori, în vreme ce comanda count returnează un 

Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf) 

Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf)) 

typedef struct _node { 

int key; 

 struct _node *left, *right;  

} node; 

%union { 

 int ival; 

 struct _node *btree; 

} 



număr întreg. Astfel, reies alte două seturi de reguli, unul pentru situațiile din care rezultă un 
arbore (t_expr) și unul pentru cele din care rezultă numere întregi (i_expr). Cel mai important set 
de reguli este cel care descrie construirea unui arbore binar (tree), cu ajutorul celor doi 
constructori de date Haskell/ML pentru arbori binari: constructorul Node cu trei argumente și 
constructorul Lf cu zero argumente. 

 Setul de producții pentru sintaxă Haskell:

 

Setul de producții pentru sintaxă ML: 

 

  

expr : i_expr 

     | t_expr 

     ; 

i_expr : COUNT t_expr 

  |'(' i_expr ')' 

  | NUMBER 

  ; 

t_expr : INSERT i_expr t_expr 

       | '(' t_expr ')' 

       | tree 

       ; 

tree : NODE tree NUMBER tree 

     | '(' tree ')'    

     | LF    

     ; 

expr : i_expr 

     | t_expr 

     ; 

i_expr : COUNT '(' t_expr ')' 

  | NUMBER 

  ; 

t_expr : INSERT '(' i_expr ',' t_expr ')' 

       | tree 

       ; 

tree : NODE '(' NUMBER ',' tree ',' tree ')' 

     | LF    

     ; 



Exerciții propuse: 

1. Implementați o funcție pentru căutarea unui nod într-un arbore.  

Exemple în Haskell: 

find 12 (Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf)) 
> true 
find 17 (Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf)) 
> false 

Exemple în ML: 

 

2. Implementați o funcție pentru ștergerea unui nod dintr-un arbore. Verificați întâi dacă 

nodul căutat există în arbore.  

Exemplu în Haskell: 

delete 12 (Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf)) 
> Node (Node Lf 2 Lf) 10 Lf 

Exemplu în ML: 

 
 

3. Creați o funcție pentru a verifica dacă un arbore binar este echilibrat.  

Exemple în Haskell: 

balanced (Node (Node Lf 2 Lf) 10 (Node Lf 12 Lf)) 
> true 
balanced (Node (Node Lf 2 Lf) 10 Lf) 
> false 

Exemple în ML: 

 

find(12, Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf))) 
> true 
find(17, Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf))) 
> false 

 

delete(12, Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf))) 
> Node(10, Node(2, Lf, Lf), Lf) 

balanced(Node(10, Node(2, Lf, Lf), Node(12, Lf, Lf))) 
> true 
balanced(Node(10, Node(2, Lf, Lf), Lf)) 
> false 



reading content from D:\SD\SearchEngine_ver1\Bee\Model_CV_ro 2v 4.doc

 
Curriculum Vitae 


	INFORMAŢII PERSONALE
	Braica Patricia Maria 

	

	 
	 Satu Mare, Strada Zenit, Z4, cod postal 440174 

	
	 0770644019      

	
	 braica.patricia@yahoo.com 

	
	

	
	Whatsapp, yahoo 

	
	Sexul F | Data naşterii 22/11/2003 | Naţionalitatea Română 


	LOCUL DE MUNCA PENTRU CARE SE CANDIDEAZĂ

POZIŢIA

LOCUL DE MUNCĂ DORIT

STUDIILE PENTRU CARE SE CANDIDEAZĂ

profilul personal
	Participant grup țintă în proiectul „ Studenți motivați în realizarea de stagii de practică corelate cu cerințele pieței muncii - SMART-PRACTICE„


	EXPERIENŢA PROFESIONALĂ
	 


	Scrieţi datele (de la - până la) 
	

	

	

	


	EDUCAŢIE ŞI FORMARE
	 


	Scrieţi datele (de la - până la) 
	Studentă, anul III, Forma de zi
UTCN, specializarea Calculatoare și Tehnologia Informației


	Scrieţi nivelul EQF, dacă îl cunoaşteţi 

	
	Secția: limba engleză 

	
	· OOP on Java and C++
I successfully completed an Object-Oriented Programming (OOP) course using Java, which included a mandatory project.
· SQL programming
Through the completion of an SQL course, I acquired the essential skills required for effective database management.
· Fundamental Algorithms in C
Completing the Fundamental Algorithms and Data Structures in C course set me on the path to efficiency in programming.
· Logic Design of Circuits, Assembly, VHDL
Successfully completing the Logic Design of Circuits course has been instrumental in building a strong foundation for my understanding of hardware systems.
· AI Technologies in Python
Implemented PDDL-like theorem proving to detect deception in Among Us. Designed AI solutions for Sliding Tile Puzzle and All Lights Out using automated planning. Integrated AI into the Pac-Man framework for decision-making and pathfinding, leveraging adversarial search.


	COMPETENΤE PERSONALE
	 


	Limba(i) maternă(e)
	Limba română

	
	

	Alte limbi străine cunoscute
	ΙNΤELEGERE 
	VORBIRE 
	SCRIERE 

	
	Ascultare 
	Citire 
	Participare la conversaţie 
	Discurs oral 
	

	Limba engleză
	Utilizator experimentat 
	Utilizator experimentat
	Utilizator experimentat
	Utilizator experimentat
	Utilizator experimentat

	
	Admiterea la sectia Engleză a UTCN a fost echivalată cu Nivelul C1


	Limba germană
	Utilizator independent
	Utilizator independent
	Utilizator independent
	Utilizator independent
	Utilizator independent

	
	Certificat DSD Nivelul B1 


	
	Niveluri: A1/A2: Utilizator elementar  -  B1/B2: Utilizator independent  -  C1/C2: Utilizator experimentat 

Cadrul european comun de referinţă pentru limbi străine 


	Competenţe digitale
	AUTOEVALUARE

	
	Procesarea informaţiei
	Comunicare
	Creare de conţinut
	Securitate
	Rezolvarea de probleme

	
	Utilizator experimentat 
	Utilizator experimentat
	Utilizator experimentat
	Utilizator experimentat
	Utilizator experimentat

	
	Niveluri: Utilizator elementar  -  Utilizator independent  -  Utilizator experimentat 

Competențele digitale - Grilă de auto-evaluare

	
	Certificat ECDL


	
	În primul rând, mă simt foarte pregătită pentru a aborda  domeniul complex al Web Development. Pregătirea mea se confirmă prin rezultatele foarte bune obținute la materiile vizate în timpul celor 3 ani de studiu.

În al doilea rând, aș vrea să îmi dezvolt abilitățile practice în domeniul tehnic, în special, în ceea ce privește implementarea soluțiilor software. Consider că acest proiect îmi va oferi o oportunitate de a învăța de la profesioniști și de a aplica teoria în practică. Mă motivează oportunitatea de a lucra într-o echipă interdisciplinară și de a contribui la dezvoltarea unui proiect real. 


Consider că este prioritar să amintesc că am lucrat cu acest tip de tehnologie Web Development în cadrul cursului “Inginerie Software”, și am realizat un proiect despre sisteme de recomandare ale resturantelor din apropiere folosind API-urile de la Google Location si de vreme. 

De asemenea, am urmat cursuri de "Object-Oriented Programming (OOP) on Java and C++", unde am realizat un proiect obligatoriu ce mi-a consolidat cunoștințele în dezvoltarea aplicațiilor bazate pe OOP.

 
"SQL Programming" mi-a oferit abilități fundamentale pentru gestionarea bazelor de date, esențiale în orice proiect care implică stocarea și manipularea datelor. 

În cadrul studiilor mele, am urmat cursuri relevante care mi-au oferit abilități esențiale în domeniul informaticii și al tehnologiilor aplicate. De exemplu, prin completarea cursului de "Fundamental Algorithms and Data Structures in C", am învățat tehnici de programare eficiente, pentru dezvoltarea de soluții performante. 

În cadrul cursului "AI Technologies in Python", am implementat soluții AI complexe, cum ar fi theorem proving și PDDL împreună cu colegii mei de echipă. 




	Permis de conducere 
	Dețin permis Categoria B


	INFORMAΤII SUPLIMENTARE
	 


	ANEXE
	 


	
	





 © Uniunea Europeană, 2002-2015 | europass.cedefop.europa.eu 
Pagina 2 / 6 

 © Uniunea Europeană, 2002-2018 | europass.cedefop.europa.eu 
Pagina 1 / 6 


reading content from D:\SD\SearchEngine_ver1\Bee\morphological_op_images.zip


Morphological_Op_Images/1_Dilate/mon1thr1_bw.bmp


Morphological_Op_Images/1_Dilate/reg1neg1_bw.bmp


Morphological_Op_Images/1_Dilate/wdg2ded1_bw.bmp


Morphological_Op_Images/1_Dilate/wdg2thr3_bw.bmp


Morphological_Op_Images/2_Erode/mon1thr1_bw.bmp


Morphological_Op_Images/2_Erode/mon1_gray.bmp


Morphological_Op_Images/3_Open/art3_bw.bmp


Morphological_Op_Images/3_Open/cel4thr3_bw.bmp


Morphological_Op_Images/3_Open/cel4_gray.bmp


Morphological_Op_Images/3_Open/mon1thr1_bw.bmp


Morphological_Op_Images/4_Close/art4_bw.bmp


Morphological_Op_Images/4_Close/mon1thr1_bw.bmp


Morphological_Op_Images/4_Close/phn1thr1_bw.bmp


Morphological_Op_Images/4_Close/phn1_gray.bmp


Morphological_Op_Images/5_BoundaryExtraction/reg1neg1_bw.bmp


Morphological_Op_Images/5_BoundaryExtraction/wdg2thr3_bw.bmp


Morphological_Op_Images/5_BoundaryExtraction/wdg2_gray.bmp


Morphological_Op_Images/6_RegionFilling/reg1neg1_bw.bmp


Morphological_Op_Images/6_RegionFilling/wdg2ded1_bw.bmp


Morphological_Op_Images/2_Erode/reg1neg1_bw.bmp


reading content from D:\SD\SearchEngine_ver1\Bee\RC3a_2022.doc

REŢELE DE CALCULATOARE
FIBRE OPTICE ŞI COMPONENTE OPTICE

LUCRAREA NR. 3a
FIBRE OPTICE ŞI COMPONENTE OPTICE
1. Scopul lucrării

Obiectivul acestei lucrări este cunoașterea și înțelegerea fibrelor optice, a componentelor optice, principalele metodelor de testare, precum şi calculul bugetului optic.
2. Consideraţii teoretice

2.1 Fibre şi componente optice
Lucrarea de laborator continuă să se concentreze asupra nivelului fizic al stivei ISO/OSI, oferind cunoștințe despre fibrele optice și componente optice. În plus, în partea 3b sunt prezentate principalele dispozitive de rețea și elementele cablării structurate.

Odată cu scăderea accentuată a preţului fibrei optice, şi a echipamentelor de comunicaţie corespunzătoare, aceasta a devenit mediul preferat pentru noile conexiuni de mare viteza (în mediul exterior, cât şi în interiorul clădirilor).

Pentru transmiterea datelor, fibrele optice trimit semnale luminoase de-a lungul miezurilor de sticlă sau plastic (de ordinul zecilor de microni (μ), care constituie un ghid de undă pentru lumină, obținut dintr-o combinație de dioxid de siliciu și alte elemente).

Un fir de fibră optică (eng. fiber strand) este elementul de bază al unui cablu de fibră optică (un cablu conține mai multe fire). Un fir optic este format din trei straturi: miez, îmbrăcăminte și învelitoare de protecție. Un cablu de fibră optică este format din mai multe componente: fire de fibră, zona tampon/buffer, materiale de protecție și mantaua exterioară.

Miezul este învelit de un material realizat din dioxid de siliciu având un indice de refracţie mai mic decât al miezului numit imbrăcăminte. Pentru a proteja îmbrăcămintea, aceasta este învelită într-un material plastic. Acest inveliş se numeşte protecţie şi este învelit la rândul său de un material întăritor, de obicei Kevlar, care conferă rezistenţă fibrei în momentul instalării. Zonele tampoan ale fibrelor optice sunt de două categorii: strânse (se aplică o acoperire de protecție peste învelișul fiecărui fir de fibră) sau cu tub liber (mai multe fire în interiorul unui tub umplut cu un gel protector). Ultimul inveliş este mantaua care protejează fibra împotriva materialelor abrazive, a solventilor şi a altor factori. Culoarea mantalei în cazul fibrei optice multimod este de obicei portocaliu şi în cazul fibrei optice monomod este de obicei galben. Fiecare cablu de fibră optică este compus din doua fibre invelite separat, o fibră fiind folosită pentru transmisie şi alta pentru recepţie, asigurându-se în acest mod o legatură full-duplex. Un cablu de fibră optică poate contine de la 2 până la sute de fibre separate, învelite într-un strat protector. 
Figura 2.1 prezintă o straturile unei fibre și o secţiune transversală prin fibra optică.

	

	Figure 2.1 a. Straturile unei fibre optice             b. Secţiune transversală prin fibra optică


Pentru ca semnalul luminos să fie reflectat fără pierderi trebuiesc îndeplinite următoarele două condiţii:

· fibra optică trebuie să aibă un indice de refracţie mai mare decât materialul care o înconjoară;
· unghiul de incidenţă al semnalului luminos trebuie să fie mai mare decât unghiul critic al fibrei şi al materialului care o inconjoară. Unghiul de incidenta al semnalului luminos poate fi controlat cu ajutorul următorilor doi factori:

· apertura numerică a fibrei este gama unghiurilor semnalului luminos pentru care reflexia este totală;
· modurile reprezintă căile pe care semnalul luminos le poate urma.

Spre deosebire de mediile de transmisie bazate de cupru, fibra optică nu este susceptibilă la și nu generează interferențe electromagnetice sau probleme de diafonie.
Două tipuri principale de fibre optice sunt utilizate în mod obișnuit în rețele LAN și WAN: monomod (eng. single-mode) și multimod (eng. multimode). Fibra optică monomod este utilizată pentru conexiuni pe distanțe lungi și pentru cablarea verticală în clădiri (coloana vertebrală a clădirii). Fibra optică multimod este utilizată în cablarea orizontală și verticală. Fibra multimod are un diametru miezului mai mare în comparație cu cel al fibrei monomod. Astfel, fibra multimod nu necesită aceeași precizie ca în cazul fibrei monomod, rezultând astfel elemente optice (conectori, transmițători etc) mai puțin costisitoare.

Miezul fibrei monomod are diametrul suficient de mic încât să permită doar un singur mod (o singură cale) semnalului luminos, acesta fiind transmis în linie dreaptă prin mijlocul miezului. Cablurile de fibră optică monomod folosesc miezul cu diametrul între 8μ şi 10μ. Cele mai folosite fibre optice monomod au diametrul de 9μ şi îmbrăcămintea cu diametrul de 125μ. Acestea sunt de obicei referite ca şi fibre optice de 9/125μ. Sursa de lumină folosită la fibra monomod este laserul infraroşu. Se recomandă precauţie atunci când se foloseşte laserul ca şi sursă de lumină deoarece acesta poate afecta ochii. Fibra monomod poate transmite date la distanţe de peste 100km. Pierderea pe km de fibră optică monomod este specificată de către producator. În cazul fibrei monomod indicele de refracţie al sticlei este constant. Acest tip de sticlă se numeşte sticlă cu index pas.

Miezul fibrei multimod are diametrul suficient de mare încât să permită mai multe moduri (mai multe căi) semnalului luminos. Cablurile de fibră optică multimod standard folosesc miezul cu diametrul de 62,5μ sau 50μ şi îmbrăcămintea cu diametrul de 125μ. Acestea sunt de obicei referite ca şi fibre optice de 62.5/125μ sau 50/125μ. De obicei, sursele de lumina folosite cu fibra multimod sunt Infrared Light Emitting Diode (LED) sau Vertical Cavity Surface Emitting Lasers (VCSEL). LED-urile sunt mai ieftine şi necesită mai puţine măsuri de siguranţă decât laserele. Dezavantajul LED-urilor este că nu pot transmite semnalele luminoase la distante la fel de mari ca şi laserele. Fibra multimod de 62.5/125 poate transmite date la distante de până la 2000m. În cazul fibrei multimod indicele de refracţie al sticlei poate fi constant (sticlă monomod cu index pas) sau poate scădea de la centru spre exterior (sticlă monomod cu index variabil sau gradat şi permite diferitelor moduri luminoase să ajunga la receptor în acelaşi moment).
În fibra optică lumina suferă, pe lângă propagare, două fenomene principale: atenuare şi dispersie. Atenuarea sau absorbţia se datorează în principal prezenţei ionilor hidroxil -OH şi a diferiţilor ioni de metale. Lumina poate fi de asemenea împrăştiată de microcristale, mai mici decât lungimea de undă, care se formează la răcirea sticlei. Atenuarea limitează utilizarea fibrei optice în lungime. Dispersia sau lărgirea lăţimii impulsurilor se datorează în fibra multimod lungimii diferite pe care o au diferitele moduri. O altă dispersie cea cromatică este datorată variaţiei indicelui de refracţie în funcţie de culoarea sau lungimea de undă a luminii. Dispersia limitează utilizarea fibrei optice în frecvenţă sau lărgime de bandă. Cele două limitări înmulţite caracterizează cel mai corect o fibră optică. Valori de 20MHz-km se obţin pentru fibra cu index pas, de 1GHz-km pentru cea cu index variabil şi de 1000GHz-km pentru cea monomod la care nu există dispersie modală.

Transmiţătoarele pentru fibra optică convertesc semnalele electrice în pulsuri luminoase echivalente. Există două tipuri de surse de lumină folosite de transmiţătoarele pentru fibra optică:

· LED-ul care produce lumina în infraroşu având lungimea de undă de 850nm sau 1310nm. Acestea sunt folosite cu fibre multimod. Cuplarea la fibra optică poate fi îmbunătăţită prin utilizarea unei lentile sferice;
· dioda semiconductoare LASER care produce lumina în infrarosu având lungimea de undă de 1310nm sau 1550nm. Acestea sunt folosite cu fibre multimod sau monomod.
Există două tipuri constructive de bază pentru LED-uri: cu emisie pe suprafaţă şi cu emisie pe muchie. La LED cu emisie pe suprafaţă, emisia luminii are loc perpendicular pe planul joncţiunii printr-un strat subţire transparent. Acestea emit într-un spectru geometric radial. La LED cu emisie pe muchie lumina este emisă într-un plan paralel cu joncţiunea la muchia semiconductorului. Materialele cel mai des utilizate sunt compuşi III-V ca GaAs sau AlxGa1-xAs pentru lungimi de undă de 0,8-0,9 μm şi GaxIn1-xPyAs1-y pentru lungimi de undă de 1,3-1,6 μm. Spectrul de emisie a unui LED este cuprins între 25-40 μm pentru lungimi de undă mici şi 50-100 μm pentru lungimi de undă mai mari.

Diodele semiconductoare LASER, diode laser (LD), se obţin prin introducerea unui LED într-o cavitate rezonantă optic. Efectul de LASER apare numai la existenţa unui curent direct suficient de mare pentru a se realiza o inversare de populaţii a electronilor şi a golurilor din cele două benzi energetice de conducţie şi de valenţă. Valoarea de curent de la care apare acest efect se numeşte curent limită. Sub acest curent dispozitivul se comportă ca un LED obişnuit. Deoarece lumina emisă de un laser este mult mai coerentă decât cea emisă de un LED, eficienţa de cuplare la fibra optică este superioară. De asemenea puterea optică captată de la un laser este mai mare decât cea emisă de LED.
O analiză comparată între cele două tipuri de emiţătoare este clar în favoarea LD prin posibilitatea de utilizare la frecvenţe mai mari, spectru mai restrâns şi în favoarea LED ca preţ şi stabilitate mai mare a puterii în raport cu temperatura.

Timpul de viaţă al ambelor dispozitive este egal şi este de ordinul a 10 milioane ore.

Receptoarele pentru fibra optică convertesc pulsurile luminoase în semnale electrice echivalente. Dispozitivele semiconductoare folosite de obicei de receptoarele pentru fibra optică se clasifică în două tipuri: simple şi cu câştig intern. Primele se mai numesc şi fotodiode PIN după tipul de dopare (p intrinsec şi n) iar cea de a doua categorie se numeşte APD (Avalanche Photo-Diodes). Aceste dispozitive sunt sensibile la lungimile de undă ale luminii de 850, 1310 şi 1550nm, lungimi de undă folosite de transmiţătoarele pentru fibra optică. Ca materiale semiconductoare sunt folosite Si pentru lungimi de undă de 800-900 nm şi Ge sau InGaAsP pentru 1300 şi 1500 nm. Si are sensibilitate optimă doar într-o zonă de frecvenţe redusă pe când Ge are un curent de întuneric apreciabil şi este mai sensibil la zgomot. Din acest motiv ultima variantă este cea mai bună dar necesită o tehnologie de fabricaţie mai sofisticată şi în consecinţă are şi un preţ mai mare.

Pentru a conecta fibrele sau pentru a realizare unei fibre mai lungi se folosesc joncţiuni (eng. splices). Joncţiunile sunt de două tipuri: mecanice şi de fuziune. Atenuările introduse sunt  mai mici de 0.5dB (ANSI/TIA-568-C.3 specifică că joncțiunile mecanice sau de fuziune nu trebuie să depășească o pierdere maximă de inserție optică de 0,3 dB). La joncţiunile mecanice cele două capete de fibră, atent tăiate, curăţate şi şlefuite sunt prinse într-o montură mecanică rigidă care le fixează una faţă de cealaltă într-un ansamblu imobil. Joncţiunile de fuziune se execută prin încălzirea aproape până la punctul de topire. În acest moment cele două fibre sunt lipite una de alta şi răcite. Aceste operaţii sunt precedate de operaţii de tăiere şi finisare a capetelor şi de aliniere prealabilă a celor două capete de jonctat. Joncţiunile de fuziune refac şi rezistenţa la tragere/rupere a fibrei la aproximativ 90% din cea iniţială. Pentru a proteja joncțiunile, se folosesc incinte speciale.
Conectorii pentru fibra optică permit conectarea fibrelor la porturi. Cei mai folosiţi conectori sunt SC (Subscriber Connector) - snap on type, ST (Straight Tip) - twist on type, FC (Ferrule Connector) - screw on type, LC (Lucent Connector) - snap on type and MTP/MPO - push/pull type, pentru fibre optice multimod si fibre optice monomod. Atenuarea introdusă de un conector optic, chiar de calitate superioară este mai mare decât cea introdusă de o joncţiune, având valori de aproximativ 1dB. Conectorii sunt echipamente mecanice de mare precizie şi de obicei un capăt al fibrei se află în conector iar unul este liber. În acest caz ataşarea unui conector se reduce la execuţia unei joncţiuni. O astfel de soluţie este de obicei mai avantajoasă decât montarea unui conector direct pe capătul fibrei deoarece conectorii prefabricaţi asigură o precizie de montare mult mai mare. Dacă fibra optică este terminată într­un terminator de fibră optică pentru redistribuire acest conector de capăt se mai numeşte şi pig­tail şi este de tipul prefabricat. O categorie specială de conectori o constituie cordoanele optice de distribuire sau legătură. Acestea sunt fibre optice speciale cu conectori la ambele capete care permit raze de curbură a fibrei mici de ordinul 2,5­5 cm. Culoarea acestora este galben pentru fibra monomod şi portocaliu pentru fibra multimod.

Repetoarele sunt amplificatoare optice care receptionează semnalele luminoase atenuate ca urmare a distanţei parcurse prin fibra optică, refac forma, puterea şi parametri de timp a acestor semnale şi le transmit mai departe.

Patch panel-urile pentru fibră sunt similare patch panel-urilor pentru cablul de cupru mărind flexibilitatea reţelelor optice. Pentru conectarea diferitelor echipamente, se folosește un patch cord de fibră optică (cunoscut și sub denumirea de zip cord - două fibre optice flexibile cu conectori la fiecare capăt).
În plus, alte câteva dispozitive active sau pasive sunt folosite împreună cu fibrele optice (exemple: cuploare optice - combină sau împart semnale optice; atenuatoare optice - reduc nivelul de putere al unui semnal optic; izolatori optici; comutatoare de fibră optică; multiplexoare optice etc.).

ISO/IEC 11801-1 specifică cerințele pentru fibre coaxiale, cu perechi răsucite și fibre optice. Standardele ISO/IEC 11801 (Europa) și ANSI/TIA-568-C (SUA și Canada) definesc 7 clase de fibre optice (monomod și multimod) așa cum se arată în tabelul 2.1, împreună cu câțiva parametri importanți (specificațiile pentru fibre optice, performanța transmisiei prin cablu și specificațiile fizice ale cablurilor):
Tabel 2.1 Caracteristicile fibrelor optice
	
	Multimod
	Monomod

	Tip
	OM1
62,5/125 μm
	OM2
50/125 μm
	OM3
50/125 μm
	OM4
50/125 μm
	OM5
50/125 μm
	OS1
9/125 μm
	OS2
9/125 μm

	Lungime de undă
	850, 1300nm
	850, 1300nm
	850, 1300nm
	850, 1300nm
	850, 1300nm
	1300nm, 1550nm
(1383nm)
	1300nm, 1550nm

	Atenuare max. (db/km) 
	2.6 / 
2.4
	3.56 / 2.3
	2.6 / 
1.9
	2.9 / 
1.5
	2.9 / 
1.5
	1
	0.4

	Sursă luminoasă
	LED (Light-Emitting Diode) / 

VCSEL (Vertical Cavity Surface-Emitting Lasers Light Source) 
	LASER (Light Amplification by Stimulated Emission of Radiation)

	Distanță/

rată

de date
	1 Gbps
	275m
	550m
	-
	-
	-
	5-120km

	
	10Gbps
	33m
	82m
	300m
	400m
	400m
	10-80km

	
	40-100 Gbps
	-
	-
	100m
	150m
	150m
	2-80km

	Culoare
	orange/ slate
	orange
	albastru deschis (aqua)
	violet/ albastru deschis (aqua)
	verde/ lime
	galben
	galben


Instalarea incorecta a fibrelor optice are ca şi rezultat creşterea atenuării semnalului optic. Intinderea sau curbarea exagerată a fibrei optice poate cauza mici fisuri ale miezului care vor dispersa semnalul luminos. Curbarea exagerată a fibrei optice poate avea ca urmare scăderea unghiului incident al semnalului luminos sub unghiul critic de reflexie totală. Pentru instalarea conectorilor capetele fibrei trebuiesc taiate si finisate. Dupa instalare, capetele fibrelor optice, conectorii şi porturile de fibră trebuiesc păstrate curate pentru a nu introduce atenuări. Înaintea folosirii cablurilor de fibră optică, trebuie testată atenuarea introdusă de acestea. La proiectarea unei legaturi pe fibră optică, trebuie calculată pierderea puterii semnalului care poate fi tolerată. Aceasta se numeste bugetul de pierdere a legaturii optice. Pierderea puterii se masoara in decibeli (dB).

Pentru testarea unei legături prin fibră optică există mai multe procedee: testare de continuitate, localizare vizuală a erorilor, procedeul de măsurare a puterii optice la ieşire, procedeul OTDR şi testul BER de rată a erorilor.
Testerele de continuitate sunt folosite pentru a testa continuitatea unei fibre optice. Un instrument de localizare vizuală a defecțiunilor (VFL) permite unui tehnician să identifice rupturi, macro-îndoituri (se referă la raza minimă de îndoire) sau joncțiuni de fuziune slabe.
Procedeul de măsurare a puterii optice la ieşire determină pierderile de putere prin legătura optică măsurând puterea la ieşire la o putere de intrare cunoscută. Unitatea de măsură pentru puteri optice este miliwattul (mW) insă din considerente practice se utilizează o altă unitate de măsură care măsoră câştigul (G) sau pierderea (L) într-un sistem şi anume deciBell-ul (dB).

Procedeul OTDR Optical Time Domain Reflectometer este procedeul prin care se pot vizualiza caracteristicile de atenuare ale unei fibre optice precum şi lungimea acesteia. Acest procedeu este singurul prin care se pot detecta poziţiile întreruperilor în fibra optică. OTDR afişează un grafic care are ca axă x lungimea fibrei şi ca axă y atenuarea. Din graficul astfel afişat se pot deduce atenuarea fibrei, calitatea joncţiunilor şi a conectoarelor. Deasemenea se poate determina poziţia rupturilor în cablu dacă extern cablul nu este afectat.

Testul BER (Bit Error Rate) este testul final la care se supune o legătură de date prin fibră optică. Acest test sau criteriu arată la câţi biţi transmişi prin fibră se produce o eroare datorată fibrei. Testul BER trebuie să îndeplinească cerinţele impuse de producătorii de echipamente DTE ce se cuplează la fibra optică. Pentru reţele de calculatoare acestea cer să fie mai mici decât 1 bit de eroare la 109/1012 biţi transmişi sau BER < 10-9/10-12. Pentru testare este nevoie de un generator de secvenţe de bit aleatoare şi de o interfaţă la fibra optică dacă se testează o buclă sau de două dacă se testează o singură fibră. Pentru a avea rezultate semnificative testul trebuie să se desfăşoare pe o perioadă suficient de lungă astfel încât să se transmită un număr suficient de mare de biţi. Perioade de testare de o zi sau două sunt obişnuite dacă se lucrează la rată de bit mare în utilizarea legăturii prin fibră optică şi BER mic. Un numărător poate contoriza automat numărul de erori detectate.

2.2 Calculul bugetului de putere optică 
Tabelul  2.2 Calcul buget de putere optica
	Crt. 
	Pierdere sau Putere Optică
	dB

	1.
	Pierderea pe km în Fibra Optică___dB/km X __km fibră 
	___dB

	2.
	Pierderea în Joncţiuni ___dB/joncţiune X __ joncţiuni
	___dB

	3.
	Pierderea în Conectoare ___dB/conector X ___ conectoare
	___dB

	4.
	Pierderi pe alte Componente
	___dB

	5.
	Margine de Eroare
	___dB

	6.
	Pierderea Totală pe Legătură (1+2+3+4+5)
	___dB

	7.
	Puterea de Emisie Medie a Emiţătorului
	___dB

	8.
	Puterea Medie Recepţionată de Receptor (7-6)
	___dB

	9.
	Dinamica Receptorului _____dB la _____dB
	

	10.
	Sensibilitatea Receptorului la o Rată de Erori dată BER ____
	___dB

	11.
	Putere Rămasă Disponibilă (8-10)
	___dB


Observaţii:
La punctul 3. nu se iau în considerare pierderile de conectare a emiţătorului la fibra optică, acestea fiind deja incluse. Valoarea calculată la punctul 8. trebuie să fie în intervalul de la punctul 9. pentru ca receptorul să funcţioneze corect. Valoarea calculată la punctul 11. trebuie să fie pozitivă pentru a avea o legătură de date optică funcţională.

Marginea de eroare se datorează luării în calcul a unor valori medii pentru toate componentele legăturii. Dispersia acestor valori în jurul valorii medii este cunoscută şi se poate lua o margine de eroare suficient de mare ca aceasta să acopere deviaţiile de la medie cu o probabilitate de 99,9% sau mai mare. Cu cât numărul de elemente este mai mare şi cu cât se doreşte o probabilitate de acoperire mai mare cu atât se va lua o margine de eroare mai mare.

Puterea de emisie optică a emiţătorului este o dată de catalog şi conţine în ea inclusă şi pierderea de conectare la un capăt de fibră optică în cazul în care conectarea se face conform recomandărilor. Puterea este mai mare la diode LASER şi mai mică la LED. În cazul utilizării de LASER este nevoie pentru distanţe relativ scurte chiar de un atenuator pentru a nu distruge receptorul.

Dinamica receptorului reprezintă plaja de puteri pe care un receptor le poate transforma în semnal electric fără pierderi de informaţie.

De asemenea este nevoie de o putere optică minimă necesară pentru îndeplinirea condiţiei de rată de erori tolerată care pentru reţele de calculatoare se situează la valoarea de 1 bit eronat la un miliard de biţi transmişi.

Exemplu de calcul al bugetului de putere optică

Diametrul fibrei optice: Miez 62.5μm/Înveliş 125μm. Apertura numerică a fibrei NA:0,275. Lungimea de undă a echipamentului optic: 1310μm.

Tabelul 2.3 Exemplu de calcul 
	Crt. 
	Pierdere sau Putere Optică
	dB

	1.
	Pierderea pe km în Fibra Optică 1,8dB/km X 3,5km fibră
	6,3dB

	2.
	Pierderea în Joncţiuni 0,5dB/joncţiune X 2 joncţiuni
	1,0dB

	3.
	Pierderea în Conectoare 1,0dB/conector X 2 conectoare
	2,0dB

	4.
	Pierderi pe alte Componente
	0,0dB

	5.
	Margine de Eroare
	2.0dB

	6.
	Pierderea totală pe Legătură (1+2+3+4+5)
	11,3dB

	7.
	Puterea de Emisie Medie a Emiţătorului
	-10,0dB

	8.
	Puterea Medie Recepţionată de Receptor (7-6)
	-21,3dB

	9.
	Dinamica Receptorului -10,0dB la -30,0dB
	

	10.
	Sensibilitatea Receptorului la o Rată de Erori dată BER 10-9
	-26,0dB

	11.
	Putere Rămasă Disponibilă (8-10)
	+4,7dB


Puterea ajunsă la receptor se încadrează în dinamica receptorului, ceea ce face posibilă funcţionarea sa, iar puterea rămasă disponibilă este pozitivă ceea ce ne asigură de o legătură viabilă.

Trebuie ţinut cont şi de faptul că în cursul vieţii legăturii pot apare fenomene de îmbătrânire a materialelor, care duc la creşterea pierderilor de putere, precum şi de faptul că fibra optică poate fi ruptă accidental şi trebuie joncţionată.
Un calcul făcut la limită periclitează durata de exploatare a unei legături prin fibră optică.

3. Desfăşurarea lucrării

3.1 Se vor discuta caracteristicile diferitelor tipuri de fibre şi componente optice şi aspectele legate de cablarea reţelelor de calculatoare folosindu-se acest mediu de transmisie.
3.2 Explorați infrastructura de fibra optică din oceane: https://www.submarinecablemap.com/ 

3.3 Se consideră o fibră optică monomod de 9/125μ având lungimea de 2,5km şi pierderea egală cu 0,5dB/km, care conectează două echipamente DTE. Atenuarea introdusă de joncţiuni şi conectori este egală cu 0,5 şi respectiv 1dB. Marginea de eroare luată în considerare este de 3dB. Puterea de emisie medie a emiţătorului este de -15dB, sensibilitatea receptorului la o rată de erori dată BER 10-9 este de -25dB şi dinamica receptorului este în intervalul -10 ÷ -30dB. Să se calculeze bugetul de putere optică.
(Manta)

(Întăritor)

(Protecție)

(Îmbracaminte)

(Miez)





2
3


